{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belin\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "from random import random\n",
    "from nltk import word_tokenize\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition\n",
    "\n",
    "For this assignment, you must download the data and extract it into `data/`. The dataset contains two files, both containing a single caption on each line. We should have 415,795 sentences in the training captions and 500 sentences in the validation captions.\n",
    "\n",
    "To download the data, run the following directly on your server: `wget https://s3-us-west-2.amazonaws.com/cpsc532l-data/a3_data.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414143\n",
      "500\n",
      "A very clean and well decorated empty bathroom.\n"
     ]
    }
   ],
   "source": [
    "# Load the data into memory.\n",
    "train_sentences = [line.strip() for line in open(\"data/mscoco_train_captions.txt\").readlines() if line.strip() != '']\n",
    "val_sentences = [line.strip() for line in open(\"data/mscoco_val_captions.txt\").readlines()]\n",
    "\n",
    "for index, sentence in enumerate(train_sentences):\n",
    "    if sentence[-1] != '.':\n",
    "        train_sentences[index] = sentence + '.'\n",
    "\n",
    "for index, sentence in enumerate(val_sentences):\n",
    "    if sentence[-1] != '.':\n",
    "        val_sentences[index] = sentence + '.'\n",
    "        \n",
    "print(len(train_sentences))\n",
    "print(len(val_sentences))\n",
    "print(train_sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "The code provided below creates word embeddings for you to use. After creating the vocabulary, we construct both one-hot embeddings and word2vec embeddings. \n",
    "\n",
    "All of the packages utilized should be installed on your Azure servers, however you will have to download an NLTK corpus. To do this, follow the instructions below:\n",
    "\n",
    "1. SSH to your Azure server\n",
    "2. Open up Python interpreter\n",
    "3. `import nltk`\n",
    "4. `nltk.download()`\n",
    "\n",
    "    You should now see something that looks like:\n",
    "\n",
    "    ```\n",
    "    >>> nltk.download()\n",
    "    NLTK Downloader\n",
    "    ---------------------------------------------------------------------------\n",
    "        d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
    "    ---------------------------------------------------------------------------\n",
    "    Downloader> \n",
    "\n",
    "    ```\n",
    "\n",
    "5. `d punkt`\n",
    "6. Provided the download finished successfully, you may now exit out of the Python interpreter and close the SSH connection.\n",
    "\n",
    "Please look through the functions provided below **carefully**, as you will need to use all of them at some point in your assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = train_sentences\n",
    "\n",
    "# Lower-case the sentence, tokenize them and add <SOS> and <EOS> tokens\n",
    "sentences = [[\"<SOS>\"] + word_tokenize(sentence.lower()) + [\"<EOS>\"] for sentence in sentences]\n",
    "\n",
    "# Create the vocabulary. Note that we add an <UNK> token to represent words not in our vocabulary.\n",
    "vocabularySize = 1000\n",
    "word_counts = Counter([word for sentence in sentences for word in sentence])\n",
    "vocabulary = [\"<UNK>\"] + [e[0] for e in word_counts.most_common(vocabularySize-1)]\n",
    "word2index = {word:index for index,word in enumerate(vocabulary)}\n",
    "one_hot_embeddings = np.eye(vocabularySize)\n",
    "\n",
    "# Build the word2vec embeddings\n",
    "wordEncodingSize = 300\n",
    "filtered_sentences = [[word for word in sentence if word in word2index] for sentence in sentences]\n",
    "w2v = Word2Vec(filtered_sentences, min_count=0, size=wordEncodingSize)\n",
    "w2v_embeddings = np.concatenate((np.zeros((1, wordEncodingSize)), w2v.wv.syn0))\n",
    "\n",
    "# Define the max sequence length to be the longest sentence in the training data. \n",
    "maxSequenceLength = max([len(sentence) for sentence in sentences])\n",
    "\n",
    "def preprocess_numberize(sentence):\n",
    "    \"\"\"\n",
    "    Given a sentence, in the form of a string, this function will preprocess it\n",
    "    into list of numbers (denoting the index into the vocabulary).\n",
    "    \"\"\"\n",
    "    tokenized = word_tokenize(sentence.lower())\n",
    "        \n",
    "    # Add the <SOS>/<EOS> tokens and numberize (all unknown words are represented as <UNK>).\n",
    "    tokenized = [\"<SOS>\"] + tokenized + [\"<EOS>\"]\n",
    "    numberized = [word2index.get(word, 0) for word in tokenized]\n",
    "    \n",
    "    return numberized\n",
    "\n",
    "def preprocess_one_hot(sentence):\n",
    "    \"\"\"\n",
    "    Given a sentence, in the form of a string, this function will preprocess it\n",
    "    into a numpy array of one-hot vectors.\n",
    "    \"\"\"\n",
    "    numberized = preprocess_numberize(sentence)\n",
    "    \n",
    "    # Represent each word as it's one-hot embedding\n",
    "    one_hot_embedded = one_hot_embeddings[numberized]\n",
    "    \n",
    "    return one_hot_embedded\n",
    "\n",
    "def preprocess_word2vec(sentence):\n",
    "    \"\"\"\n",
    "    Given a sentence, in the form of a string, this function will preprocess it\n",
    "    into a numpy array of word2vec embeddings.\n",
    "    \"\"\"\n",
    "    numberized = preprocess_numberize(sentence)\n",
    "    \n",
    "    # Represent each word as it's one-hot embedding\n",
    "    w2v_embedded = w2v_embeddings[numberized]\n",
    "    \n",
    "    return w2v_embedded\n",
    "\n",
    "def compute_bleu(reference_sentence, predicted_sentence):\n",
    "    \"\"\"\n",
    "    Given a reference sentence, and a predicted sentence, compute the BLEU similary between them.\n",
    "    \"\"\"\n",
    "    reference_tokenized = word_tokenize(reference_sentence.lower())\n",
    "    predicted_tokenized = word_tokenize(predicted_sentence.lower())\n",
    "    return sentence_bleu([reference_tokenized], predicted_tokenized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Building a Language Decoder\n",
    "\n",
    "We now implement a language decoder. For now, we will have the decoder take a single training sample at a time (as opposed to batching). For our purposes, we will also avoid defining the embeddings as part of the model and instead pass in embedded inputs. While this is sometimes useful, as it learns/tunes the embeddings, we avoid doing it for the sake of simplicity and speed.\n",
    "\n",
    "Remember to use LSTM hidden units!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "(1000, 300)\n",
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.64252836 -0.04464054 -0.02437208 ...  0.45854273 -0.40346768\n",
      "  -0.58654529]\n",
      " [ 0.29306009  0.19502763  0.38849041 ...  0.50763428 -0.24476127\n",
      "  -0.47664955]\n",
      " ...\n",
      " [-0.57009608  0.53415418 -0.37802663 ... -0.00389384 -0.61393547\n",
      "   0.01855109]\n",
      " [ 0.53694671 -0.15880792  0.51926643 ... -0.20401719 -0.10407556\n",
      "  -0.26090741]\n",
      " [ 0.403263   -1.45369279  0.12051474 ... -0.27986085  0.36217818\n",
      "  -0.32311931]]\n",
      "['<UNK>', 'a', '.', '<SOS>', '<EOS>']\n",
      "A blue and white bathroom with butterfly themed wall tiles.\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(11, 1000)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Testing only \"\"\"\n",
    "print(maxSequenceLength)\n",
    "print(w2v_embeddings.shape)\n",
    "print(w2v_embeddings)\n",
    "\n",
    "print(vocabulary[0:5])\n",
    "print(train_sentences[2])\n",
    "print(preprocess_one_hot(train_sentences[0]))\n",
    "print(preprocess_one_hot(train_sentences[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "( 0  ,.,.) = \n",
      "1.00000e-02 *\n",
      "  1.6582 -5.8084 -5.8018  ...   1.0613  5.2599  2.9784\n",
      "[torch.cuda.DoubleTensor of size 1x1x1000 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 0.2716  1.6143 -0.2492 -0.4618 -0.7349\n",
      "-0.2343 -2.1428  0.6304 -1.6372  1.3402\n",
      "-0.6010  1.5082 -1.9139  0.3596 -0.7784\n",
      "[torch.FloatTensor of size 3x5]\n",
      "\n",
      "Variable containing:\n",
      " 2\n",
      " 1\n",
      " 3\n",
      "[torch.LongTensor of size 3]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Testing only \"\"\"\n",
    "input_sentence = preprocess_one_hot(train_sentences[0])\n",
    "input_sentence = torch.from_numpy(input_sentence[0])\n",
    "input_sentence = Variable(input_sentence.float())\n",
    "input_sentence = input_sentence.cuda()\n",
    "input_sentence = input_sentence.view(1, 1, 1000)\n",
    "\n",
    "lstm = nn.LSTM(1000, 300).cuda()\n",
    "output, hidden = lstm(input_sentence)\n",
    "\n",
    "linear = nn.Linear(300, 1000).double().cuda()\n",
    "output = linear(output.double().cuda())\n",
    "print(output)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "input = Variable(torch.randn(3, 5), requires_grad=True)\n",
    "target = Variable(torch.LongTensor(3).random_(5))\n",
    "print(input)\n",
    "print(target)\n",
    "output = loss(input, target)\n",
    "torch.cuda.current_device()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderLSTM(nn.Module):\n",
    "    # Your code goes here\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size).double().cuda()\n",
    "        self.linear = nn.Linear(hidden_size, output_size).double().cuda()\n",
    "        self.softmax = nn.LogSoftmax(dim=2).double().cuda()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output, hidden = self.lstm(input, hidden)\n",
    "        output = self.linear(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        return result.double().cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training a Language Decoder\n",
    "\n",
    "We must now train the language decoder we implemented above. An important thing to pay attention to is the [inputs for an LSTM](http://pytorch.org/docs/master/nn.html#torch.nn.LSTM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 37s (- 261m 20s) (1000 0%) 4.5910\n",
      "1m 16s (- 262m 17s) (2000 0%) 4.1580\n",
      "1m 55s (- 264m 13s) (3000 0%) 4.0781\n",
      "2m 35s (- 264m 54s) (4000 0%) 4.0283\n",
      "3m 13s (- 263m 40s) (5000 1%) 3.9425\n",
      "3m 51s (- 262m 50s) (6000 1%) 3.9330\n",
      "4m 31s (- 263m 1s) (7000 1%) 3.9186\n",
      "5m 10s (- 262m 41s) (8000 1%) 3.8757\n",
      "5m 49s (- 262m 6s) (9000 2%) 3.8457\n",
      "6m 28s (- 261m 39s) (10000 2%) 3.8771\n",
      "7m 7s (- 261m 18s) (11000 2%) 3.8434\n",
      "7m 47s (- 261m 13s) (12000 2%) 3.8914\n",
      "8m 27s (- 260m 45s) (13000 3%) 3.8548\n",
      "9m 5s (- 260m 4s) (14000 3%) 3.8475\n",
      "9m 44s (- 259m 10s) (15000 3%) 3.8205\n",
      "10m 23s (- 258m 36s) (16000 3%) 3.8072\n",
      "11m 2s (- 257m 53s) (17000 4%) 3.8749\n",
      "11m 40s (- 257m 5s) (18000 4%) 3.8085\n",
      "12m 20s (- 256m 43s) (19000 4%) 3.8706\n",
      "13m 0s (- 256m 15s) (20000 4%) 3.8384\n",
      "13m 39s (- 255m 38s) (21000 5%) 3.8192\n",
      "14m 18s (- 254m 58s) (22000 5%) 3.7802\n",
      "14m 56s (- 254m 5s) (23000 5%) 3.7696\n",
      "15m 35s (- 253m 30s) (24000 5%) 3.8240\n",
      "16m 14s (- 252m 47s) (25000 6%) 3.8611\n",
      "16m 52s (- 251m 57s) (26000 6%) 3.8123\n",
      "17m 30s (- 251m 9s) (27000 6%) 3.7500\n",
      "18m 9s (- 250m 27s) (28000 6%) 3.7581\n",
      "18m 48s (- 249m 41s) (29000 7%) 3.7882\n",
      "19m 26s (- 248m 54s) (30000 7%) 3.8025\n",
      "20m 4s (- 248m 9s) (31000 7%) 3.7828\n",
      "20m 43s (- 247m 26s) (32000 7%) 3.7181\n",
      "21m 21s (- 246m 45s) (33000 7%) 3.8824\n",
      "21m 59s (- 245m 54s) (34000 8%) 4.0305\n",
      "22m 38s (- 245m 17s) (35000 8%) 3.9964\n",
      "23m 18s (- 244m 48s) (36000 8%) 3.9432\n",
      "23m 56s (- 244m 3s) (37000 8%) 3.8414\n",
      "24m 34s (- 243m 16s) (38000 9%) 3.8394\n",
      "25m 13s (- 242m 33s) (39000 9%) 3.8691\n",
      "25m 52s (- 241m 57s) (40000 9%) 3.8435\n",
      "26m 30s (- 241m 14s) (41000 9%) 3.8256\n",
      "27m 8s (- 240m 32s) (42000 10%) 3.8432\n",
      "27m 48s (- 239m 57s) (43000 10%) 3.8688\n",
      "28m 27s (- 239m 21s) (44000 10%) 3.8955\n",
      "29m 6s (- 238m 43s) (45000 10%) 3.8825\n",
      "29m 45s (- 238m 8s) (46000 11%) 3.9264\n",
      "30m 23s (- 237m 28s) (47000 11%) 3.8017\n",
      "31m 2s (- 236m 47s) (48000 11%) 3.8625\n",
      "31m 40s (- 236m 5s) (49000 11%) 3.8894\n",
      "32m 19s (- 235m 23s) (50000 12%) 3.8703\n",
      "32m 57s (- 234m 38s) (51000 12%) 3.8337\n",
      "33m 35s (- 233m 57s) (52000 12%) 3.7874\n",
      "34m 14s (- 233m 18s) (53000 12%) 3.8007\n",
      "34m 52s (- 232m 37s) (54000 13%) 3.8484\n",
      "35m 31s (- 231m 57s) (55000 13%) 3.8291\n",
      "36m 9s (- 231m 15s) (56000 13%) 3.7878\n",
      "36m 48s (- 230m 34s) (57000 13%) 3.8007\n",
      "37m 26s (- 229m 54s) (58000 14%) 3.7978\n",
      "38m 4s (- 229m 9s) (59000 14%) 3.7807\n",
      "38m 41s (- 228m 24s) (60000 14%) 3.8211\n",
      "39m 19s (- 227m 42s) (61000 14%) 3.7759\n",
      "39m 57s (- 226m 59s) (62000 14%) 3.7941\n",
      "40m 36s (- 226m 18s) (63000 15%) 3.7777\n",
      "41m 13s (- 225m 34s) (64000 15%) 3.7592\n",
      "41m 52s (- 224m 54s) (65000 15%) 3.7872\n",
      "42m 30s (- 224m 13s) (66000 15%) 3.9073\n",
      "43m 8s (- 223m 31s) (67000 16%) 3.9476\n",
      "43m 47s (- 222m 53s) (68000 16%) 3.8877\n",
      "44m 26s (- 222m 17s) (69000 16%) 3.8564\n",
      "45m 4s (- 221m 37s) (70000 16%) 3.8137\n",
      "45m 43s (- 220m 58s) (71000 17%) 3.7716\n",
      "46m 21s (- 220m 16s) (72000 17%) 3.7791\n",
      "47m 0s (- 219m 38s) (73000 17%) 3.7831\n",
      "47m 38s (- 218m 58s) (74000 17%) 3.7400\n",
      "48m 17s (- 218m 20s) (75000 18%) 3.7658\n",
      "48m 56s (- 217m 43s) (76000 18%) 3.7905\n",
      "49m 34s (- 217m 5s) (77000 18%) 3.7491\n",
      "50m 12s (- 216m 24s) (78000 18%) 3.7512\n",
      "50m 50s (- 215m 42s) (79000 19%) 3.7339\n",
      "51m 29s (- 215m 2s) (80000 19%) 3.7664\n",
      "52m 7s (- 214m 23s) (81000 19%) 3.7044\n",
      "52m 46s (- 213m 44s) (82000 19%) 3.7559\n",
      "53m 24s (- 213m 4s) (83000 20%) 3.7592\n",
      "54m 2s (- 212m 23s) (84000 20%) 3.7142\n",
      "54m 41s (- 211m 46s) (85000 20%) 3.7252\n",
      "55m 19s (- 211m 7s) (86000 20%) 3.7928\n",
      "55m 58s (- 210m 28s) (87000 21%) 3.7672\n",
      "56m 36s (- 209m 48s) (88000 21%) 3.7804\n",
      "57m 15s (- 209m 9s) (89000 21%) 3.7311\n",
      "57m 53s (- 208m 29s) (90000 21%) 3.7545\n",
      "58m 31s (- 207m 49s) (91000 21%) 3.7411\n",
      "59m 9s (- 207m 10s) (92000 22%) 3.7290\n",
      "59m 47s (- 206m 29s) (93000 22%) 3.7461\n",
      "60m 25s (- 205m 48s) (94000 22%) 3.6798\n",
      "61m 3s (- 205m 8s) (95000 22%) 3.7054\n",
      "61m 41s (- 204m 26s) (96000 23%) 3.7273\n",
      "62m 19s (- 203m 45s) (97000 23%) 3.7012\n",
      "62m 57s (- 203m 4s) (98000 23%) 3.7045\n",
      "63m 34s (- 202m 23s) (99000 23%) 3.8385\n",
      "64m 12s (- 201m 41s) (100000 24%) 3.8788\n",
      "64m 50s (- 201m 1s) (101000 24%) 3.8200\n",
      "65m 29s (- 200m 24s) (102000 24%) 3.8439\n",
      "66m 7s (- 199m 44s) (103000 24%) 3.7698\n",
      "66m 45s (- 199m 5s) (104000 25%) 3.7335\n",
      "67m 24s (- 198m 26s) (105000 25%) 3.8018\n",
      "68m 2s (- 197m 47s) (106000 25%) 3.7530\n",
      "68m 41s (- 197m 9s) (107000 25%) 3.7496\n",
      "69m 19s (- 196m 30s) (108000 26%) 3.7653\n",
      "69m 57s (- 195m 50s) (109000 26%) 3.7737\n",
      "70m 35s (- 195m 11s) (110000 26%) 3.7772\n",
      "71m 14s (- 194m 33s) (111000 26%) 3.7913\n",
      "71m 52s (- 193m 52s) (112000 27%) 3.7489\n",
      "72m 30s (- 193m 13s) (113000 27%) 3.8030\n",
      "73m 8s (- 192m 33s) (114000 27%) 3.7364\n",
      "73m 46s (- 191m 53s) (115000 27%) 3.7266\n",
      "74m 24s (- 191m 13s) (116000 28%) 3.7221\n",
      "75m 2s (- 190m 34s) (117000 28%) 3.7018\n",
      "75m 40s (- 189m 56s) (118000 28%) 3.7812\n",
      "76m 19s (- 189m 17s) (119000 28%) 3.8165\n",
      "76m 57s (- 188m 38s) (120000 28%) 3.7421\n",
      "77m 35s (- 187m 58s) (121000 29%) 3.7556\n",
      "78m 13s (- 187m 19s) (122000 29%) 3.7149\n",
      "78m 52s (- 186m 41s) (123000 29%) 3.7184\n",
      "79m 30s (- 186m 1s) (124000 29%) 3.6726\n",
      "80m 7s (- 185m 20s) (125000 30%) 3.7466\n",
      "80m 45s (- 184m 41s) (126000 30%) 3.7052\n",
      "81m 23s (- 184m 1s) (127000 30%) 3.6479\n",
      "82m 1s (- 183m 22s) (128000 30%) 3.7153\n",
      "82m 38s (- 182m 41s) (129000 31%) 3.7241\n",
      "83m 16s (- 182m 1s) (130000 31%) 3.6926\n",
      "83m 54s (- 181m 22s) (131000 31%) 3.6977\n",
      "84m 32s (- 180m 41s) (132000 31%) 3.8567\n",
      "85m 10s (- 180m 3s) (133000 32%) 3.8460\n",
      "85m 49s (- 179m 26s) (134000 32%) 3.8010\n",
      "86m 29s (- 178m 50s) (135000 32%) 3.8231\n",
      "87m 8s (- 178m 12s) (136000 32%) 3.7797\n",
      "87m 47s (- 177m 35s) (137000 33%) 3.7135\n",
      "88m 26s (- 176m 57s) (138000 33%) 3.7301\n",
      "89m 4s (- 176m 19s) (139000 33%) 3.7289\n",
      "89m 44s (- 175m 44s) (140000 33%) 3.6639\n",
      "90m 24s (- 175m 7s) (141000 34%) 3.7289\n",
      "91m 3s (- 174m 30s) (142000 34%) 3.7387\n",
      "91m 42s (- 173m 52s) (143000 34%) 3.7207\n",
      "92m 21s (- 173m 15s) (144000 34%) 3.7436\n",
      "93m 0s (- 172m 38s) (145000 35%) 3.6981\n",
      "93m 39s (- 172m 0s) (146000 35%) 3.7093\n",
      "94m 17s (- 171m 21s) (147000 35%) 3.7002\n",
      "94m 56s (- 170m 44s) (148000 35%) 3.7594\n",
      "95m 36s (- 170m 7s) (149000 35%) 3.7534\n",
      "96m 15s (- 169m 30s) (150000 36%) 3.6753\n",
      "96m 55s (- 168m 53s) (151000 36%) 3.7024\n",
      "97m 34s (- 168m 16s) (152000 36%) 3.7854\n",
      "98m 13s (- 167m 38s) (153000 36%) 3.7288\n",
      "98m 51s (- 166m 59s) (154000 37%) 3.7023\n",
      "99m 30s (- 166m 22s) (155000 37%) 3.7361\n",
      "100m 10s (- 165m 45s) (156000 37%) 3.7096\n",
      "100m 48s (- 165m 6s) (157000 37%) 3.6662\n",
      "101m 27s (- 164m 28s) (158000 38%) 3.7121\n",
      "102m 6s (- 163m 50s) (159000 38%) 3.6846\n",
      "102m 44s (- 163m 11s) (160000 38%) 3.6424\n",
      "103m 22s (- 162m 32s) (161000 38%) 3.6415\n",
      "104m 1s (- 161m 53s) (162000 39%) 3.6379\n",
      "104m 39s (- 161m 15s) (163000 39%) 3.6915\n",
      "105m 18s (- 160m 36s) (164000 39%) 3.7003\n",
      "105m 56s (- 159m 58s) (165000 39%) 3.9391\n",
      "106m 36s (- 159m 21s) (166000 40%) 3.8599\n",
      "107m 15s (- 158m 43s) (167000 40%) 3.8331\n",
      "107m 54s (- 158m 5s) (168000 40%) 3.8030\n",
      "108m 32s (- 157m 27s) (169000 40%) 3.7760\n",
      "109m 11s (- 156m 49s) (170000 41%) 3.7435\n",
      "109m 49s (- 156m 10s) (171000 41%) 3.7200\n",
      "110m 28s (- 155m 31s) (172000 41%) 3.6932\n",
      "111m 7s (- 154m 53s) (173000 41%) 3.7861\n",
      "111m 46s (- 154m 15s) (174000 42%) 3.7946\n",
      "112m 25s (- 153m 38s) (175000 42%) 3.7469\n",
      "113m 5s (- 153m 0s) (176000 42%) 3.7657\n",
      "113m 43s (- 152m 21s) (177000 42%) 3.7195\n",
      "114m 21s (- 151m 42s) (178000 42%) 3.7015\n",
      "115m 0s (- 151m 4s) (179000 43%) 3.7021\n",
      "115m 39s (- 150m 26s) (180000 43%) 3.7546\n",
      "116m 18s (- 149m 49s) (181000 43%) 3.7633\n",
      "116m 57s (- 149m 10s) (182000 43%) 3.6279\n",
      "117m 36s (- 148m 32s) (183000 44%) 3.7371\n",
      "118m 18s (- 147m 59s) (184000 44%) 3.7707\n",
      "118m 58s (- 147m 21s) (185000 44%) 3.7199\n",
      "119m 37s (- 146m 43s) (186000 44%) 3.7034\n",
      "120m 16s (- 146m 5s) (187000 45%) 3.7177\n",
      "120m 55s (- 145m 27s) (188000 45%) 3.7220\n",
      "121m 35s (- 144m 50s) (189000 45%) 3.7420\n",
      "122m 13s (- 144m 11s) (190000 45%) 3.6722\n",
      "122m 52s (- 143m 33s) (191000 46%) 3.7079\n",
      "123m 31s (- 142m 54s) (192000 46%) 3.6490\n",
      "124m 9s (- 142m 16s) (193000 46%) 3.7338\n",
      "124m 48s (- 141m 37s) (194000 46%) 3.6747\n",
      "125m 27s (- 140m 59s) (195000 47%) 3.6818\n",
      "126m 6s (- 140m 20s) (196000 47%) 3.6754\n",
      "126m 44s (- 139m 42s) (197000 47%) 3.8919\n",
      "127m 22s (- 139m 2s) (198000 47%) 3.9904\n",
      "128m 0s (- 138m 23s) (199000 48%) 3.8527\n",
      "128m 39s (- 137m 45s) (200000 48%) 3.8090\n",
      "129m 17s (- 137m 6s) (201000 48%) 3.7705\n",
      "129m 56s (- 136m 27s) (202000 48%) 3.7675\n",
      "130m 34s (- 135m 48s) (203000 49%) 3.7014\n",
      "131m 13s (- 135m 10s) (204000 49%) 3.7292\n",
      "131m 50s (- 134m 30s) (205000 49%) 3.6613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132m 29s (- 133m 52s) (206000 49%) 3.6969\n",
      "133m 7s (- 133m 13s) (207000 49%) 3.7438\n",
      "133m 46s (- 132m 34s) (208000 50%) 3.7131\n",
      "134m 25s (- 131m 56s) (209000 50%) 3.6926\n",
      "135m 3s (- 131m 17s) (210000 50%) 3.6695\n",
      "135m 41s (- 130m 38s) (211000 50%) 3.6021\n",
      "136m 18s (- 129m 58s) (212000 51%) 3.6214\n",
      "136m 57s (- 129m 19s) (213000 51%) 3.6773\n",
      "137m 35s (- 128m 41s) (214000 51%) 3.6741\n",
      "138m 14s (- 128m 2s) (215000 51%) 3.6372\n",
      "138m 53s (- 127m 24s) (216000 52%) 3.6755\n",
      "139m 32s (- 126m 45s) (217000 52%) 3.7058\n",
      "140m 9s (- 126m 6s) (218000 52%) 3.6152\n",
      "140m 48s (- 125m 27s) (219000 52%) 3.6222\n",
      "141m 26s (- 124m 48s) (220000 53%) 3.6473\n",
      "142m 4s (- 124m 10s) (221000 53%) 3.7172\n",
      "142m 42s (- 123m 31s) (222000 53%) 3.6645\n",
      "143m 20s (- 122m 51s) (223000 53%) 3.6063\n",
      "143m 58s (- 122m 13s) (224000 54%) 3.5773\n",
      "144m 37s (- 121m 34s) (225000 54%) 3.6502\n",
      "145m 16s (- 120m 56s) (226000 54%) 3.6489\n",
      "145m 53s (- 120m 16s) (227000 54%) 3.5710\n",
      "146m 31s (- 119m 37s) (228000 55%) 3.6006\n",
      "147m 9s (- 118m 58s) (229000 55%) 3.6585\n",
      "147m 47s (- 118m 19s) (230000 55%) 3.9401\n",
      "148m 25s (- 117m 40s) (231000 55%) 3.9272\n",
      "149m 3s (- 117m 1s) (232000 56%) 3.8677\n",
      "149m 43s (- 116m 23s) (233000 56%) 3.8788\n",
      "150m 21s (- 115m 44s) (234000 56%) 3.7265\n",
      "150m 59s (- 115m 6s) (235000 56%) 3.7749\n",
      "151m 37s (- 114m 27s) (236000 56%) 3.7709\n",
      "152m 16s (- 113m 49s) (237000 57%) 3.7186\n",
      "152m 54s (- 113m 10s) (238000 57%) 3.6971\n",
      "153m 33s (- 112m 31s) (239000 57%) 3.6908\n",
      "154m 12s (- 111m 53s) (240000 57%) 3.7208\n",
      "154m 50s (- 111m 14s) (241000 58%) 3.7553\n",
      "155m 29s (- 110m 36s) (242000 58%) 3.7271\n",
      "156m 7s (- 109m 57s) (243000 58%) 3.6829\n",
      "156m 45s (- 109m 18s) (244000 58%) 3.7293\n",
      "157m 23s (- 108m 39s) (245000 59%) 3.7362\n",
      "158m 1s (- 108m 0s) (246000 59%) 3.7212\n",
      "158m 40s (- 107m 22s) (247000 59%) 3.7207\n",
      "159m 18s (- 106m 43s) (248000 59%) 3.7035\n",
      "159m 57s (- 106m 5s) (249000 60%) 3.7413\n",
      "160m 35s (- 105m 26s) (250000 60%) 3.7458\n",
      "161m 14s (- 104m 48s) (251000 60%) 3.6731\n",
      "161m 52s (- 104m 9s) (252000 60%) 3.7205\n",
      "162m 30s (- 103m 30s) (253000 61%) 3.7071\n",
      "163m 9s (- 102m 51s) (254000 61%) 3.7034\n",
      "163m 47s (- 102m 13s) (255000 61%) 3.7472\n",
      "164m 25s (- 101m 34s) (256000 61%) 3.7091\n",
      "165m 2s (- 100m 55s) (257000 62%) 3.6491\n",
      "165m 40s (- 100m 16s) (258000 62%) 3.6647\n",
      "166m 19s (- 99m 37s) (259000 62%) 3.6458\n",
      "166m 57s (- 98m 58s) (260000 62%) 3.6420\n",
      "167m 34s (- 98m 19s) (261000 63%) 3.6373\n",
      "168m 13s (- 97m 41s) (262000 63%) 3.6604\n",
      "168m 51s (- 97m 2s) (263000 63%) 3.9148\n",
      "169m 30s (- 96m 23s) (264000 63%) 3.8560\n",
      "170m 9s (- 95m 45s) (265000 63%) 3.8731\n",
      "170m 49s (- 95m 8s) (266000 64%) 3.7969\n",
      "171m 27s (- 94m 29s) (267000 64%) 3.7390\n",
      "172m 6s (- 93m 50s) (268000 64%) 3.7226\n",
      "172m 44s (- 93m 12s) (269000 64%) 3.7144\n",
      "173m 23s (- 92m 33s) (270000 65%) 3.6658\n",
      "174m 1s (- 91m 55s) (271000 65%) 3.7004\n",
      "174m 41s (- 91m 17s) (272000 65%) 3.7256\n",
      "175m 19s (- 90m 38s) (273000 65%) 3.7507\n",
      "175m 59s (- 90m 0s) (274000 66%) 3.7271\n",
      "176m 37s (- 89m 22s) (275000 66%) 3.7030\n",
      "177m 16s (- 88m 43s) (276000 66%) 3.7159\n",
      "177m 55s (- 88m 5s) (277000 66%) 3.7096\n",
      "178m 33s (- 87m 26s) (278000 67%) 3.7068\n",
      "179m 12s (- 86m 48s) (279000 67%) 3.7434\n",
      "179m 51s (- 86m 9s) (280000 67%) 3.7145\n",
      "180m 30s (- 85m 31s) (281000 67%) 3.6506\n",
      "181m 9s (- 84m 53s) (282000 68%) 3.6968\n",
      "181m 48s (- 84m 15s) (283000 68%) 3.7017\n",
      "182m 27s (- 83m 36s) (284000 68%) 3.6304\n",
      "183m 6s (- 82m 58s) (285000 68%) 3.6896\n",
      "183m 44s (- 82m 19s) (286000 69%) 3.6253\n",
      "184m 22s (- 81m 40s) (287000 69%) 3.7228\n",
      "185m 0s (- 81m 2s) (288000 69%) 3.7200\n",
      "185m 39s (- 80m 23s) (289000 69%) 3.6908\n",
      "186m 17s (- 79m 44s) (290000 70%) 3.6858\n",
      "186m 55s (- 79m 6s) (291000 70%) 3.6646\n",
      "187m 33s (- 78m 27s) (292000 70%) 3.6512\n",
      "188m 11s (- 77m 48s) (293000 70%) 3.6899\n",
      "188m 50s (- 77m 10s) (294000 70%) 3.5802\n",
      "189m 28s (- 76m 31s) (295000 71%) 3.6909\n",
      "190m 6s (- 75m 52s) (296000 71%) 4.0242\n",
      "190m 45s (- 75m 14s) (297000 71%) 3.8707\n",
      "191m 24s (- 74m 36s) (298000 71%) 3.8130\n",
      "192m 3s (- 73m 57s) (299000 72%) 3.7192\n",
      "192m 42s (- 73m 19s) (300000 72%) 3.7502\n",
      "193m 21s (- 72m 40s) (301000 72%) 3.7108\n",
      "194m 0s (- 72m 2s) (302000 72%) 3.6948\n",
      "194m 39s (- 71m 24s) (303000 73%) 3.7125\n",
      "195m 17s (- 70m 45s) (304000 73%) 3.6508\n",
      "195m 56s (- 70m 7s) (305000 73%) 3.7331\n",
      "196m 36s (- 69m 28s) (306000 73%) 3.6928\n",
      "197m 15s (- 68m 50s) (307000 74%) 3.7119\n",
      "197m 55s (- 68m 12s) (308000 74%) 3.6533\n",
      "198m 33s (- 67m 33s) (309000 74%) 3.6230\n",
      "199m 12s (- 66m 55s) (310000 74%) 3.6029\n",
      "199m 51s (- 66m 16s) (311000 75%) 3.6553\n",
      "200m 30s (- 65m 38s) (312000 75%) 3.6834\n",
      "201m 8s (- 64m 59s) (313000 75%) 3.6319\n",
      "201m 48s (- 64m 21s) (314000 75%) 3.6557\n",
      "202m 27s (- 63m 43s) (315000 76%) 3.6551\n",
      "203m 6s (- 63m 4s) (316000 76%) 3.5998\n",
      "203m 44s (- 62m 26s) (317000 76%) 3.5914\n",
      "204m 24s (- 61m 47s) (318000 76%) 3.6679\n",
      "205m 2s (- 61m 9s) (319000 77%) 3.6548\n",
      "205m 41s (- 60m 30s) (320000 77%) 3.6727\n",
      "206m 20s (- 59m 52s) (321000 77%) 3.5913\n",
      "206m 58s (- 59m 13s) (322000 77%) 3.6124\n",
      "207m 37s (- 58m 35s) (323000 77%) 3.5825\n",
      "208m 16s (- 57m 56s) (324000 78%) 3.6094\n",
      "208m 55s (- 57m 18s) (325000 78%) 3.6195\n",
      "209m 33s (- 56m 39s) (326000 78%) 3.6130\n",
      "210m 12s (- 56m 1s) (327000 78%) 3.6073\n",
      "210m 51s (- 55m 22s) (328000 79%) 3.8651\n",
      "211m 29s (- 54m 43s) (329000 79%) 4.1400\n",
      "212m 8s (- 54m 5s) (330000 79%) 3.8778\n",
      "212m 47s (- 53m 27s) (331000 79%) 3.9199\n",
      "213m 27s (- 52m 48s) (332000 80%) 3.8676\n",
      "214m 6s (- 52m 10s) (333000 80%) 3.7639\n",
      "214m 45s (- 51m 31s) (334000 80%) 3.7704\n",
      "215m 23s (- 50m 53s) (335000 80%) 3.7402\n",
      "216m 3s (- 50m 14s) (336000 81%) 3.7937\n",
      "216m 42s (- 49m 36s) (337000 81%) 3.7426\n",
      "217m 21s (- 48m 58s) (338000 81%) 3.8068\n",
      "218m 1s (- 48m 19s) (339000 81%) 3.7373\n",
      "218m 41s (- 47m 41s) (340000 82%) 3.7750\n",
      "219m 20s (- 47m 2s) (341000 82%) 3.7434\n",
      "219m 59s (- 46m 24s) (342000 82%) 3.7323\n",
      "220m 37s (- 45m 45s) (343000 82%) 3.7620\n",
      "221m 16s (- 45m 7s) (344000 83%) 3.7288\n",
      "221m 55s (- 44m 28s) (345000 83%) 3.7560\n",
      "222m 33s (- 43m 49s) (346000 83%) 3.7190\n",
      "223m 12s (- 43m 11s) (347000 83%) 3.7432\n",
      "223m 52s (- 42m 33s) (348000 84%) 3.7467\n",
      "224m 32s (- 41m 54s) (349000 84%) 3.7668\n",
      "225m 11s (- 41m 16s) (350000 84%) 3.7167\n",
      "225m 50s (- 40m 37s) (351000 84%) 3.6965\n",
      "226m 29s (- 39m 59s) (352000 84%) 3.7386\n",
      "227m 8s (- 39m 20s) (353000 85%) 3.7473\n",
      "227m 47s (- 38m 42s) (354000 85%) 3.7490\n",
      "228m 26s (- 38m 3s) (355000 85%) 3.6934\n",
      "229m 5s (- 37m 24s) (356000 85%) 3.7034\n",
      "229m 45s (- 36m 46s) (357000 86%) 3.7231\n",
      "230m 25s (- 36m 8s) (358000 86%) 3.7156\n",
      "231m 4s (- 35m 29s) (359000 86%) 3.6509\n",
      "231m 44s (- 34m 51s) (360000 86%) 3.6825\n",
      "232m 24s (- 34m 12s) (361000 87%) 3.9488\n",
      "233m 3s (- 33m 34s) (362000 87%) 3.8610\n",
      "233m 43s (- 32m 55s) (363000 87%) 3.8465\n",
      "234m 23s (- 32m 17s) (364000 87%) 3.7957\n",
      "235m 3s (- 31m 38s) (365000 88%) 3.8007\n",
      "235m 42s (- 31m 0s) (366000 88%) 3.7456\n",
      "236m 22s (- 30m 21s) (367000 88%) 3.8074\n",
      "237m 2s (- 29m 43s) (368000 88%) 3.7314\n",
      "237m 41s (- 29m 4s) (369000 89%) 3.7073\n",
      "238m 21s (- 28m 26s) (370000 89%) 3.7517\n",
      "239m 2s (- 27m 47s) (371000 89%) 3.8157\n",
      "239m 42s (- 27m 9s) (372000 89%) 3.7606\n",
      "240m 23s (- 26m 30s) (373000 90%) 3.7729\n",
      "241m 2s (- 25m 52s) (374000 90%) 3.7627\n",
      "241m 41s (- 25m 13s) (375000 90%) 3.7056\n",
      "242m 21s (- 24m 35s) (376000 90%) 3.7513\n",
      "243m 0s (- 23m 56s) (377000 91%) 3.7559\n",
      "243m 41s (- 23m 18s) (378000 91%) 3.7330\n",
      "244m 20s (- 22m 39s) (379000 91%) 3.7274\n",
      "245m 1s (- 22m 0s) (380000 91%) 3.8433\n",
      "245m 41s (- 21m 22s) (381000 91%) 3.7362\n",
      "246m 19s (- 20m 43s) (382000 92%) 3.7140\n",
      "246m 58s (- 20m 4s) (383000 92%) 3.6625\n",
      "247m 37s (- 19m 26s) (384000 92%) 3.6892\n",
      "248m 17s (- 18m 47s) (385000 92%) 3.7149\n",
      "248m 56s (- 18m 9s) (386000 93%) 3.7612\n",
      "249m 35s (- 17m 30s) (387000 93%) 3.7068\n",
      "250m 14s (- 16m 51s) (388000 93%) 3.7368\n",
      "250m 53s (- 16m 12s) (389000 93%) 3.6956\n",
      "251m 32s (- 15m 34s) (390000 94%) 3.7100\n",
      "252m 11s (- 14m 55s) (391000 94%) 3.6923\n",
      "252m 50s (- 14m 16s) (392000 94%) 3.7143\n",
      "253m 29s (- 13m 38s) (393000 94%) 3.7412\n",
      "254m 9s (- 12m 59s) (394000 95%) 3.8628\n",
      "254m 48s (- 12m 20s) (395000 95%) 3.7966\n",
      "255m 28s (- 11m 42s) (396000 95%) 3.7592\n",
      "256m 7s (- 11m 3s) (397000 95%) 3.7258\n",
      "256m 46s (- 10m 24s) (398000 96%) 3.7293\n",
      "257m 25s (- 9m 46s) (399000 96%) 3.7089\n",
      "258m 4s (- 9m 7s) (400000 96%) 3.7417\n",
      "258m 43s (- 8m 28s) (401000 96%) 3.7019\n",
      "259m 22s (- 7m 50s) (402000 97%) 3.6883\n",
      "260m 1s (- 7m 11s) (403000 97%) 3.6737\n",
      "260m 40s (- 6m 32s) (404000 97%) 3.7157\n",
      "261m 19s (- 5m 53s) (405000 97%) 3.6995\n",
      "261m 59s (- 5m 15s) (406000 98%) 3.6589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262m 38s (- 4m 36s) (407000 98%) 3.6639\n",
      "263m 17s (- 3m 57s) (408000 98%) 3.6860\n",
      "263m 56s (- 3m 19s) (409000 98%) 3.7168\n",
      "264m 35s (- 2m 40s) (410000 98%) 3.6655\n",
      "265m 14s (- 2m 1s) (411000 99%) 3.6563\n",
      "265m 53s (- 1m 22s) (412000 99%) 3.6704\n",
      "266m 31s (- 0m 44s) (413000 99%) 3.6663\n",
      "267m 11s (- 0m 5s) (414000 99%) 3.6633\n"
     ]
    }
   ],
   "source": [
    "def train(target_variable, \n",
    "          decoder, \n",
    "          decoder_optimizer, \n",
    "          criterion, \n",
    "          embeddings=one_hot_embeddings): \n",
    "    \"\"\"\n",
    "    Given a single training sample, go through a single step of training.\n",
    "    \"\"\"\n",
    "    \n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # target_variable has (batch_size, n_words, n_vocab)\n",
    "    target_length = target_variable.size()[1]\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    # First word in sentence needs to be fed h1=0\n",
    "    decoder_input = target_variable[0][1] # First one is SOS\n",
    "    prev_hidden = (decoder.initHidden(), decoder.initHidden())\n",
    "    predicted_word_index = 0\n",
    "\n",
    "    for index_word in range(2, target_length):\n",
    "        decoder_input = decoder_input.view(1, 1, vocabularySize)\n",
    "        decoder_output, prev_hidden = decoder(decoder_input, prev_hidden)\n",
    "        \n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        predicted_word_index = int(topi[0][0][0])\n",
    "        # print('sum:', decoder_output.sum().data[0])\n",
    "        # print(index_word, predicted_word_index, topv[0][0][0])\n",
    "        # This is the next input, without teacher forcing it's the predicted output\n",
    "        decoder_input = torch.from_numpy(embeddings[predicted_word_index])\n",
    "        decoder_input = Variable(decoder_input).cuda()\n",
    "        \n",
    "        # This is just to conform with the pytorch format..\n",
    "        # CrossEntropyLoss takes input1: (N, C) and input2: (N).\n",
    "        _, actual_word_index = target_variable[0][index_word].data.topk(1)\n",
    "        actual_word_index = Variable(actual_word_index)\n",
    "\n",
    "        # Compare current output to next \"target\" input\n",
    "        loss += criterion(decoder_output.view(1, decoder_output.size(2)), actual_word_index)\n",
    "        \n",
    "        # Stop on EOS\n",
    "        # NOTE: Saw training is better without this, so commented out\n",
    "        # if predicted_word_index == word2index['<EOS>']:\n",
    "        #   break\n",
    "            \n",
    "    \n",
    "    # Last word in sentence is fed x=0\n",
    "    # zeros = Variable(torch.zeros(1, 1, vocabularySize).double()).cuda()\n",
    "    # decoder_output, _ = decoder(zeros, prev_hidden)\n",
    "    # loss += criterion(decoder_output, zeros) # What should this be?\n",
    "    \n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    # index_word keeps track of the current word\n",
    "    # in case of break (EOS) and non-break (teacher-forcing), it'll be the actually count.\n",
    "    return loss.data[0] / index_word\n",
    "    \n",
    "\n",
    "# Train the model and monitor the loss. Remember to use Adam optimizer and CrossEntropyLoss\n",
    "decoder = DecoderLSTM(vocabularySize, 300, vocabularySize)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=0.0001)\n",
    "criterion = nn.NLLLoss()  # Since my DecoderLSTM has LogSoftmax as final layer, use NLL loss here\n",
    "\n",
    "n_iters = len(train_sentences)\n",
    "print_every = 1000\n",
    "print_loss_total = 0\n",
    "start = time.time()\n",
    "for s_index in range(1, n_iters):\n",
    "    input_sentence = preprocess_one_hot(train_sentences[s_index])\n",
    "    n_words = input_sentence.shape[0]\n",
    "    input_sentence = torch.from_numpy(input_sentence)\n",
    "    input_sentence = input_sentence.view(1, n_words, vocabularySize)\n",
    "    input_sentence = Variable(input_sentence).cuda()\n",
    "    loss = train(input_sentence, decoder, decoder_optimizer, criterion)\n",
    "    \n",
    "    print_loss_total += loss\n",
    "    \n",
    "    if s_index % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(start, s_index / n_iters),\n",
    "                                     s_index, s_index / n_iters * 100, print_loss_avg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Models\n",
    "    1. './model/decoder_noEOS_23000_3_48'  -- lr = 0.0001\n",
    "    2. './model/decoder_EOS_23000_3_48'    -- lr = 0.0001\n",
    "    3. './model/decoder_noEOS_414000_3_66' -- lr = 0.0001\n",
    "\"\"\"\n",
    "torch.save(decoder.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading\n",
    "decoder = DecoderLSTM(vocabularySize, 300, vocabularySize)\n",
    "decoder.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Building Language Decoder MAP Inference\n",
    "\n",
    "We now define a method to perform inference with our decoder and test it with a few different starting words. This code will be fairly similar to your training function from part 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the <UNK> is is <UNK> <UNK> <UNK> <UNK> <UNK> . . <EOS>\n",
      "man <UNK> a a <UNK> <UNK> a <UNK> . . <EOS>\n",
      "woman <UNK> a a <UNK> <UNK> a <UNK> . . <EOS>\n",
      "dog <UNK> a a <UNK> <UNK> <UNK> <UNK> . . <EOS>\n"
     ]
    }
   ],
   "source": [
    "def inference(decoder, init_word, embeddings=one_hot_embeddings, max_length=maxSequenceLength):\n",
    "    # Your code goes here\n",
    "    \n",
    "    # Initialize\n",
    "    sentence_word_list = []\n",
    "    predicted_word_index = word2index[init_word]\n",
    "    sentence_word_list.append(vocabulary[predicted_word_index])\n",
    "    prev_hidden = (decoder.initHidden(), decoder.initHidden())\n",
    "    \n",
    "    # Convert to one hot\n",
    "    one_hot = embeddings[predicted_word_index]\n",
    "    decoder_input = torch.from_numpy(one_hot)\n",
    "    decoder_input = Variable(decoder_input).double().cuda()\n",
    "    \n",
    "    while predicted_word_index != word2index['<EOS>']:\n",
    "        # prediction\n",
    "        decoder_input = decoder_input.view(1, 1, vocabularySize)\n",
    "        decoder_output, prev_hidden = decoder(decoder_input, prev_hidden)\n",
    "        \n",
    "        # Process output\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        predicted_word_index = int(topi[0][0][0])\n",
    "        sentence_word_list.append(vocabulary[predicted_word_index])\n",
    "        \n",
    "        # Package input for next loop\n",
    "        decoder_input = torch.from_numpy(embeddings[predicted_word_index])\n",
    "        decoder_input = Variable(decoder_input).double().cuda()\n",
    "    \n",
    "    return ' '.join(sentence_word_list)\n",
    "\n",
    "print(inference(decoder, init_word=\"the\"))\n",
    "print(inference(decoder, init_word=\"man\"))\n",
    "print(inference(decoder, init_word=\"woman\"))\n",
    "print(inference(decoder, init_word=\"dog\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Building Language Decoder Sampling Inference\n",
    "\n",
    "We must now modify the method defined in part 3, to sample from the distribution outputted by the LSTM rather than taking the most probable word.\n",
    "\n",
    "It might be useful to take a look at the output of your model and (depending on your implementation) modify it so that the outputs sum to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat 1.\n",
      "a. Starting with `the`:\n",
      "\t the boy surfing and land front to down on a a woman green green a black <SOS> <SOS> a <EOS>\n",
      "\n",
      "b. Starting with `man`:\n",
      "\t man cellphone one one floating on toilet the a a <SOS> <SOS> <SOS> blue <SOS> motorcycle on standing having <SOS> out <SOS> a <SOS> <SOS> a woman <EOS>\n",
      "\n",
      "c. Starting with `woman`:\n",
      "\t woman skateboard sunglasses hanging woman standing doing a <SOS> <UNK> a <SOS> on <SOS> horse <SOS> a <SOS> a person pole woman <SOS> make <SOS> working holding with a baseball <SOS> two <SOS> shower top posing player <SOS> <SOS> filled a tree player sheep in two black <EOS>\n",
      "\n",
      "d. Starting with `dog`:\n",
      "\t dog <UNK> in down are food a a base <EOS>\n",
      "Repeat 2.\n",
      "a. Starting with `the`:\n",
      "\t the mounted and and soup with wooden of and a <SOS> a to a a elephant a <SOS> three <SOS> having branch salad bikes and and <UNK> standing on <UNK> <UNK> a of the <SOS> <SOS> woman a holding a of toilet bridge down a other plane tour male drives branch center and and <UNK> in motorcycle <EOS>\n",
      "\n",
      "b. Starting with `man`:\n",
      "\t man on broccoli skateboards lights different bottles video a a with <SOS> carrying signs <SOS> <SOS> <SOS> a <SOS> on sign <SOS> man two boy tracks bicycles stand <EOS>\n",
      "\n",
      "c. Starting with `woman`:\n",
      "\t woman while swinging sandwich standing of <UNK> skiing a <SOS> <EOS>\n",
      "\n",
      "d. Starting with `dog`:\n",
      "\t dog two posing with skiing blue side a a <SOS> a throwing <SOS> other a is woman in a elephant orange other <SOS> close a other sinks are people <UNK> with people one on on a <SOS> blue the <SOS> <SOS> <SOS> laptops a a light other video from sinks drives sinks cement girl <EOS>\n",
      "Repeat 3.\n",
      "a. Starting with `the`:\n",
      "\t the other that orange wrapped and reading <UNK> <SOS> a a <UNK> <EOS>\n",
      "\n",
      "b. Starting with `man`:\n",
      "\t man with <UNK> screen rice and standing pitcher woman a dock <SOS> a <SOS> <SOS> <SOS> bridge a <SOS> the <SOS> tricks a top decker foot fruits throw in <UNK> <EOS>\n",
      "\n",
      "c. Starting with `woman`:\n",
      "\t woman to the <EOS>\n",
      "\n",
      "d. Starting with `dog`:\n",
      "\t dog shown has one hanging <UNK> <UNK> lights <UNK> river <UNK> <SOS> several <SOS> a <SOS> on elephant <SOS> holding a background sides adults at <EOS>\n",
      "Repeat 4.\n",
      "a. Starting with `the`:\n",
      "\t the white dressed little ground <EOS>\n",
      "\n",
      "b. Starting with `man`:\n",
      "\t man front <UNK> <UNK> couple the on laptop <SOS> a <SOS> trail decker veggies a <SOS> sunny <EOS>\n",
      "\n",
      "c. Starting with `woman`:\n",
      "\t woman that ski something <EOS>\n",
      "\n",
      "d. Starting with `dog`:\n",
      "\t dog that <UNK> <EOS>\n",
      "Repeat 5.\n",
      "a. Starting with `the`:\n",
      "\t the red player little <UNK> cows <EOS>\n",
      "\n",
      "b. Starting with `man`:\n",
      "\t man zebras <UNK> long branch glasses on <UNK> oven a wooden a woman <SOS> holding a <SOS> holding <SOS> ski player <SOS> <SOS> holding his desk <SOS> out <SOS> legs brown a next stopped <UNK> match with with in street a <UNK> on sheep cross on a player cement ground she sign light cut tie <UNK> winter from get with next tennis <SOS> vases <SOS> <SOS> <UNK> two the park four middle of big next a <SOS> lights <UNK> desk <SOS> <SOS> a of <SOS> piece square two <SOS> a player red table table of truck holding holding cross two large tall baseball through with a <UNK> two get of video from two next sitting surfboard with <SOS> woman slope a <SOS> truck out are two a a sheep bowls having tarmac with are all parked in <SOS> a a plate <SOS> <SOS> racket lady <SOS> floors orange that <UNK> lady on platform people with two on on on <SOS> with side woman and have other that brushing two <SOS> slice bow on motorcycle two a in laptop bridge couple path on from with that an the with and on <UNK> <SOS> a <UNK> very pole a is man man <UNK> two on <EOS>\n",
      "\n",
      "c. Starting with `woman`:\n",
      "\t woman walking <UNK> <UNK> hit <EOS>\n",
      "\n",
      "d. Starting with `dog`:\n",
      "\t dog in to one that a <UNK> <SOS> a <SOS> snow wood <SOS> <SOS> <SOS> covered woman on <UNK> a is <SOS> the two served bun single is are standing are open the a couple a adults with <SOS> <SOS> <SOS> <UNK> <SOS> man of of <SOS> body a other trail shirt <UNK> <SOS> sides holding signs woman two carrying a up light in laying <EOS>\n"
     ]
    }
   ],
   "source": [
    "def sampling_inference(decoder, init_word, embeddings=one_hot_embeddings, max_length=maxSequenceLength):\n",
    "    # Your code goes here\n",
    "    \n",
    "    # Initialize\n",
    "    sentence_word_list = []\n",
    "    predicted_word_index = word2index[init_word]\n",
    "    sentence_word_list.append(vocabulary[predicted_word_index])\n",
    "    prev_hidden = (decoder.initHidden(), decoder.initHidden())\n",
    "    \n",
    "    # Convert to one hot\n",
    "    one_hot = embeddings[predicted_word_index]\n",
    "    decoder_input = torch.from_numpy(one_hot)\n",
    "    decoder_input = Variable(decoder_input).double().cuda()\n",
    "    \n",
    "    while predicted_word_index != word2index['<EOS>']:\n",
    "        # prediction\n",
    "        decoder_input = decoder_input.view(1, 1, vocabularySize)\n",
    "        decoder_output, prev_hidden = decoder(decoder_input, prev_hidden)\n",
    "        \n",
    "        # Process output\n",
    "        _numpy_array = decoder_output.squeeze().data.cpu().numpy()\n",
    "        probs = np.exp(_numpy_array) # original output was LogSoftmax, apply exp() to get probs\n",
    "        assert(np.isclose(np.sum(probs), 1.0)) # assert that probability sums to 1\n",
    "        \n",
    "        # Sample for a word according to probs\n",
    "        cdf = np.cumsum(probs) # Cumulative sum on probs to produce CDF\n",
    "        uniform_sample = np.random.uniform()\n",
    "        for _index, item in enumerate(cdf):\n",
    "            if uniform_sample > item and uniform_sample <= cdf[_index+1]:\n",
    "                # This is ok, because we'll never get to the last item in cdf\n",
    "                sentence_word_list.append(vocabulary[_index])\n",
    "                predicted_word_index = _index\n",
    "                break\n",
    "                \n",
    "        # Package input for next loop\n",
    "        decoder_input = torch.from_numpy(embeddings[predicted_word_index])\n",
    "        decoder_input = Variable(decoder_input).double().cuda()\n",
    "    \n",
    "    return ' '.join(sentence_word_list)\n",
    "\n",
    "# Print the results with sampling_inference by drawing 5 samples per initial word, requiring to run \n",
    "# the code below 5 times\n",
    "for repeat in range(1, 5+1):\n",
    "    print('Repeat {}.'.format(repeat))\n",
    "    print('a. Starting with `the`:')\n",
    "    print('\\t %s' % sampling_inference(decoder, init_word=\"the\"))\n",
    "    print('\\nb. Starting with `man`:')\n",
    "    print('\\t %s' % sampling_inference(decoder, init_word=\"man\"))\n",
    "    print('\\nc. Starting with `woman`:')\n",
    "    print('\\t %s' % sampling_inference(decoder, init_word=\"woman\"))\n",
    "    print('\\nd. Starting with `dog`:')\n",
    "    print('\\t %s' % sampling_inference(decoder, init_word=\"dog\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.  Building Language Encoder\n",
    "\n",
    "We now build a language encoder, which will encode an input word by word, and ultimately output a hidden state that we can then be used by our decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    # Your code goes here\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size).double().cuda()\n",
    "\n",
    "    def forward(self, input, hidden_in):\n",
    "        _, hidden_out = self.lstm(input, hidden_in) # encoder only outputs hidden\n",
    "        return hidden_out\n",
    "    \n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        return result.double().cuda()\n",
    "        \n",
    "# Initialize the encoder with a hidden size of 300. \n",
    "encoder = EncoderLSTM(1000, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Connecting Encoder to Decoder and Training End-to-End\n",
    "\n",
    "We now connect our newly created encoder with our decoder, to train an end-to-end seq2seq architecture. \n",
    "\n",
    "It's likely that you'll be able to re-use most of your code from part 2. For our purposes, the only interaction between the encoder and the decoder is that the *last hidden state of the encoder is used as the initial hidden state of the decoder*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with old decoder\n",
    "decoder = DecoderLSTM(vocabularySize, 300, vocabularySize)\n",
    "decoder.load_state_dict(torch.load('./model/decoder_noEOS_414000_3_66'))\n",
    "\n",
    "# Initialize encoder\n",
    "encoder = EncoderLSTM(1000, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 11s (- 494m 51s) (1000 0%) 3.7468\n",
      "2m 20s (- 481m 49s) (2000 0%) 3.8289\n",
      "3m 30s (- 480m 45s) (3000 0%) 3.8144\n",
      "4m 39s (- 477m 43s) (4000 0%) 3.7436\n",
      "5m 46s (- 472m 7s) (5000 1%) 3.6125\n",
      "6m 53s (- 468m 21s) (6000 1%) 3.5653\n",
      "8m 0s (- 465m 56s) (7000 1%) 3.5430\n",
      "9m 7s (- 463m 27s) (8000 1%) 3.4199\n",
      "10m 14s (- 460m 53s) (9000 2%) 3.3200\n",
      "11m 23s (- 460m 3s) (10000 2%) 3.3572\n",
      "12m 32s (- 459m 29s) (11000 2%) 3.2435\n",
      "13m 42s (- 459m 30s) (12000 2%) 3.2991\n",
      "14m 51s (- 458m 36s) (13000 3%) 3.1864\n",
      "16m 2s (- 458m 22s) (14000 3%) 3.0665\n",
      "17m 8s (- 456m 11s) (15000 3%) 3.1133\n",
      "18m 16s (- 454m 35s) (16000 3%) 2.9929\n",
      "19m 23s (- 452m 49s) (17000 4%) 3.0342\n",
      "20m 28s (- 450m 44s) (18000 4%) 2.8683\n",
      "21m 37s (- 449m 35s) (19000 4%) 2.9113\n",
      "22m 44s (- 448m 17s) (20000 4%) 2.8265\n",
      "23m 53s (- 447m 16s) (21000 5%) 2.8179\n",
      "25m 2s (- 446m 19s) (22000 5%) 2.7092\n",
      "26m 9s (- 444m 49s) (23000 5%) 2.6536\n",
      "27m 19s (- 444m 6s) (24000 5%) 2.6802\n",
      "28m 27s (- 442m 59s) (25000 6%) 2.7522\n",
      "29m 35s (- 441m 40s) (26000 6%) 2.6193\n",
      "30m 43s (- 440m 26s) (27000 6%) 2.4821\n",
      "31m 51s (- 439m 19s) (28000 6%) 2.4828\n",
      "32m 59s (- 438m 6s) (29000 7%) 2.4460\n",
      "34m 6s (- 436m 40s) (30000 7%) 2.4672\n",
      "35m 13s (- 435m 16s) (31000 7%) 2.4146\n",
      "36m 19s (- 433m 49s) (32000 7%) 2.3047\n",
      "37m 28s (- 432m 45s) (33000 7%) 2.4699\n",
      "38m 34s (- 431m 18s) (34000 8%) 2.6220\n",
      "39m 43s (- 430m 22s) (35000 8%) 2.6395\n",
      "40m 54s (- 429m 38s) (36000 8%) 2.5224\n",
      "42m 1s (- 428m 18s) (37000 8%) 2.3890\n",
      "43m 8s (- 426m 58s) (38000 9%) 2.2933\n",
      "44m 15s (- 425m 47s) (39000 9%) 2.2900\n",
      "45m 24s (- 424m 45s) (40000 9%) 2.2299\n",
      "46m 32s (- 423m 32s) (41000 9%) 2.1492\n",
      "47m 40s (- 422m 23s) (42000 10%) 2.1566\n",
      "48m 49s (- 421m 26s) (43000 10%) 2.1928\n",
      "49m 59s (- 420m 33s) (44000 10%) 2.1420\n",
      "51m 9s (- 419m 37s) (45000 10%) 2.0944\n",
      "52m 18s (- 418m 40s) (46000 11%) 2.1529\n",
      "53m 27s (- 417m 35s) (47000 11%) 1.9253\n",
      "54m 36s (- 416m 30s) (48000 11%) 2.0626\n",
      "55m 44s (- 415m 22s) (49000 11%) 2.0440\n",
      "56m 52s (- 414m 13s) (50000 12%) 1.9605\n",
      "58m 0s (- 413m 1s) (51000 12%) 1.8978\n",
      "59m 9s (- 411m 57s) (52000 12%) 1.8067\n",
      "60m 17s (- 410m 51s) (53000 12%) 1.7330\n",
      "61m 24s (- 409m 33s) (54000 13%) 1.7978\n",
      "62m 31s (- 408m 14s) (55000 13%) 1.7843\n",
      "63m 37s (- 406m 51s) (56000 13%) 1.7098\n",
      "64m 45s (- 405m 44s) (57000 13%) 1.6992\n",
      "65m 53s (- 404m 36s) (58000 14%) 1.7258\n",
      "67m 0s (- 403m 23s) (59000 14%) 1.6701\n",
      "68m 8s (- 402m 11s) (60000 14%) 1.6403\n",
      "69m 16s (- 401m 2s) (61000 14%) 1.6023\n",
      "70m 23s (- 399m 48s) (62000 14%) 1.5512\n",
      "71m 31s (- 398m 40s) (63000 15%) 1.6019\n",
      "72m 38s (- 397m 25s) (64000 15%) 1.5514\n",
      "73m 46s (- 396m 19s) (65000 15%) 1.5115\n",
      "74m 54s (- 395m 8s) (66000 15%) 1.7067\n",
      "76m 1s (- 393m 52s) (67000 16%) 1.7098\n",
      "77m 8s (- 392m 39s) (68000 16%) 1.7048\n",
      "78m 16s (- 391m 31s) (69000 16%) 1.6465\n",
      "79m 23s (- 390m 20s) (70000 16%) 1.5692\n",
      "80m 31s (- 389m 12s) (71000 17%) 1.4970\n",
      "81m 39s (- 388m 0s) (72000 17%) 1.4406\n",
      "82m 46s (- 386m 49s) (73000 17%) 1.4726\n",
      "83m 52s (- 385m 33s) (74000 17%) 1.3641\n",
      "84m 59s (- 384m 21s) (75000 18%) 1.4404\n",
      "86m 8s (- 383m 14s) (76000 18%) 1.4155\n",
      "87m 16s (- 382m 9s) (77000 18%) 1.3518\n",
      "88m 24s (- 380m 58s) (78000 18%) 1.3179\n",
      "89m 31s (- 379m 49s) (79000 19%) 1.2999\n",
      "90m 40s (- 378m 44s) (80000 19%) 1.3300\n",
      "91m 48s (- 377m 35s) (81000 19%) 1.2178\n",
      "92m 56s (- 376m 28s) (82000 19%) 1.2914\n",
      "94m 4s (- 375m 19s) (83000 20%) 1.2212\n",
      "95m 11s (- 374m 8s) (84000 20%) 1.1924\n",
      "96m 20s (- 373m 3s) (85000 20%) 1.1718\n",
      "97m 28s (- 371m 53s) (86000 20%) 1.2206\n",
      "98m 34s (- 370m 41s) (87000 21%) 1.2001\n",
      "99m 41s (- 369m 26s) (88000 21%) 1.1671\n",
      "100m 47s (- 368m 14s) (89000 21%) 1.1232\n",
      "101m 53s (- 366m 59s) (90000 21%) 1.1743\n",
      "103m 0s (- 365m 46s) (91000 21%) 1.1505\n",
      "104m 8s (- 364m 39s) (92000 22%) 1.1125\n",
      "105m 15s (- 363m 26s) (93000 22%) 1.0668\n",
      "106m 21s (- 362m 13s) (94000 22%) 0.9880\n",
      "107m 28s (- 361m 2s) (95000 22%) 1.0030\n",
      "108m 34s (- 359m 50s) (96000 23%) 1.0844\n",
      "109m 42s (- 358m 41s) (97000 23%) 1.0168\n",
      "110m 50s (- 357m 33s) (98000 23%) 0.9744\n",
      "111m 56s (- 356m 21s) (99000 23%) 1.1901\n",
      "113m 2s (- 355m 5s) (100000 24%) 1.2087\n",
      "114m 8s (- 353m 54s) (101000 24%) 1.2026\n",
      "115m 16s (- 352m 47s) (102000 24%) 1.2045\n",
      "116m 23s (- 351m 35s) (103000 24%) 1.1113\n",
      "117m 30s (- 350m 24s) (104000 25%) 1.0847\n",
      "118m 38s (- 349m 19s) (105000 25%) 1.0986\n",
      "119m 47s (- 348m 14s) (106000 25%) 1.0173\n",
      "120m 55s (- 347m 7s) (107000 25%) 0.9903\n",
      "122m 4s (- 346m 1s) (108000 26%) 1.0706\n",
      "123m 12s (- 344m 55s) (109000 26%) 0.9947\n",
      "124m 20s (- 343m 49s) (110000 26%) 1.0295\n",
      "125m 29s (- 342m 43s) (111000 26%) 0.9890\n",
      "126m 35s (- 341m 31s) (112000 27%) 0.9413\n",
      "127m 42s (- 340m 20s) (113000 27%) 1.0160\n",
      "128m 48s (- 339m 8s) (114000 27%) 0.9249\n",
      "129m 56s (- 338m 0s) (115000 27%) 0.9261\n",
      "131m 4s (- 336m 53s) (116000 28%) 0.8688\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-82ab00dfb971>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[0minput_sentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_sentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabularySize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[0minput_sentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_sentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_sentence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[0mprint_loss_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-50-82ab00dfb971>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(target_variable, encoder, encoder_optimizer, decoder, decoder_optimizer, criterion, embeddings)\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;31m#   break\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0mdecoder_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\variable.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[0;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \"\"\"\n\u001b[1;32m--> 167\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m---> 99\u001b[1;33m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "\n",
    "# Helper to flip a tensor\n",
    "# Taken from: https://github.com/pytorch/pytorch/issues/229\n",
    "def flip(x, dim):\n",
    "    xsize = x.size()\n",
    "    dim = x.dim() + dim if dim < 0 else dim\n",
    "    x = x.view(-1, *xsize[dim:])\n",
    "    x = x.view(x.size(0), x.size(1), -1)[:, getattr(torch.arange(x.size(1)-1, \n",
    "                      -1, -1), ('cpu','cuda')[x.is_cuda])().long(), :]\n",
    "    return x.view(xsize)\n",
    "\n",
    "# One training step\n",
    "def train(target_variable,\n",
    "          encoder,\n",
    "          encoder_optimizer,\n",
    "          decoder,\n",
    "          decoder_optimizer, \n",
    "          criterion, \n",
    "          embeddings=one_hot_embeddings):\n",
    "    \n",
    "    # Some initilization\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    # target_variable has (batch_size, n_words, n_vocab)\n",
    "    # Without minibatch, this is just one sentence\n",
    "    target_length = target_variable.size()[1]\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    # Reverse input sentence to help training\n",
    "    # For performance, don't actually do this, just reverse in loop\n",
    "    # flipped_target = flip(target_variable, 1)\n",
    "    \n",
    "    # Encoder is fed from the flipped sentence\n",
    "    encoder_input = target_variable[0][-1] # Starting from last\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    encoder_hidden = (encoder_hidden, encoder_hidden) # Need a tuple\n",
    "    \n",
    "    # Feeding encoder in a loop, in reverse order\n",
    "    # Starting from length - 2, since we set the last word above.\n",
    "    # Ending on index=1 to skip SOS as suggested in handout \n",
    "    for index_word in np.arange(target_length-2, 0, -1):\n",
    "        encoder_input = encoder_input.view(1, 1, vocabularySize)\n",
    "        encoder_hidden = encoder(encoder_input, encoder_hidden) # Gets hidden for next input    \n",
    "        # Get input for next loop from sentence\n",
    "        encoder_input = target_variable[0][index_word]\n",
    "    \n",
    "    # Do the same as part 2 for decoder, but feed encoder_hidden instead\n",
    "    decoder_input = target_variable[0][0]\n",
    "    decoder_hidden = encoder_hidden\n",
    "    predicted_word_index = 0\n",
    "    \n",
    "    for index_word in range(1, target_length):\n",
    "        decoder_input = decoder_input.view(1, 1, vocabularySize)\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        \n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        predicted_word_index = int(topi[0][0][0])\n",
    "\n",
    "        # This is the next input, without teacher forcing it's the predicted output\n",
    "        decoder_input = torch.from_numpy(embeddings[predicted_word_index])\n",
    "        decoder_input = Variable(decoder_input).cuda()\n",
    "        \n",
    "        # This is just to conform with the pytorch format..\n",
    "        # CrossEntropyLoss takes input1: (N, C) and input2: (N).\n",
    "        _, actual_word_index = target_variable[0][index_word].data.topk(1)\n",
    "        actual_word_index = Variable(actual_word_index)\n",
    "\n",
    "        # Compare current output to next \"target\" input\n",
    "        loss += criterion(decoder_output.view(1, decoder_output.size(2)), actual_word_index)\n",
    "        \n",
    "        # Stop on EOS\n",
    "        # Saw training went better without this\n",
    "        # if predicted_word_index == word2index['<EOS>']:\n",
    "        #   break\n",
    "            \n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    # index_word keeps track of the current word\n",
    "    # in case of break (EOS) and non-break (teacher-forcing), it'll be the actually count.\n",
    "    return loss.data[0] / index_word\n",
    "\n",
    "    \n",
    "    \n",
    "# Train the model and monitor the loss. Remember to use Adam optimizer and CrossEntropyLoss\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=0.0001)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=0.0001)\n",
    "criterion = nn.NLLLoss()  # Since my DecoderLSTM has LogSoftmax as final layer, use NLL loss here\n",
    "\n",
    "n_iters = len(train_sentences)\n",
    "print_every = 1000\n",
    "print_loss_total = 0\n",
    "start = time.time()\n",
    "\n",
    "for s_index in range(1, n_iters):\n",
    "    input_sentence = preprocess_one_hot(train_sentences[s_index])\n",
    "    n_words = input_sentence.shape[0]\n",
    "    input_sentence = torch.from_numpy(input_sentence)\n",
    "    input_sentence = input_sentence.view(1, n_words, vocabularySize)\n",
    "    input_sentence = Variable(input_sentence).cuda()\n",
    "    loss = train(input_sentence, encoder, encoder_optimizer, decoder, decoder_optimizer, criterion)\n",
    "    \n",
    "    print_loss_total += loss\n",
    "    \n",
    "    if s_index % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(start, s_index / n_iters),\n",
    "                                     s_index, s_index / n_iters * 100, print_loss_avg))\n",
    "\n",
    "\"\"\"Second part of training continued two blocks below\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Models\n",
    "    1. './model/q6_encoder_116000' and './model/q6_decoder_116000'\n",
    "    2. './model/q6_encoder_414000' and './model/q6_decoder_414000'\n",
    "\"\"\"\n",
    "torch.save(encoder.state_dict(), PATH)\n",
    "torch.save(decoder.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407m 44s (- 1035m 31s) (117000 28%) 0.9769\n",
      "408m 50s (- 1026m 4s) (118000 28%) 0.9136\n",
      "409m 57s (- 1016m 46s) (119000 28%) 0.9372\n",
      "411m 4s (- 1007m 36s) (120000 28%) 0.8595\n",
      "412m 9s (- 998m 31s) (121000 29%) 0.8594\n",
      "413m 16s (- 989m 37s) (122000 29%) 0.7968\n",
      "414m 22s (- 980m 50s) (123000 29%) 0.8755\n",
      "415m 28s (- 972m 10s) (124000 29%) 0.7949\n",
      "416m 35s (- 963m 37s) (125000 30%) 0.8322\n",
      "417m 42s (- 955m 13s) (126000 30%) 0.7951\n",
      "418m 48s (- 946m 54s) (127000 30%) 0.7101\n",
      "419m 55s (- 938m 44s) (128000 30%) 0.7804\n",
      "421m 1s (- 930m 38s) (129000 31%) 0.8360\n",
      "422m 7s (- 922m 39s) (130000 31%) 0.7915\n",
      "423m 14s (- 914m 48s) (131000 31%) 0.7375\n",
      "424m 20s (- 907m 0s) (132000 31%) 0.9024\n",
      "425m 27s (- 899m 21s) (133000 32%) 0.8803\n",
      "426m 35s (- 891m 49s) (134000 32%) 0.8844\n",
      "427m 46s (- 884m 30s) (135000 32%) 0.8683\n",
      "428m 53s (- 877m 9s) (136000 32%) 0.8002\n",
      "430m 1s (- 869m 54s) (137000 33%) 0.8113\n",
      "431m 10s (- 862m 48s) (138000 33%) 0.7579\n",
      "432m 17s (- 855m 42s) (139000 33%) 0.7481\n",
      "433m 24s (- 848m 40s) (140000 33%) 0.6547\n",
      "434m 31s (- 841m 46s) (141000 34%) 0.7829\n",
      "435m 39s (- 834m 57s) (142000 34%) 0.7251\n",
      "436m 47s (- 828m 12s) (143000 34%) 0.7392\n",
      "437m 56s (- 821m 35s) (144000 34%) 0.7066\n",
      "439m 4s (- 814m 59s) (145000 35%) 0.7253\n",
      "440m 10s (- 808m 26s) (146000 35%) 0.6992\n",
      "441m 17s (- 801m 56s) (147000 35%) 0.7219\n",
      "442m 24s (- 795m 33s) (148000 35%) 0.7345\n",
      "443m 33s (- 789m 18s) (149000 35%) 0.6912\n",
      "444m 41s (- 783m 5s) (150000 36%) 0.6353\n",
      "445m 51s (- 776m 58s) (151000 36%) 0.6572\n",
      "446m 59s (- 770m 53s) (152000 36%) 0.7060\n",
      "448m 6s (- 764m 50s) (153000 36%) 0.6325\n",
      "449m 13s (- 758m 51s) (154000 37%) 0.6261\n",
      "450m 21s (- 752m 57s) (155000 37%) 0.6563\n",
      "451m 29s (- 747m 6s) (156000 37%) 0.6687\n",
      "452m 35s (- 741m 16s) (157000 37%) 0.6275\n",
      "453m 42s (- 735m 31s) (158000 38%) 0.6387\n",
      "454m 48s (- 729m 49s) (159000 38%) 0.6033\n",
      "455m 54s (- 724m 9s) (160000 38%) 0.5508\n",
      "457m 1s (- 718m 34s) (161000 38%) 0.5988\n",
      "458m 8s (- 713m 3s) (162000 39%) 0.5923\n",
      "459m 15s (- 707m 35s) (163000 39%) 0.5853\n",
      "460m 23s (- 702m 12s) (164000 39%) 0.6162\n",
      "461m 29s (- 696m 50s) (165000 39%) 0.7972\n",
      "462m 37s (- 691m 33s) (166000 40%) 0.7822\n",
      "463m 46s (- 686m 20s) (167000 40%) 0.7574\n",
      "464m 53s (- 681m 8s) (168000 40%) 0.7538\n",
      "466m 0s (- 675m 58s) (169000 40%) 0.6909\n",
      "467m 9s (- 670m 53s) (170000 41%) 0.6972\n",
      "468m 15s (- 665m 48s) (171000 41%) 0.6581\n",
      "469m 21s (- 660m 45s) (172000 41%) 0.6056\n",
      "470m 27s (- 655m 46s) (173000 41%) 0.6952\n",
      "471m 35s (- 650m 51s) (174000 42%) 0.7127\n",
      "472m 43s (- 646m 0s) (175000 42%) 0.6479\n",
      "473m 52s (- 641m 11s) (176000 42%) 0.6726\n",
      "474m 59s (- 636m 23s) (177000 42%) 0.5874\n",
      "476m 6s (- 631m 37s) (178000 42%) 0.6357\n",
      "477m 13s (- 626m 54s) (179000 43%) 0.6030\n",
      "478m 21s (- 622m 14s) (180000 43%) 0.6375\n",
      "479m 29s (- 617m 38s) (181000 43%) 0.6408\n",
      "480m 35s (- 613m 0s) (182000 43%) 0.5447\n",
      "481m 42s (- 608m 26s) (183000 44%) 0.6053\n",
      "482m 52s (- 603m 57s) (184000 44%) 0.5916\n",
      "483m 58s (- 599m 27s) (185000 44%) 0.5607\n",
      "485m 5s (- 595m 0s) (186000 44%) 0.5378\n",
      "486m 12s (- 590m 34s) (187000 45%) 0.5507\n",
      "487m 19s (- 586m 11s) (188000 45%) 0.5550\n",
      "488m 27s (- 581m 52s) (189000 45%) 0.6251\n",
      "489m 34s (- 577m 32s) (190000 45%) 0.5516\n",
      "490m 40s (- 573m 14s) (191000 46%) 0.5294\n",
      "491m 47s (- 568m 59s) (192000 46%) 0.5119\n",
      "492m 54s (- 564m 47s) (193000 46%) 0.5143\n",
      "494m 1s (- 560m 35s) (194000 46%) 0.5313\n",
      "495m 8s (- 556m 26s) (195000 47%) 0.5528\n",
      "496m 15s (- 552m 19s) (196000 47%) 0.4971\n",
      "497m 21s (- 548m 12s) (197000 47%) 0.6491\n",
      "498m 26s (- 544m 7s) (198000 47%) 0.6421\n",
      "499m 32s (- 540m 4s) (199000 48%) 0.6200\n",
      "500m 40s (- 536m 5s) (200000 48%) 0.6089\n",
      "501m 47s (- 532m 6s) (201000 48%) 0.5923\n",
      "502m 55s (- 528m 10s) (202000 48%) 0.5864\n",
      "504m 2s (- 524m 15s) (203000 49%) 0.5145\n",
      "505m 7s (- 520m 20s) (204000 49%) 0.5643\n",
      "506m 12s (- 516m 25s) (205000 49%) 0.4763\n",
      "507m 18s (- 512m 35s) (206000 49%) 0.5087\n",
      "508m 25s (- 508m 46s) (207000 49%) 0.5524\n",
      "509m 33s (- 505m 0s) (208000 50%) 0.5259\n",
      "510m 41s (- 501m 15s) (209000 50%) 0.5139\n",
      "511m 47s (- 497m 31s) (210000 50%) 0.4582\n",
      "512m 53s (- 493m 47s) (211000 50%) 0.4570\n",
      "513m 58s (- 490m 4s) (212000 51%) 0.4632\n",
      "515m 5s (- 486m 25s) (213000 51%) 0.5039\n",
      "516m 12s (- 482m 46s) (214000 51%) 0.4492\n",
      "517m 18s (- 479m 9s) (215000 51%) 0.4511\n",
      "518m 25s (- 475m 34s) (216000 52%) 0.4642\n",
      "519m 32s (- 471m 59s) (217000 52%) 0.4525\n",
      "520m 37s (- 468m 25s) (218000 52%) 0.3993\n",
      "521m 44s (- 464m 54s) (219000 52%) 0.4268\n",
      "522m 51s (- 461m 24s) (220000 53%) 0.4359\n",
      "523m 58s (- 457m 55s) (221000 53%) 0.4798\n",
      "525m 8s (- 454m 31s) (222000 53%) 0.4868\n",
      "526m 14s (- 451m 4s) (223000 53%) 0.4095\n",
      "527m 21s (- 447m 38s) (224000 54%) 0.3593\n",
      "528m 28s (- 444m 15s) (225000 54%) 0.4176\n",
      "529m 35s (- 440m 53s) (226000 54%) 0.4236\n",
      "530m 40s (- 437m 30s) (227000 54%) 0.3841\n",
      "531m 46s (- 434m 8s) (228000 55%) 0.3916\n",
      "532m 52s (- 430m 49s) (229000 55%) 0.4129\n",
      "533m 59s (- 427m 31s) (230000 55%) 0.6516\n",
      "535m 5s (- 424m 13s) (231000 55%) 0.6724\n",
      "536m 12s (- 420m 58s) (232000 56%) 0.6765\n",
      "537m 21s (- 417m 45s) (233000 56%) 0.6647\n",
      "538m 27s (- 414m 32s) (234000 56%) 0.5536\n",
      "539m 35s (- 411m 19s) (235000 56%) 0.5760\n",
      "540m 41s (- 408m 8s) (236000 56%) 0.5259\n",
      "541m 50s (- 404m 59s) (237000 57%) 0.5712\n",
      "542m 56s (- 401m 49s) (238000 57%) 0.4838\n",
      "544m 3s (- 398m 41s) (239000 57%) 0.5044\n",
      "545m 10s (- 395m 34s) (240000 57%) 0.5221\n",
      "546m 17s (- 392m 28s) (241000 58%) 0.4950\n",
      "547m 24s (- 389m 23s) (242000 58%) 0.4979\n",
      "548m 31s (- 386m 19s) (243000 58%) 0.4709\n",
      "549m 36s (- 383m 14s) (244000 58%) 0.4925\n",
      "550m 42s (- 380m 11s) (245000 59%) 0.4975\n",
      "551m 49s (- 377m 10s) (246000 59%) 0.5024\n",
      "552m 56s (- 374m 9s) (247000 59%) 0.4277\n",
      "554m 2s (- 371m 10s) (248000 59%) 0.4264\n",
      "555m 10s (- 368m 12s) (249000 60%) 0.4573\n",
      "556m 16s (- 365m 14s) (250000 60%) 0.4365\n",
      "557m 24s (- 362m 17s) (251000 60%) 0.4096\n",
      "558m 29s (- 359m 21s) (252000 60%) 0.3977\n",
      "559m 36s (- 356m 25s) (253000 61%) 0.4463\n",
      "560m 42s (- 353m 30s) (254000 61%) 0.4266\n",
      "561m 48s (- 350m 37s) (255000 61%) 0.4403\n",
      "562m 55s (- 347m 44s) (256000 61%) 0.4241\n",
      "564m 1s (- 344m 52s) (257000 62%) 0.3731\n",
      "565m 8s (- 342m 1s) (258000 62%) 0.3760\n",
      "566m 16s (- 339m 12s) (259000 62%) 0.4108\n",
      "567m 22s (- 336m 22s) (260000 62%) 0.3940\n",
      "568m 29s (- 333m 33s) (261000 63%) 0.3795\n",
      "569m 36s (- 330m 45s) (262000 63%) 0.3574\n",
      "570m 42s (- 327m 58s) (263000 63%) 0.5393\n",
      "571m 50s (- 325m 13s) (264000 63%) 0.4830\n",
      "572m 58s (- 322m 28s) (265000 63%) 0.5286\n",
      "574m 7s (- 319m 44s) (266000 64%) 0.4669\n",
      "575m 14s (- 317m 1s) (267000 64%) 0.4392\n",
      "576m 21s (- 314m 17s) (268000 64%) 0.4200\n",
      "577m 28s (- 311m 35s) (269000 64%) 0.4201\n",
      "578m 34s (- 308m 53s) (270000 65%) 0.3672\n",
      "579m 40s (- 306m 11s) (271000 65%) 0.3584\n",
      "580m 47s (- 303m 30s) (272000 65%) 0.4301\n",
      "581m 54s (- 300m 51s) (273000 65%) 0.3954\n",
      "583m 3s (- 298m 12s) (274000 66%) 0.4124\n",
      "584m 11s (- 295m 34s) (275000 66%) 0.3932\n",
      "585m 18s (- 292m 57s) (276000 66%) 0.3748\n",
      "586m 25s (- 290m 20s) (277000 66%) 0.3642\n",
      "587m 32s (- 287m 44s) (278000 67%) 0.3991\n",
      "588m 40s (- 285m 8s) (279000 67%) 0.4153\n",
      "589m 48s (- 282m 33s) (280000 67%) 0.3463\n",
      "590m 56s (- 280m 0s) (281000 67%) 0.3302\n",
      "592m 4s (- 277m 26s) (282000 68%) 0.3330\n",
      "593m 12s (- 274m 53s) (283000 68%) 0.3526\n",
      "594m 19s (- 272m 20s) (284000 68%) 0.3097\n",
      "595m 26s (- 269m 48s) (285000 68%) 0.3359\n",
      "596m 33s (- 267m 17s) (286000 69%) 0.3205\n",
      "597m 41s (- 264m 46s) (287000 69%) 0.3704\n",
      "598m 47s (- 262m 16s) (288000 69%) 0.3343\n",
      "599m 53s (- 259m 46s) (289000 69%) 0.3136\n",
      "601m 0s (- 257m 16s) (290000 70%) 0.2993\n",
      "602m 7s (- 254m 48s) (291000 70%) 0.2988\n",
      "603m 14s (- 252m 19s) (292000 70%) 0.3181\n",
      "604m 19s (- 249m 51s) (293000 70%) 0.3555\n",
      "605m 26s (- 247m 24s) (294000 70%) 0.2821\n",
      "606m 33s (- 244m 58s) (295000 71%) 0.3286\n",
      "607m 40s (- 242m 32s) (296000 71%) 0.4459\n",
      "608m 47s (- 240m 7s) (297000 71%) 0.3850\n",
      "609m 57s (- 237m 43s) (298000 71%) 0.4179\n",
      "611m 6s (- 235m 19s) (299000 72%) 0.3798\n",
      "612m 14s (- 232m 56s) (300000 72%) 0.3656\n",
      "613m 22s (- 230m 33s) (301000 72%) 0.3579\n",
      "614m 30s (- 228m 11s) (302000 72%) 0.3417\n",
      "615m 37s (- 225m 49s) (303000 73%) 0.3284\n",
      "616m 44s (- 223m 27s) (304000 73%) 0.3069\n",
      "617m 51s (- 221m 5s) (305000 73%) 0.3782\n",
      "618m 59s (- 218m 45s) (306000 73%) 0.3225\n",
      "620m 9s (- 216m 25s) (307000 74%) 0.3804\n",
      "621m 17s (- 214m 6s) (308000 74%) 0.3055\n",
      "622m 25s (- 211m 47s) (309000 74%) 0.2889\n",
      "623m 31s (- 209m 28s) (310000 74%) 0.2936\n",
      "624m 39s (- 207m 9s) (311000 75%) 0.3278\n",
      "625m 46s (- 204m 52s) (312000 75%) 0.3416\n",
      "626m 53s (- 202m 34s) (313000 75%) 0.2883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "628m 0s (- 200m 17s) (314000 75%) 0.2868\n",
      "629m 8s (- 198m 0s) (315000 76%) 0.2989\n",
      "630m 15s (- 195m 44s) (316000 76%) 0.2603\n",
      "631m 23s (- 193m 29s) (317000 76%) 0.2775\n",
      "632m 31s (- 191m 14s) (318000 76%) 0.3101\n",
      "633m 38s (- 188m 59s) (319000 77%) 0.2968\n",
      "634m 46s (- 186m 44s) (320000 77%) 0.2970\n",
      "635m 53s (- 184m 30s) (321000 77%) 0.2841\n",
      "637m 0s (- 182m 17s) (322000 77%) 0.2380\n",
      "638m 9s (- 180m 4s) (323000 77%) 0.2447\n",
      "639m 16s (- 177m 51s) (324000 78%) 0.2483\n",
      "640m 24s (- 175m 39s) (325000 78%) 0.2836\n",
      "641m 31s (- 173m 27s) (326000 78%) 0.2999\n",
      "642m 39s (- 171m 15s) (327000 78%) 0.2522\n",
      "643m 46s (- 169m 4s) (328000 79%) 0.3578\n",
      "644m 53s (- 166m 53s) (329000 79%) 0.4271\n",
      "646m 1s (- 164m 43s) (330000 79%) 0.3970\n",
      "647m 11s (- 162m 33s) (331000 79%) 0.4297\n",
      "648m 21s (- 160m 24s) (332000 80%) 0.4335\n",
      "649m 29s (- 158m 15s) (333000 80%) 0.3287\n",
      "650m 36s (- 156m 6s) (334000 80%) 0.3383\n",
      "651m 43s (- 153m 58s) (335000 80%) 0.3112\n",
      "652m 52s (- 151m 50s) (336000 81%) 0.3589\n",
      "654m 0s (- 149m 42s) (337000 81%) 0.3008\n",
      "655m 9s (- 147m 35s) (338000 81%) 0.3729\n",
      "656m 18s (- 145m 28s) (339000 81%) 0.2989\n",
      "657m 27s (- 143m 22s) (340000 82%) 0.3407\n",
      "658m 36s (- 141m 16s) (341000 82%) 0.2929\n",
      "659m 44s (- 139m 10s) (342000 82%) 0.3103\n",
      "660m 51s (- 137m 4s) (343000 82%) 0.3146\n",
      "661m 58s (- 134m 58s) (344000 83%) 0.2945\n",
      "663m 6s (- 132m 53s) (345000 83%) 0.3391\n",
      "664m 14s (- 130m 49s) (346000 83%) 0.2701\n",
      "665m 22s (- 128m 44s) (347000 83%) 0.2957\n",
      "666m 31s (- 126m 41s) (348000 84%) 0.2791\n",
      "667m 41s (- 124m 37s) (349000 84%) 0.2852\n",
      "668m 50s (- 122m 34s) (350000 84%) 0.2679\n",
      "669m 58s (- 120m 31s) (351000 84%) 0.2678\n",
      "671m 7s (- 118m 28s) (352000 84%) 0.2863\n",
      "672m 15s (- 116m 26s) (353000 85%) 0.3024\n",
      "673m 24s (- 114m 24s) (354000 85%) 0.2962\n",
      "674m 30s (- 112m 22s) (355000 85%) 0.2425\n",
      "675m 37s (- 110m 20s) (356000 85%) 0.2737\n",
      "676m 46s (- 108m 19s) (357000 86%) 0.2780\n",
      "677m 53s (- 106m 18s) (358000 86%) 0.2977\n",
      "679m 0s (- 104m 17s) (359000 86%) 0.2504\n",
      "680m 7s (- 102m 17s) (360000 86%) 0.2449\n",
      "681m 15s (- 100m 17s) (361000 87%) 0.3430\n",
      "682m 21s (- 98m 17s) (362000 87%) 0.3104\n",
      "683m 29s (- 96m 17s) (363000 87%) 0.3342\n",
      "684m 37s (- 94m 18s) (364000 87%) 0.3100\n",
      "685m 44s (- 92m 19s) (365000 88%) 0.3000\n",
      "686m 51s (- 90m 20s) (366000 88%) 0.2698\n",
      "687m 59s (- 88m 22s) (367000 88%) 0.3073\n",
      "689m 6s (- 86m 24s) (368000 88%) 0.2749\n",
      "690m 13s (- 84m 26s) (369000 89%) 0.2542\n",
      "691m 20s (- 82m 28s) (370000 89%) 0.2699\n",
      "692m 29s (- 80m 31s) (371000 89%) 0.3138\n",
      "693m 37s (- 78m 34s) (372000 89%) 0.2703\n",
      "694m 45s (- 76m 38s) (373000 90%) 0.2741\n",
      "695m 52s (- 74m 41s) (374000 90%) 0.2607\n",
      "696m 58s (- 72m 45s) (375000 90%) 0.2440\n",
      "698m 4s (- 70m 48s) (376000 90%) 0.2531\n",
      "699m 12s (- 68m 53s) (377000 91%) 0.2666\n",
      "700m 19s (- 66m 57s) (378000 91%) 0.2667\n",
      "701m 26s (- 65m 2s) (379000 91%) 0.2435\n",
      "702m 34s (- 63m 7s) (380000 91%) 0.2767\n",
      "703m 42s (- 61m 12s) (381000 91%) 0.2527\n",
      "704m 48s (- 59m 18s) (382000 92%) 0.2227\n",
      "705m 54s (- 57m 23s) (383000 92%) 0.2259\n",
      "707m 1s (- 55m 29s) (384000 92%) 0.2232\n",
      "708m 9s (- 53m 36s) (385000 92%) 0.2472\n",
      "709m 16s (- 51m 42s) (386000 93%) 0.2738\n",
      "710m 22s (- 49m 49s) (387000 93%) 0.2500\n",
      "711m 29s (- 47m 56s) (388000 93%) 0.2144\n",
      "712m 35s (- 46m 3s) (389000 93%) 0.2150\n",
      "713m 41s (- 44m 10s) (390000 94%) 0.2168\n",
      "714m 48s (- 42m 18s) (391000 94%) 0.2514\n",
      "715m 54s (- 40m 26s) (392000 94%) 0.2509\n",
      "717m 2s (- 38m 34s) (393000 94%) 0.2495\n",
      "718m 9s (- 36m 42s) (394000 95%) 0.3190\n",
      "719m 16s (- 34m 51s) (395000 95%) 0.3274\n",
      "720m 25s (- 33m 0s) (396000 95%) 0.3253\n",
      "721m 31s (- 31m 9s) (397000 95%) 0.2730\n",
      "722m 38s (- 29m 18s) (398000 96%) 0.2734\n",
      "723m 44s (- 27m 28s) (399000 96%) 0.2506\n",
      "724m 51s (- 25m 37s) (400000 96%) 0.2895\n",
      "725m 58s (- 23m 47s) (401000 96%) 0.2646\n",
      "727m 4s (- 21m 57s) (402000 97%) 0.2445\n",
      "728m 11s (- 20m 8s) (403000 97%) 0.2547\n",
      "729m 18s (- 18m 18s) (404000 97%) 0.2864\n",
      "730m 25s (- 16m 29s) (405000 97%) 0.2591\n",
      "731m 33s (- 14m 40s) (406000 98%) 0.2394\n",
      "732m 40s (- 12m 51s) (407000 98%) 0.2248\n",
      "733m 46s (- 11m 2s) (408000 98%) 0.2416\n",
      "734m 53s (- 9m 14s) (409000 98%) 0.2699\n",
      "735m 59s (- 7m 26s) (410000 98%) 0.2317\n",
      "737m 6s (- 5m 38s) (411000 99%) 0.2242\n",
      "738m 12s (- 3m 50s) (412000 99%) 0.2238\n",
      "739m 18s (- 2m 2s) (413000 99%) 0.2391\n",
      "740m 25s (- 0m 15s) (414000 99%) 0.2201\n"
     ]
    }
   ],
   "source": [
    "for s_index in range(116001, n_iters):\n",
    "    input_sentence = preprocess_one_hot(train_sentences[s_index])\n",
    "    n_words = input_sentence.shape[0]\n",
    "    input_sentence = torch.from_numpy(input_sentence)\n",
    "    input_sentence = input_sentence.view(1, n_words, vocabularySize)\n",
    "    input_sentence = Variable(input_sentence).cuda()\n",
    "    loss = train(input_sentence, encoder, encoder_optimizer, decoder, decoder_optimizer, criterion)\n",
    "    \n",
    "    print_loss_total += loss\n",
    "    \n",
    "    if s_index % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(start, s_index / n_iters),\n",
    "                                     s_index, s_index / n_iters * 100, print_loss_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Testing \n",
    "\n",
    "We must now define a method that allows us to do inference using the seq2seq architecture. We then run the 500 validation captions through this method, and ultimately compare the **reference** and **generated** sentences using our **BLEU** similarity score method defined above, to identify the average BLEU score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A man and woman at a table with beer and wine.', 'A man speaking into a microphone on a stage with a bicycle and dressed in cyclist gear.', 'Four horses are skattered around a small water hole.', 'A man and a young girl playing Wii.', 'A boat home sitting on a river bay.', \"Several Tim's of mints are stacked up with a bottle that has several  clipped roses inside.\", 'Family at a pizza restaurant posing for a picture before meal.', 'Several mopeds are lined up along the side of a hotel parking lot.', 'A young man appears to be taking a break from the waves.', 'A baseball player standing next to home plate with a bat.']\n",
      "Variable containing:\n",
      "    0     0     0  ...      0     0     0\n",
      "    0     1     0  ...      0     0     0\n",
      "    0     0     0  ...      0     0     0\n",
      "       ...                    ...       \n",
      "    0     0     0  ...      0     0     0\n",
      "    0     0     1  ...      0     0     0\n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.cuda.DoubleTensor of size 14x1000 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Testing only \"\"\"\n",
    "print(val_sentences[0:10])\n",
    "numberized = preprocess_numberize(val_sentences[0])\n",
    "sentence = one_hot_embeddings[numberized]\n",
    "input_sentence = torch.from_numpy(sentence)\n",
    "input_sentence = Variable(input_sentence).double().cuda()\n",
    "print(input_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seq2seq_inference(sentence, encoder, decoder, embeddings=one_hot_embeddings, max_length=maxSequenceLength):\n",
    "    # Your code goes here\n",
    "    \n",
    "    # Some initialization\n",
    "    output_sentence = []\n",
    "    \n",
    "    # Assuming sentence is not already onehot\n",
    "    numberized = preprocess_numberize(sentence)\n",
    "    one_hot_sentence = embeddings[numberized]\n",
    "    sentence_length = one_hot_sentence.shape[0]\n",
    "    \n",
    "    # Convert everything pytorch Variable\n",
    "    input_sentence = torch.from_numpy(one_hot_sentence)\n",
    "    input_sentence = Variable(input_sentence).double().cuda()\n",
    "    \n",
    "    # Encoder\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    encoder_hidden = (encoder_hidden, encoder_hidden)\n",
    "    \n",
    "    for index_word in np.arange(sentence_length-1, 0, -1): # Skipping SOS, otherwise needs to be -1\n",
    "        encoder_input = input_sentence[index_word]\n",
    "        encoder_input = encoder_input.view(1, 1, vocabularySize)\n",
    "        encoder_hidden = encoder(encoder_input, encoder_hidden) # Gets hidden for next input\n",
    "        \n",
    "    # This point we have last encoder_hidden, feed into decoder\n",
    "    decoder_hidden = encoder_hidden\n",
    "    decoder_input = input_sentence[0] # Starting from SOS\n",
    "    predicted_word_index = word2index['<SOS>']\n",
    "    while predicted_word_index != word2index['<EOS>']:\n",
    "        decoder_input = decoder_input.view(1, 1, vocabularySize)\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        \n",
    "        # MAP inference\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        predicted_word_index = int(topi[0][0][0])\n",
    "        output_sentence.append(vocabulary[predicted_word_index])\n",
    "        \n",
    "        # This is the next input\n",
    "        decoder_input = torch.from_numpy(embeddings[predicted_word_index])\n",
    "        decoder_input = Variable(decoder_input).double().cuda()\n",
    "    \n",
    "    return ' '.join(output_sentence)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Just loading back saved model \"\"\"\n",
    "PATH = '<put in correct path when needed>'\n",
    "encoder = EncoderLSTM(1000, 300)\n",
    "encoder.load_state_dict(torch.load(PATH))\n",
    "decoder = DecoderLSTM(vocabularySize, 300, vocabularySize)\n",
    "decoder.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.\n",
      "\t Ref: A man and woman at a table with beer and wine.\n",
      "\t Pred: a a man and woman at a table with beer and wine . <EOS>\n",
      "2.\n",
      "\t Ref: A man speaking into a microphone on a stage with a bicycle and dressed in cyclist gear.\n",
      "\t Pred: a a man <UNK> into a <UNK> on a <UNK> with a <UNK> <UNK> dressed in <UNK> snow . <EOS>\n",
      "3.\n",
      "\t Ref: Four horses are skattered around a small water hole.\n",
      "\t Pred: the four horses are <UNK> around a small water rocks . <EOS>\n",
      "4.\n",
      "\t Ref: A man and a young girl playing Wii.\n",
      "\t Pred: a a man and a young girl playing wii . <EOS>\n",
      "5.\n",
      "\t Ref: A boat home sitting on a river bay.\n",
      "\t Pred: a a boat laptop sitting on a river <UNK> . <EOS>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belin\\Anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.\n",
      "\t Ref: Several Tim's of mints are stacked up with a bottle that has several  clipped roses inside.\n",
      "\t Pred: a basket <UNK> that of <UNK> are seen up a a bottle that has <UNK> <UNK> and two vase . <EOS>\n",
      "7.\n",
      "\t Ref: Family at a pizza restaurant posing for a picture before meal.\n",
      "\t Pred: a family at a restaurant restaurant posing for a picture for meal . <EOS>\n",
      "8.\n",
      "\t Ref: Several mopeds are lined up along the side of a hotel parking lot.\n",
      "\t Pred: the several <UNK> are lined up along the side of a narrow parking lot . <EOS>\n",
      "9.\n",
      "\t Ref: A young man appears to be taking a break from the waves.\n",
      "\t Pred: a a young man appears to be from a <UNK> from the waves . <EOS>\n",
      "10.\n",
      "\t Ref: A baseball player standing next to home plate with a bat.\n",
      "\t Pred: a a baseball player standing next to home plate with a bat . <EOS>\n",
      "11.\n",
      "\t Ref: a man sitting on a motorcycle in an empty parking lot.\n",
      "\t Pred: a man man sitting on a motorcycle in an empty parking lot . <EOS>\n",
      "12.\n",
      "\t Ref: A girl rides her skateboard in a public place."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belin\\Anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t Pred: a large child putting her skateboard in a public place . <EOS>\n",
      "13.\n",
      "\t Ref: Two men gesture hands next to laptops, one man uses a phone.\n",
      "\t Pred: two two men <UNK> hands , to clocks , one man <UNK> a phone . <EOS>\n",
      "14.\n",
      "\t Ref: a couple of women sitting at a hair salon.\n",
      "\t Pred: a a couple of women sitting at a hair <UNK> . <EOS>\n",
      "15.\n",
      "\t Ref: A furnished neutral modern open floor plan.\n",
      "\t Pred: <UNK> a <UNK> <UNK> modern open floor <UNK> . <EOS>\n",
      "16.\n",
      "\t Ref: A man standing near a table with video equipment.\n",
      "\t Pred: a a man standing near a table with video equipment . <EOS>\n",
      "17.\n",
      "\t Ref: A close-up picture of some food on paper plates.\n",
      "\t Pred: a a <UNK> picture of some food on paper plates . <EOS>\n",
      "18.\n",
      "\t Ref: A male baseball player wearing red and white is up to bat.\n",
      "\t Pred: a boy male baseball player wearing red and white <UNK> up on bat . <EOS>\n",
      "19.\n",
      "\t Ref: the propeller of a white plane flying and a river.\n",
      "\t Pred: a the <UNK> of a white plane flying and a river . <EOS>\n",
      "20.\n",
      "\t Ref: Two birds standing on an floating on a body of water.\n",
      "\t Pred: a two birds people on its boats on a body of water . <EOS>\n",
      "21.\n",
      "\t Ref: People are riding on skis in the snow on a street.\n",
      "\t Pred: several people are riding on skis in the snow on a street . <EOS>\n",
      "22.\n",
      "\t Ref: A pot of vegetable soup is cooking on the stove.\n",
      "\t Pred: a white pot of stainless soup is cooking on the stove . <EOS>\n",
      "23.\n",
      "\t Ref: A part of a silver utensil on a gray surface.\n",
      "\t Pred: a of <UNK> of a silver <UNK> on a gray surface . <EOS>\n",
      "24.\n",
      "\t Ref: A hot dog in a napkin with onions and green peppers.\n",
      "\t Pred: a a hot dog in a <UNK> with onions and green lettuce . <EOS>\n",
      "25.\n",
      "\t Ref: A young boy holding an umbrella while standing on a wooden deck.\n",
      "\t Pred: a young young boy holding an umbrella while standing on a wooden <UNK> . <EOS>\n",
      "26.\n",
      "\t Ref: This is a beach with a lot of lounge chairs under umbrellas.\n",
      "\t Pred: a there is a sidewalk with a lot of <UNK> chairs chairs umbrellas . <EOS>\n",
      "27.\n",
      "\t Ref: A vase sitting on a table filled with water and white flowers.\n",
      "\t Pred: a a vase sitting on a table filled with water and white flowers . <EOS>\n",
      "28.\n",
      "\t Ref: A clock tower is raised in front of a blue sky.\n",
      "\t Pred: a large clock tower is <UNK> in front of a blue sky . <EOS>\n",
      "29.\n",
      "\t Ref: Several cows in a grassy field behind a fence.\n",
      "\t Pred: several several steam in a grassy field behind a fence . <EOS>\n",
      "30.\n",
      "\t Ref: The orange passenger train is loading passengers onto it.\n",
      "\t Pred: the the orange passenger train is <UNK> passengers onto it . <EOS>\n",
      "31.\n",
      "\t Ref: A toilet lid is closed next to a bathtub with a white curtain and pink tile wall.\n",
      "\t Pred: a the tub <UNK> that towel next to a refrigerator brown a brown , with refrigerator tile chairs . <EOS>\n",
      "32.\n",
      "\t Ref: A woman opening up a laptop computer gift in her living room.\n",
      "\t Pred: a a woman <UNK> up a laptop computer <UNK> in her living room . <EOS>\n",
      "33.\n",
      "\t Ref: A blue kite is flying in the sky.\n",
      "\t Pred: a blue blue kite is flying in the sky . <EOS>\n",
      "34.\n",
      "\t Ref: A black cow is walking through the streets of a town.\n",
      "\t Pred: a black black passenger is walking through the shade of a town . <EOS>\n",
      "35.\n",
      "\t Ref: The side of a boat and a bridge going over the ocean.\n",
      "\t Pred: the the top of a cars and a bridge going over the ocean . <EOS>\n",
      "36.\n",
      "\t Ref: a paper design of a castle with numbers and silver designs on it.\n",
      "\t Pred: a a paper <UNK> of a <UNK> with <UNK> and silver <UNK> on it . <EOS>\n",
      "37.\n",
      "\t Ref: Man in a restaurant kitchen preparing a meal.\n",
      "\t Pred: a man in a kitchen kitchen preparing a meal . <EOS>\n",
      "38.\n",
      "\t Ref: The computer is sitting on a desk with another device plugged in it.\n",
      "\t Pred: the the computer is sitting on a desk with another device in in it . <EOS>\n",
      "39.\n",
      "\t Ref: A bunch of white flowers sit in a vase by the window.\n",
      "\t Pred: a a bunch of white flowers sit in a vase by the window . <EOS>\n",
      "40.\n",
      "\t Ref: Young people open up many pizza boxes lined up on tables.\n",
      "\t Pred: a young people area up some water boxes lined up on tables . <EOS>\n",
      "41.\n",
      "\t Ref: a male and a female in a dress and a laptop.\n",
      "\t Pred: a a male and a professional in a dress and a laptop . <EOS>\n",
      "42.\n",
      "\t Ref: A large crowd watches as a pitcher throws a ball.\n",
      "\t Pred: a large a crowd watches as a pitcher <UNK> a ball . <EOS>\n",
      "43.\n",
      "\t Ref: a person in a hat riding a bicycle and an airplane in the sky.\n",
      "\t Pred: a in top a a hat riding a bike and an airplane in the sky . <EOS>\n",
      "44.\n",
      "\t Ref: An older man is riding his bike down the road.\n",
      "\t Pred: a an older man is riding his bike down the road . <EOS>\n",
      "45.\n",
      "\t Ref: A skate boarder is performing a trick on his skateboard.\n",
      "\t Pred: a a skate boarder is performing a trick on his skateboard . <EOS>\n",
      "46.\n",
      "\t Ref: Holstein calves with tags on their ears stand in a corral.\n",
      "\t Pred: a <UNK> <UNK> with <UNK> on their <UNK> stand in a <UNK> . <EOS>\n",
      "47.\n",
      "\t Ref: lady's walking toward a building pulling suitcases.\n",
      "\t Pred: a lady 's walking toward a building parked landing . <EOS>\n",
      "48.\n",
      "\t Ref: An adult skier towing a small child by a ski pole.\n",
      "\t Pred: a pair adult lies <UNK> a small child on a poles poles . <EOS>\n",
      "49.\n",
      "\t Ref: A woman taking a picture of her cat.\n",
      "\t Pred: a a woman taking a picture of her cat . <EOS>\n",
      "50.\n",
      "\t Ref: A bus is stopping to pick up a passenger.\n",
      "\t Pred: a a bus is <UNK> to <UNK> up a subway . <EOS>\n",
      "51.\n",
      "\t Ref: a big pink house with some chairs out front.\n",
      "\t Pred: a a big big house with chairs chairs inside front . <EOS>\n",
      "52.\n",
      "\t Ref: reflection of a poster on a wall in the mirror of a motorcycle.\n",
      "\t Pred: a blender of a <UNK> on a wall in the end of a motorcycle . <EOS>\n",
      "53.\n",
      "\t Ref: A cat is resting his head on a remote control.\n",
      "\t Pred: a a cat is resting his head on a remote control . <EOS>\n",
      "54.\n",
      "\t Ref: The inside of a subway station with a yellow subway in the distance.\n",
      "\t Pred: the front inside of a narrow station with a yellow bow in the distance . <EOS>\n",
      "55.\n",
      "\t Ref: TWO WOMEN BRIDES GETTING MARRIED STANDING UNDER AND UMBRELLA.\n",
      "\t Pred: two a women <UNK> are <UNK> standing under and umbrella . <EOS>\n",
      "56.\n",
      "\t Ref: a thrown together bed beside a very large picture picture window.\n",
      "\t Pred: a <UNK> <UNK> bed together beside a very large picture picture window . <EOS>\n",
      "57.\n",
      "\t Ref: A team photo with a trophy after a game.\n",
      "\t Pred: a a team photo with a <UNK> after a game . <EOS>\n",
      "58.\n",
      "\t Ref: A dog looking through someones purse by a desk.\n",
      "\t Pred: a a dog looking through <UNK> <UNK> by a desk . <EOS>\n",
      "59.\n",
      "\t Ref: Someone has won a first place ribbon in baking.\n",
      "\t Pred: the someone has a <UNK> <UNK> place <UNK> in <UNK> . <EOS>\n",
      "60.\n",
      "\t Ref: A man riding a wind sail over a large body of water.\n",
      "\t Pred: a a man riding a <UNK> <UNK> over a large body of water . <EOS>\n",
      "61.\n",
      "\t Ref: a train with a sign above the doors parked at the platform.\n",
      "\t Pred: a a pole with a sign above the lamp mounted at the platform . <EOS>\n",
      "62.\n",
      "\t Ref: The man is typing on his red laptop on a table.\n",
      "\t Pred: the the man is <UNK> on his red laptop on a table . <EOS>\n",
      "63.\n",
      "\t Ref: A woman with a pink top on is sheering a sheep.\n",
      "\t Pred: a a woman with a pink top on <UNK> is a school . <EOS>\n",
      "64.\n",
      "\t Ref: a guy skate boarding on the edge of a wall.\n",
      "\t Pred: a a skateboard skateboard boarding on the edge of a wall . <EOS>\n",
      "65.\n",
      "\t Ref: A man sitting in front of a laptop computer in an office.\n",
      "\t Pred: a in man sitting in front of a laptop computer in an office . <EOS>\n",
      "66.\n",
      "\t Ref: two girls eating ice cream at a party.\n",
      "\t Pred: a little girls eating ice cream at a party . <EOS>\n",
      "67.\n",
      "\t Ref: a man and woman the man has a game controller.\n",
      "\t Pred: the a man and one the man has a game controller . <EOS>\n",
      "68.\n",
      "\t Ref: People are waiting alongside a train track for the train to stop.\n",
      "\t Pred: the people are waiting <UNK> a train passing for the station on train . <EOS>\n",
      "69.\n",
      "\t Ref: A person lying on a couch with a cup on the table.\n",
      "\t Pred: a person bed lying on a couch with a cup on the table . <EOS>\n",
      "70.\n",
      "\t Ref: A train is coming up to a passenger loading area.\n",
      "\t Pred: a the bridge is coming up to a church <UNK> area . <EOS>\n",
      "71.\n",
      "\t Ref: Player #11 swings the bat hard at the ball.\n",
      "\t Pred: a player <UNK> <UNK> swings the bat swing at the ball . <EOS>\n",
      "72.\n",
      "\t Ref: A large polar bear sitting on a boulder in a zoo enclosure.\n",
      "\t Pred: a large a decorative bear sitting on a <UNK> in a zoo enclosure . <EOS>\n",
      "73.\n",
      "\t Ref: Two young children with red bat and ball in outdoor setting.\n",
      "\t Pred: a young young children with blue bat and ball in different setting . <EOS>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.\n",
      "\t Ref: The wooden table has many objects on it.\n",
      "\t Pred: the the wooden table has many <UNK> on it . <EOS>\n",
      "75.\n",
      "\t Ref: Boats are off shore in a body of water.\n",
      "\t Pred: several boats are off sand in a body of water . <EOS>\n",
      "76.\n",
      "\t Ref: Two riders on dirt bikes in full safety gear.\n",
      "\t Pred: a two <UNK> on dirt horses in full <UNK> gear . <EOS>\n",
      "77.\n",
      "\t Ref: A city train stopped at a boarding station.\n",
      "\t Pred: a a city train stopped at a train subway . <EOS>\n",
      "78.\n",
      "\t Ref: A professorial baseball player hitting a ball in a game.\n",
      "\t Pred: a <UNK> a baseball player hitting a ball in a game . <EOS>\n",
      "79.\n",
      "\t Ref: Several bunches of carrots and a crate of lemons at a produce stand.\n",
      "\t Pred: a metal <UNK> of carrots and <UNK> <UNK> of <UNK> at a <UNK> stand . <EOS>\n",
      "80.\n",
      "\t Ref: the woman is standing in the ocean with a hat.\n",
      "\t Pred: the a woman is standing in the ocean with a hat . <EOS>\n",
      "81.\n",
      "\t Ref: A large selection of pastries and snacks inside of a glass case.\n",
      "\t Pred: a a large <UNK> of pastries and <UNK> inside of a glass case . <EOS>\n",
      "82.\n",
      "\t Ref: A living room filled with furniture in the time and the same living room at night.\n",
      "\t Pred: a large living room filled with furniture in the area in the old room at at the . <EOS>\n",
      "83.\n",
      "\t Ref: a pepperoni pizza with some green toppings and a fork.\n",
      "\t Pred: a large serve pizza with some some papers and a fork . <EOS>\n",
      "84.\n",
      "\t Ref: a person is blow drying their hair in a bedroom.\n",
      "\t Pred: a a person is <UNK> <UNK> their hair in a bedroom . <EOS>\n",
      "85.\n",
      "\t Ref: A laptop computer is seen sitting next to a television.\n",
      "\t Pred: a a laptop computer is seen sitting next to a television . <EOS>\n",
      "86.\n",
      "\t Ref: A man sitting on top of a hair next to a  woman.\n",
      "\t Pred: a of man sitting on top of a hair next to a woman . <EOS>\n",
      "87.\n",
      "\t Ref: a person jumping towards the side of a snowy hill.\n",
      "\t Pred: a a person jumping off the side of a snowy hill . <EOS>\n",
      "88.\n",
      "\t Ref: A man is feeding a pair of elephants.\n",
      "\t Pred: a a man is feeding a pair of herd . <EOS>\n",
      "89.\n",
      "\t Ref: A bunch of clocks that are on a wall.\n",
      "\t Pred: a a bunch of clocks that are on a wall . <EOS>\n",
      "90.\n",
      "\t Ref: A woman takes a picture of herself and her dog by using her car mirror.\n",
      "\t Pred: a a woman takes a picture of <UNK> and a bed behind her her mirror mirror . <EOS>\n",
      "91.\n",
      "\t Ref: a white and red ambulance on its side and a policeman.\n",
      "\t Pred: a a white and red <UNK> on its it and a <UNK> . <EOS>\n",
      "92.\n",
      "\t Ref: A man walking next to a woman in the rain.\n",
      "\t Pred: a a man walking next to a woman in the rain . <EOS>\n",
      "93.\n",
      "\t Ref: Many men from the armed services are gathered.\n",
      "\t Pred: the many men from the <UNK> <UNK> are gathered . <EOS>\n",
      "94.\n",
      "\t Ref: a kitten that is sitting down by a  door.\n",
      "\t Pred: a large kitten that is sitting down by a door . <EOS>\n",
      "95.\n",
      "\t Ref: A batter in a baseball game ready to hit the ball.\n",
      "\t Pred: a a batter in a baseball game ready to hit the ball . <EOS>\n",
      "96.\n",
      "\t Ref: A person grabbing a slice of pizza from a pizza box.\n",
      "\t Pred: a a person <UNK> a slice of pizza from a pizza box . <EOS>\n",
      "97.\n",
      "\t Ref: A Ford Mustang next to a brown horse.\n",
      "\t Pred: a a <UNK> <UNK> next to a brown horse . <EOS>\n",
      "98.\n",
      "\t Ref: A street sign is shown with two different languages.\n",
      "\t Pred: a a street sign is shown with two different <UNK> . <EOS>\n",
      "99.\n",
      "\t Ref: A white and red bus captured on a street.\n",
      "\t Pred: a a white and red bus <UNK> on a street . <EOS>\n",
      "100.\n",
      "\t Ref: A cow is grazing for food by himself.\n",
      "\t Pred: the a passenger is grazing for food by himself . <EOS>\n",
      "101.\n",
      "\t Ref: Two children looking over a  large birthday cake.\n",
      "\t Pred: the two children looking over a large birthday cake . <EOS>\n",
      "102.\n",
      "\t Ref: A baseball player swings his bat towards a ball next to a catcher and umpire on a field.\n",
      "\t Pred: a a baseball player swings his bat to a ball , a ball a a catcher on a plate . <EOS>\n",
      "103.\n",
      "\t Ref: A man and woman pose for a picture together.\n",
      "\t Pred: a a man and woman pose for a picture together . <EOS>\n",
      "104.\n",
      "\t Ref: Computer on a table with remote controls next to it.\n",
      "\t Pred: a computer on a table with remote <UNK> next to it . <EOS>\n",
      "105.\n",
      "\t Ref: Vase full of yellow flowers on a red table.\n",
      "\t Pred: a vase full of yellow flowers on a red table . <EOS>\n",
      "106.\n",
      "\t Ref: A group of people kneeling down beside some sheep.\n",
      "\t Pred: a a group of people kneeling down beside of dry . <EOS>\n",
      "107.\n",
      "\t Ref: A decorated neck tie saying \"Reel Big Fish\".\n",
      "\t Pred: a of bags bow tie <UNK> `` <UNK> a flag place . <EOS>\n",
      "108.\n",
      "\t Ref: Some people waiting to get on a train.\n",
      "\t Pred: some people people waiting to get on a train . <EOS>\n",
      "109.\n",
      "\t Ref: a close up of a stop sign with a building.\n",
      "\t Pred: a a close up of a pole sign with a building . <EOS>\n",
      "110.\n",
      "\t Ref: The bathroom has white modern fixtures and a brown floor.\n",
      "\t Pred: the the bathroom has white modern <UNK> and a brown floor . <EOS>\n",
      "111.\n",
      "\t Ref: Several surfers catching the last waves as the sun sets.\n",
      "\t Pred: the three adults catching the <UNK> waves as the sun <UNK> . <EOS>\n",
      "112.\n",
      "\t Ref: Several horses on a beach near a tent with the ocean in the background.\n",
      "\t Pred: two several horses on a sand near a <UNK> with the ocean in the background . <EOS>\n",
      "113.\n",
      "\t Ref: A bird sitting on top of bird seed on the ground.\n",
      "\t Pred: a large bird sitting on top of bird <UNK> on the ground . <EOS>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belin\\Anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114.\n",
      "\t Ref: A man kneels on the beach preparing a kite.\n",
      "\t Pred: a a man <UNK> on the beach preparing a kite . <EOS>\n",
      "115.\n",
      "\t Ref: One large brown bear outside at the zoo.\n",
      "\t Pred: a green brown brown bear outside at the dry . <EOS>\n",
      "116.\n",
      "\t Ref: A woman bending over holding and kissing her cat.\n",
      "\t Pred: a a woman <UNK> over while and <UNK> her cat . <EOS>\n",
      "117.\n",
      "\t Ref: It's illegal to put advertisements on public property like parking meters.\n",
      "\t Pred: the 's <UNK> 's to <UNK> <UNK> <UNK> stone <UNK> showing electronic <UNK> . <EOS>\n",
      "118.\n",
      "\t Ref: A picture of a cat in a toilet and another cat sitting next to the toilet.\n",
      "\t Pred: a a picture of a cat in a lamp and her cat sitting on on her cabinet . <EOS>\n",
      "119.\n",
      "\t Ref: A picture of a stop sign on a street.\n",
      "\t Pred: a a picture of a bus sign on a street . <EOS>\n",
      "120.\n",
      "\t Ref: The chef dices carrots quickly on a cutting board.\n",
      "\t Pred: <UNK> the <UNK> <UNK> carrots <UNK> on a cutting board . <EOS>\n",
      "121.\n",
      "\t Ref: A pair of scissors, a chain and a business logo.\n",
      "\t Pred: a a pair of scissors , a <UNK> and a business <UNK> . <EOS>\n",
      "122.\n",
      "\t Ref: A giraffe puts its head over the fence of its enclosure.\n",
      "\t Pred: a a grazing <UNK> its it over the fence of its shade . <EOS>\n",
      "123.\n",
      "\t Ref: A man is sitting on a bike while holding a dog.\n",
      "\t Pred: a a man is sitting on a bench while holding a dog . <EOS>\n",
      "124.\n",
      "\t Ref: A man sitting on top of a bench near the ocean.\n",
      "\t Pred: a a man sitting on top of a bench near the ocean . <EOS>\n",
      "125.\n",
      "\t Ref: A small bathroom where the vanity is over the sink and toilet.\n",
      "\t Pred: the the small refrigerator can the doors is above a painted and curtain . <EOS>\n",
      "126.\n",
      "\t Ref: The cow is eating grass from the ground.\n",
      "\t Pred: the the passenger is eating grass from the ground . <EOS>\n",
      "127.\n",
      "\t Ref: Skier in the air after going over a small hill in the mountains.\n",
      "\t Pred: a skier in the air just just over a large air in the mountains . <EOS>\n",
      "128.\n",
      "\t Ref: A person wearing a hat standing on some steps with a toothbrush in his mouth.\n",
      "\t Pred: a a person wearing a hat standing on his steps with plastic papers in his mouth . <EOS>\n",
      "129.\n",
      "\t Ref: A bird on a stick with palm fronds in back.\n",
      "\t Pred: a a bird on a <UNK> with palm <UNK> in back . <EOS>\n",
      "130.\n",
      "\t Ref: two people sitting on a couch playing nintendo wii.\n",
      "\t Pred: the two people sitting on a couch playing brushing controllers . <EOS>\n",
      "131.\n",
      "\t Ref: A decorative blue and green clock hangs from the ceiling.\n",
      "\t Pred: <UNK> a decorative blue and green clock <UNK> from the ceiling . <EOS>\n",
      "132.\n",
      "\t Ref: A couple of people on a street under a umbrella.\n",
      "\t Pred: a a couple of people on a street under a umbrella . <EOS>\n",
      "133.\n",
      "\t Ref: A close-up of a yellow fire hydrant with hat on top.\n",
      "\t Pred: a a <UNK> of a yellow fire hydrant with hat on top . <EOS>\n",
      "134.\n",
      "\t Ref: A woman swinging a tennis racket in a park.\n",
      "\t Pred: a a woman swinging a tennis racket in a park . <EOS>\n",
      "135.\n",
      "\t Ref: a blue tissue box on a white toilet.\n",
      "\t Pred: a a blue <UNK> box on a white pot . <EOS>\n",
      "136.\n",
      "\t Ref: There's a computer monitor on a desk with speakers around it.\n",
      "\t Pred: a there 's a computer monitor on a desk with <UNK> on it . <EOS>\n",
      "137.\n",
      "\t Ref: A very tall block tower towering over a city under a cloudy blue sky.\n",
      "\t Pred: a in very tall <UNK> tower <UNK> over a city under a cloudy blue sky . <EOS>\n",
      "138.\n",
      "\t Ref: A herd of black cattle grazing on a lush green field.\n",
      "\t Pred: a a herd of black grazing grazing on a lush green field . <EOS>\n",
      "139.\n",
      "\t Ref: The men are putting luggage in order for the plane.\n",
      "\t Pred: the two men are putting luggage in <UNK> for the plane . <EOS>\n",
      "140.\n",
      "\t Ref: A wedding cake is decorated with love birds.\n",
      "\t Pred: the a wedding cake is decorated with <UNK> birds . <EOS>\n",
      "141.\n",
      "\t Ref: Baseball player in a grey uniform holding up a baseball bat at the plate.\n",
      "\t Pred: a baseball player in a dress uniform holding up a baseball bat at the plate . <EOS>\n",
      "142.\n",
      "\t Ref: A man sits in a diner photographing his meal.\n",
      "\t Pred: a a man sits in a <UNK> <UNK> his meal . <EOS>\n",
      "143.\n",
      "\t Ref: Old wooded bench on a poorly mowed slope.\n",
      "\t Pred: an old broken bench on a <UNK> <UNK> slope . <EOS>\n",
      "144.\n",
      "\t Ref: A black and white image of a plane flying over treetops.\n",
      "\t Pred: a in black and white image of a plane flying over <UNK> . <EOS>\n",
      "145.\n",
      "\t Ref: A baseball player wears a Rangers outfit while kneeling and holding a bat.\n",
      "\t Pred: a a baseball player <UNK> a <UNK> outfit , surfing and holding a bat . <EOS>\n",
      "146.\n",
      "\t Ref: A small train is parked at the station on the track.\n",
      "\t Pred: the a small train is parked at the station on the track . <EOS>\n",
      "147.\n",
      "\t Ref: Red shirted tennis player preparing to serve ball.\n",
      "\t Pred: a red <UNK> tennis player preparing to serve ball . <EOS>\n",
      "148.\n",
      "\t Ref: A hot dog with ketchup, cheese and onions on a bun.\n",
      "\t Pred: a a hot dog with <UNK> , cheese , onions on a bun . <EOS>\n",
      "149.\n",
      "\t Ref: A dog laying on a bed chewing stuffed animals.\n",
      "\t Pred: a green dog laying on a bed <UNK> stuffed animals . <EOS>\n",
      "150.\n",
      "\t Ref: A man riding up the side of an empty pool on a skateboard.\n",
      "\t Pred: a of person riding up the side of an empty pool on a board . <EOS>\n",
      "151.\n",
      "\t Ref: Some zebras are standing in the middle of a grassland.\n",
      "\t Pred: <UNK> some grazing are standing in the middle of a <UNK> . <EOS>\n",
      "152.\n",
      "\t Ref: a table filled with cups and a vase with flowers in the middle.\n",
      "\t Pred: a a table filled with cups and a vase with flowers in the middle . <EOS>\n",
      "153.\n",
      "\t Ref: A large building with a giant clock tower.\n",
      "\t Pred: a large large building with a giant stuffed tower . <EOS>\n",
      "154.\n",
      "\t Ref: A very crowded sidewalk with a crooked light pole.\n",
      "\t Pred: a very very crowded sidewalk with a <UNK> light pole . <EOS>\n",
      "155.\n",
      "\t Ref: Several people on motorbikes stopped at an intersection.\n",
      "\t Pred: a several people on <UNK> signs at an intersection . <EOS>\n",
      "156.\n",
      "\t Ref: A guy sitting on the back of a pick up truck.\n",
      "\t Pred: a a guy sitting on the back of a <UNK> up truck . <EOS>\n",
      "157.\n",
      "\t Ref: Some very cute big  elephants by some people.\n",
      "\t Pred: a very very cute big church by some people . <EOS>\n",
      "158.\n",
      "\t Ref: Brown sheep in a snow covered field, front sheep has a snow beard.\n",
      "\t Pred: a brown boats in a middle in field and another birds plays a <UNK> <UNK> . <EOS>\n",
      "159.\n",
      "\t Ref: two children are feeding a giraffe and trees.\n",
      "\t Pred: the two children are feeding a giraffe and trees . <EOS>\n",
      "160.\n",
      "\t Ref: A man is holding an umbrella beside a truck.\n",
      "\t Pred: a a man is holding an umbrella beside a truck . <EOS>\n",
      "161.\n",
      "\t Ref: Many bicyclists are gathering at the taco truck.\n",
      "\t Pred: the many <UNK> are <UNK> at the <UNK> truck . <EOS>\n",
      "162.\n",
      "\t Ref: A woman holding a basket with sandwich in it.\n",
      "\t Pred: a a woman holding a basket with sandwich in it . <EOS>\n",
      "163.\n",
      "\t Ref: Several people are laying down in the bed together.\n",
      "\t Pred: the several people are laying down in the bed together . <EOS>\n",
      "164.\n",
      "\t Ref: Half a cup of coffee are next to a couple pieces of bread.\n",
      "\t Pred: a half top cup of coffee sit next to a pair pieces of meat . <EOS>\n",
      "165.\n",
      "\t Ref: a black and white photo of a building and two people with an umbrella.\n",
      "\t Pred: a black black and white photo of a building and two people with an umbrella . <EOS>\n",
      "166.\n",
      "\t Ref: A male tennis player swinging at a tennis ball.\n",
      "\t Pred: a a male tennis player swinging at a tennis ball . <EOS>\n",
      "167.\n",
      "\t Ref: A herd of sheep in a rural landscape with trees and a pond in the background.\n",
      "\t Pred: a a military of grazing in a <UNK> <UNK> a a <UNK> flag flag in the background . <EOS>\n",
      "168.\n",
      "\t Ref: A yellow toy is shown in different places.\n",
      "\t Pred: a a yellow toy is shown in different <UNK> . <EOS>\n",
      "169.\n",
      "\t Ref: Man in white shirt holding up a cellphone in a crowd.\n",
      "\t Pred: a man in white shirt holding up a device in a crowd . <EOS>\n",
      "170.\n",
      "\t Ref: A group of mopeds on a street next to a bus.\n",
      "\t Pred: a a pair of <UNK> on a street next to a bus . <EOS>\n",
      "171.\n",
      "\t Ref: An umbrella sitting under a bunch of palm trees.\n",
      "\t Pred: a yellow umbrella sitting under a bunch of palm trees . <EOS>\n",
      "172.\n",
      "\t Ref: A dinner plate with grilled fish, potatoes and broccoli.\n",
      "\t Pred: a a dinner plate with <UNK> fish , meat and broccoli . <EOS>\n",
      "173.\n",
      "\t Ref: A concrete bench in a garden type setting.\n",
      "\t Pred: a a concrete park in a garden setting setting . <EOS>\n",
      "174.\n",
      "\t Ref: A young man with an eye patch making gestures with his fingers.\n",
      "\t Pred: a a young man with an <UNK> <UNK> making <UNK> with his <UNK> . <EOS>\n",
      "175.\n",
      "\t Ref: A cat looking from beneath a covering it is in.\n",
      "\t Pred: a a mirror looking from used a <UNK> <UNK> is in . <EOS>\n",
      "176.\n",
      "\t Ref: A bathroom with dark wooden fixtures  and shelving.\n",
      "\t Pred: a a bathroom with dark wooden <UNK> and <UNK> . <EOS>\n",
      "177.\n",
      "\t Ref: A meal containing spinach, tomatoes, cheese, and broccoli.\n",
      "\t Pred: a a meal containing <UNK> , tomatoes , cheese , and broccoli . <EOS>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178.\n",
      "\t Ref: A vase filled with pens with fake sunflowers attached on a desk that says \"Visitors must sign in\".\n",
      "\t Pred: a <UNK> vase filled with <UNK> with <UNK> <UNK> eyes with a clock as <UNK> `` <UNK> <UNK> '' <UNK> '' . <EOS>\n",
      "179.\n",
      "\t Ref: A batter on a baseball field in mid-swing with a catcher and an umpire behind him.\n",
      "\t Pred: a a vegetable on a baseball field in <UNK> <UNK> a catcher with a catcher behind him . <EOS>\n",
      "180.\n",
      "\t Ref: Two cross country skiers smile as they cross the snow.\n",
      "\t Pred: the people cross country country <UNK> as they cross the snow . <EOS>\n",
      "181.\n",
      "\t Ref: A bathroom with a tan sink and white toliet.\n",
      "\t Pred: a a bathroom with a tan sink and white <UNK> . <EOS>\n",
      "182.\n",
      "\t Ref: There is no picture here to write a description of.\n",
      "\t Pred: this there is no picture <UNK> to <UNK> a <UNK> <UNK> . <EOS>\n",
      "183.\n",
      "\t Ref: A close shot of a hot tub near a window.\n",
      "\t Pred: a a close shot of a hot wedding near a window . <EOS>\n",
      "184.\n",
      "\t Ref: Someone jumping in the air on their snowboard.\n",
      "\t Pred: a sand jumping in the air on their served . <EOS>\n",
      "185.\n",
      "\t Ref: Two sheep in a muddy area with a  wall in the background.\n",
      "\t Pred: a two pen in a <UNK> area with a wall in the background . <EOS>\n",
      "186.\n",
      "\t Ref: Many busses drive down a busy street.\n",
      "\t Pred: many many <UNK> <UNK> down a busy street . <EOS>\n",
      "187.\n",
      "\t Ref: cars are stopped at the traffic light on the road.\n",
      "\t Pred: the cars are stopped at the light light on the road . <EOS>\n",
      "188.\n",
      "\t Ref: A bike with horses in background of the rider.\n",
      "\t Pred: a a sidewalk with horses in it of the urban . <EOS>\n",
      "189.\n",
      "\t Ref: A man in a dress shirt holding a bat over his shoulder.\n",
      "\t Pred: a a man in a dress shirt holding a bat over his <UNK> . <EOS>\n",
      "190.\n",
      "\t Ref: a trailer truck riding down the street lifting two motorcycles.\n",
      "\t Pred: a a sandy truck riding down a street <UNK> several fruits . <EOS>\n",
      "191.\n",
      "\t Ref: An unfinished bathroom with a claw foot tub and a toilet.\n",
      "\t Pred: a brown <UNK> refrigerator with a <UNK> hard tricks and a toilet . <EOS>\n",
      "192.\n",
      "\t Ref: A man and two women sitting in a dimly lit living room.\n",
      "\t Pred: a a man and two women sitting in a <UNK> lit lit room . <EOS>\n",
      "193.\n",
      "\t Ref: a person kneeling on sand with a kite.\n",
      "\t Pred: a a person kneeling on sand with a kite . <EOS>\n",
      "194.\n",
      "\t Ref: Residential bathroom with artwork on walls and large floor mat..\n",
      "\t Pred: a <UNK> refrigerator with <UNK> on walls and colored <UNK> . <EOS>\n",
      "195.\n",
      "\t Ref: A skateboarder doing a trick in the air.\n",
      "\t Pred: a a skateboarder doing a trick in the air . <EOS>\n",
      "196.\n",
      "\t Ref: Long table filled with cake on individual plates.\n",
      "\t Pred: a long table filled with cake on <UNK> plates . <EOS>\n",
      "197.\n",
      "\t Ref: A group of buses lined up in a garage.\n",
      "\t Pred: a of group of subway lined up in a <UNK> . <EOS>\n",
      "198.\n",
      "\t Ref: A stuffed bear that is wearing a mask.\n",
      "\t Pred: a a stuffed that that is wearing a <UNK> . <EOS>\n",
      "199.\n",
      "\t Ref: The view from under a plane that is taking off.\n",
      "\t Pred: a the view from under a plane that that taking off . <EOS>\n",
      "200.\n",
      "\t Ref: A large silver double decker bus driving down a street.\n",
      "\t Pred: a large large silver light passenger bus driving down a street . <EOS>\n",
      "201.\n",
      "\t Ref: a man in a white shirt and his luggage.\n",
      "\t Pred: a a man in a white shirt and his tie . <EOS>\n",
      "202.\n",
      "\t Ref: Relics are positioned on glass shelves with a digital piece.\n",
      "\t Pred: the <UNK> are <UNK> on glass shelves with a <UNK> piece . <EOS>\n",
      "203.\n",
      "\t Ref: a plate of food that is on checkered table cloth.\n",
      "\t Pred: a a plate of food that is on <UNK> table cloth . <EOS>\n",
      "204.\n",
      "\t Ref: a white and yellow surfboard in a bicycles rack.\n",
      "\t Pred: a a white and yellow cream in a tile tile . <EOS>\n",
      "205.\n",
      "\t Ref: Two men that are each trying to catch a Frisbee at the same time.\n",
      "\t Pred: the two men that are talking trying to catch a court across the same time . <EOS>\n",
      "206.\n",
      "\t Ref: A woman wading through shallow water with a surfboard.\n",
      "\t Pred: a a woman <UNK> through <UNK> water with a surfboard . <EOS>\n",
      "207.\n",
      "\t Ref: A cake shaped like a little bear sitting in the entrance to a tent.\n",
      "\t Pred: a <UNK> cake made like a little bear laying in the <UNK> on a <UNK> . <EOS>\n",
      "208.\n",
      "\t Ref: A motorcycle sits beside a wooden building with windows.\n",
      "\t Pred: a a motorcycle sits beside a wooden wall with windows . <EOS>\n",
      "209.\n",
      "\t Ref: A large herd of sheep covering a section of a road.\n",
      "\t Pred: a large a narrow of sheep <UNK> a <UNK> of a road . <EOS>\n",
      "210.\n",
      "\t Ref: A white toilet sitting next to a shower in a bathroom.\n",
      "\t Pred: a white a cabinet sitting next to a tiled in a bathroom . <EOS>\n",
      "211.\n",
      "\t Ref: A orange and white cat sitting underneath a white bush.\n",
      "\t Pred: a white orange and white cat sitting underneath a white <UNK> . <EOS>\n",
      "212.\n",
      "\t Ref: A group of people sitting in a restaurant booth eating food.\n",
      "\t Pred: a of group of people sitting in a restaurant <UNK> eating food . <EOS>\n",
      "213.\n",
      "\t Ref: A row of urinals hanging from a bathroom wall.\n",
      "\t Pred: a a row of <UNK> hanging from a stone wall . <EOS>\n",
      "214.\n",
      "\t Ref: Bath tub with metal shower head, vanity mirror, and small utilities compartment.\n",
      "\t Pred: a bath sink with sink antique seat , antique lamp , and small <UNK> <UNK> . <EOS>\n",
      "215.\n",
      "\t Ref: Two men in solider uniforms run to an outhouse where a chicken sits on a toilet and a polar bear approaches from the other side of the outhouse.\n",
      "\t Pred: the two men in <UNK> <UNK> arms to be <UNK> `` a construction , <UNK> a <UNK> a a <UNK> of <UNK> and <UNK> <UNK> <UNK> in the <UNK> . <EOS>\n",
      "216.\n",
      "\t Ref: A group of people in a living room playing video games.\n",
      "\t Pred: a of group of people in a living room playing video games . <EOS>\n",
      "217.\n",
      "\t Ref: A giraffe stands erect by himself in the grass.\n",
      "\t Pred: a a giraffe stands <UNK> by himself in the grass . <EOS>\n",
      "218.\n",
      "\t Ref: a surfing instructor teaches students with surfboards on a beach in front of large hotel buildings.\n",
      "\t Pred: a <UNK> eggs <UNK> <UNK> <UNK> with tie on a park of front of large big clock . <EOS>\n",
      "219.\n",
      "\t Ref: Two surfers are catching some waves of the ocean.\n",
      "\t Pred: the two wedding are catching some waves of the ocean . <EOS>\n",
      "220.\n",
      "\t Ref: fully dressed teddy bears in front of a Christmas tree.\n",
      "\t Pred: a <UNK> dressed teddy bears in front of a christmas tree . <EOS>\n",
      "221.\n",
      "\t Ref: some people on a beach stare out into the ocean.\n",
      "\t Pred: two people people on a sand <UNK> out into the ocean . <EOS>\n",
      "222.\n",
      "\t Ref: A wheeled suitcase sits on a wooden floor in front of a sofa.\n",
      "\t Pred: a <UNK> a motor sits inside a wooden floor in front of a sofa . <EOS>\n",
      "223.\n",
      "\t Ref: a toilet sitting in a tile covered floor in a single room.\n",
      "\t Pred: a on stove sitting in a bow hanging floor in a cluttered room . <EOS>\n",
      "224.\n",
      "\t Ref: a large lot full of parked school busses.\n",
      "\t Pred: a large large lot full of antique boats <UNK> . <EOS>\n",
      "225.\n",
      "\t Ref: A group of people with skis standing in the snow.\n",
      "\t Pred: a a group of people with skis standing in the snow . <EOS>\n",
      "226.\n",
      "\t Ref: people on a boat that is in the water.\n",
      "\t Pred: two people on a boat that is in the water . <EOS>\n",
      "227.\n",
      "\t Ref: A chair next to a desk with a lamp, a monitor, a notebook and paper items.\n",
      "\t Pred: a on top next to a desk with a lamp , a lamp , a <UNK> and and cups . <EOS>\n",
      "228.\n",
      "\t Ref: A photo of the front of a building with a pole clock.\n",
      "\t Pred: a of photo of the front of a building with a clock pole . <EOS>\n",
      "229.\n",
      "\t Ref: Lines of fruits, vegetables, and grains on a white surface.\n",
      "\t Pred: a <UNK> of fruits , vegetables , and <UNK> on a white surface . <EOS>\n",
      "230.\n",
      "\t Ref: One of the two giraffes has grass in it's mouth.\n",
      "\t Pred: the front of two small pretty has all in its 's mouth . <EOS>\n",
      "231.\n",
      "\t Ref: A girl in a red dress and hat is holding her phone.\n",
      "\t Pred: a in girl in a red dress and dress is holding her phone . <EOS>\n",
      "232.\n",
      "\t Ref: a person operating a blender hooked up to a small motor.\n",
      "\t Pred: a a person <UNK> a blender <UNK> up to a a dirty . <EOS>\n",
      "233.\n",
      "\t Ref: A couple of people on a court playing tennis.\n",
      "\t Pred: a a couple of people on a court playing tennis . <EOS>\n",
      "234.\n",
      "\t Ref: A man brushing his teeth and a woman doing her hair in a mirror together.\n",
      "\t Pred: a man his brushing his bow and a woman holds her hair in a modern together . <EOS>\n",
      "235.\n",
      "\t Ref: A man in uniform standing next to machines.\n",
      "\t Pred: a man man in uniform standing next to <UNK> . <EOS>\n",
      "236.\n",
      "\t Ref: Commercial jets lined up at an airport terminal.\n",
      "\t Pred: a commercial <UNK> lined up at an airport <UNK> . <EOS>\n",
      "237.\n",
      "\t Ref: A room with a bed and a chair, the sheets are turned down.\n",
      "\t Pred: a a room with a bed and a chair , the <UNK> <UNK> <UNK> down . <EOS>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238.\n",
      "\t Ref: two young men standing in front of her while she has her foot on a skateboard.\n",
      "\t Pred: a two young men standing in front of her her she has her feet on a skateboard . <EOS>\n",
      "239.\n",
      "\t Ref: a green street sign is pointing towards the right.\n",
      "\t Pred: a green green street sign is pointing towards the right . <EOS>\n",
      "240.\n",
      "\t Ref: Two people riding on a red motorcycle in the middle of the road.\n",
      "\t Pred: the two people riding on a red motorcycle in the middle of the road . <EOS>\n",
      "241.\n",
      "\t Ref: A black bird sitting on a pole among the trees.\n",
      "\t Pred: a in black bird sitting on a pole among the trees . <EOS>\n",
      "242.\n",
      "\t Ref: A floor lamp turned on in a dark room.\n",
      "\t Pred: a red stone lamp , <UNK> in a dark room . <EOS>\n",
      "243.\n",
      "\t Ref: THIS IS A PARTIALLY EATEN VEGGIE THIN CRUST PIZZA.\n",
      "\t Pred: the this is a partially eaten <UNK> <UNK> <UNK> pizza . <EOS>\n",
      "244.\n",
      "\t Ref: a person jumping a skate board in the air.\n",
      "\t Pred: a a person jumping a skate board in the air . <EOS>\n",
      "245.\n",
      "\t Ref: A yellow surfboard sitting on top of a wooden deck.\n",
      "\t Pred: a yellow yellow surfboard sitting on top of a wooden <UNK> . <EOS>\n",
      "246.\n",
      "\t Ref: person running along the beach flying a kite.\n",
      "\t Pred: a person running along the beach flying a kite . <EOS>\n",
      "247.\n",
      "\t Ref: An open suitcase on the floor containing various items.\n",
      "\t Pred: a open open brush on the floor containing various items . <EOS>\n",
      "248.\n",
      "\t Ref: A man standing in front of a store while reaching into a red car trunk.\n",
      "\t Pred: a in man standing in front of a store 's hair to a red back horses . <EOS>\n",
      "249.\n",
      "\t Ref: a do not enter sign with a sticker of a man on it.\n",
      "\t Pred: a <UNK> slope do <UNK> '' and a <UNK> with a man on it . <EOS>\n",
      "250.\n",
      "\t Ref: A man laying down on what appears to be bunk beds in a small room.\n",
      "\t Pred: a a man laying down on towel appears to be <UNK> toys in a small room . <EOS>\n",
      "251.\n",
      "\t Ref: The oranges are picked to make fresh jams.\n",
      "\t Pred: the the fruits are <UNK> to make fresh <UNK> . <EOS>\n",
      "252.\n",
      "\t Ref: A group of palm trees with lots of bananas hanging from them.\n",
      "\t Pred: a large group of traffic trees with lots of bananas hanging from them . <EOS>\n",
      "253.\n",
      "\t Ref: A man holding an umbrella while walking down a street.\n",
      "\t Pred: a a man holding an umbrella while walking down a street . <EOS>\n",
      "254.\n",
      "\t Ref: A rest room with stalls and a urinal and toilet.\n",
      "\t Pred: a a sandy room with <UNK> and a <UNK> and surfers . <EOS>\n",
      "255.\n",
      "\t Ref: A herd of giraffe standing on a dirt hill at a zoo.\n",
      "\t Pred: a a herd of cage standing on a dirt sand at a dirt . <EOS>\n",
      "256.\n",
      "\t Ref: A keyboard, mouse, and controller siting on a black table.\n",
      "\t Pred: a a keyboard , mouse , and pillows <UNK> on a black table . <EOS>\n",
      "257.\n",
      "\t Ref: A man holds a bottle of mustard at a hotdog stand.\n",
      "\t Pred: a a man holds a bottle of <UNK> at a lunch stand . <EOS>\n",
      "258.\n",
      "\t Ref: A man using his surfboard in the ocean.\n",
      "\t Pred: a a man using his surfboard in the ocean . <EOS>\n",
      "259.\n",
      "\t Ref: A white and black dog standing on wooden floor by a cake.\n",
      "\t Pred: a white white and black dog sitting on wooden floor by two pieces . <EOS>\n",
      "260.\n",
      "\t Ref: A black cat sleeping on the hood of a warm car.\n",
      "\t Pred: a black black cat sleeping on the <UNK> of a <UNK> car . <EOS>\n",
      "261.\n",
      "\t Ref: A boy performing a skateboard jump off of a wall.\n",
      "\t Pred: a young boy doing a skateboard jump off of a wall . <EOS>\n",
      "262.\n",
      "\t Ref: A white plate with blue trim full of broccoli and shrimp.\n",
      "\t Pred: a white white plate with blue <UNK> made of broccoli and <UNK> . <EOS>\n",
      "263.\n",
      "\t Ref: A dog is sitting on a work table looking down.\n",
      "\t Pred: a a dog is sitting on a lamp table looking down . <EOS>\n",
      "264.\n",
      "\t Ref: A man standing in a kitchen cooking food.\n",
      "\t Pred: a a man standing in a kitchen cooking food . <EOS>\n",
      "265.\n",
      "\t Ref: A teddy bear setting on a park bench holding a book pretending to read.\n",
      "\t Pred: a a teddy bear setting on a park park holding a book <UNK> to <UNK> . <EOS>\n",
      "266.\n",
      "\t Ref: A bride and groom cutting into their wedding cake together,.\n",
      "\t Pred: a a <UNK> and <UNK> cutting into their wedding cake clothes together . <EOS>\n",
      "267.\n",
      "\t Ref: a living room with couches a table and a lamp.\n",
      "\t Pred: a a living room with video a table and a lamp . <EOS>\n",
      "268.\n",
      "\t Ref: A man walking an elephant down a street in Washington D.C. with people watching.\n",
      "\t Pred: a in man holds a subway down a street in <UNK> <UNK> with with watching . <EOS>\n",
      "269.\n",
      "\t Ref: A man riding a surfboard on a wave in the ocean.\n",
      "\t Pred: a in man riding a surfboard on a wave in the ocean . <EOS>\n",
      "270.\n",
      "\t Ref: Small boy in a uniform sitting on the ground outdoors.\n",
      "\t Pred: a small boy in a uniform sitting on the ground outdoors . <EOS>\n",
      "271.\n",
      "\t Ref: A woman and two girls and a birthday cake.\n",
      "\t Pred: a a woman and two girls and a birthday cake . <EOS>\n",
      "272.\n",
      "\t Ref: A cake in the shape of a train.\n",
      "\t Pred: a a cake in the <UNK> of a train . <EOS>\n",
      "273.\n",
      "\t Ref: A little boy is laying on a white mattress on the wooden floor.\n",
      "\t Pred: a large little boy is laying on a white <UNK> on the floor floor . <EOS>\n",
      "274.\n",
      "\t Ref: A woman holding a plastic utensil passing out a piece of cake.\n",
      "\t Pred: a a woman holding a plastic <UNK> structure out a piece of cake . <EOS>\n",
      "275.\n",
      "\t Ref: Dog looking attentive and alert with pizza in foreground.\n",
      "\t Pred: a dog looking <UNK> and <UNK> with pizza in papers . <EOS>\n",
      "276.\n",
      "\t Ref: A toilet is sitting on the street between a van and a parked car.\n",
      "\t Pred: a yellow curtain is sitting on the street near a horse and a parked bike . <EOS>\n",
      "277.\n",
      "\t Ref: A large clock tower above some snowy trees.\n",
      "\t Pred: a large large clock tower above some palm trees . <EOS>\n",
      "278.\n",
      "\t Ref: A zebra and ostrich standing in dirt field next to trees.\n",
      "\t Pred: a a grazing and <UNK> standing in the field dirt on sunny day . <EOS>\n",
      "279.\n",
      "\t Ref: A black and white kitten perched on top of a door.\n",
      "\t Pred: a black black and white kitten stopped on top of a door . <EOS>\n",
      "280.\n",
      "\t Ref: A large jet is in the loading area.\n",
      "\t Pred: a large large kite is in the <UNK> area . <EOS>\n",
      "281.\n",
      "\t Ref: A passenger bus turning the corner on a city street.\n",
      "\t Pred: a red passenger bus <UNK> the corner on a city street . <EOS>\n",
      "282.\n",
      "\t Ref: A man leaning over a pen full of sheep.\n",
      "\t Pred: a man man leaning over a pen full of zebras . <EOS>\n",
      "283.\n",
      "\t Ref: A man kiteboarding over a body of water.\n",
      "\t Pred: a a man <UNK> over a body of water . <EOS>\n",
      "284.\n",
      "\t Ref: A person is standing by a pier near a fire hydrant.\n",
      "\t Pred: a a person is standing by a pier near a fire hydrant . <EOS>\n",
      "285.\n",
      "\t Ref: A woman bends down to kiss a woolly sheep.\n",
      "\t Pred: a a woman <UNK> down to <UNK> a <UNK> sheep . <EOS>\n",
      "286.\n",
      "\t Ref: A den with a couch, table, monitor and television with a rug.\n",
      "\t Pred: a a <UNK> with a couch , wood , screen and couch and a mouse . <EOS>\n",
      "287.\n",
      "\t Ref: Fork next to a plate of pizza and salad on the table.\n",
      "\t Pred: a fork next to a plate of pizza and salad on the table . <EOS>\n",
      "288.\n",
      "\t Ref: A young boy looking up into the sky at a flying kite.\n",
      "\t Pred: a young young boy looking up into the sky in a flying kite . <EOS>\n",
      "289.\n",
      "\t Ref: A bowl sink in front of a large mirror.\n",
      "\t Pred: a a bowl sink in front of a large mirror . <EOS>\n",
      "290.\n",
      "\t Ref: A man standing in the ocean holding a surfboard.\n",
      "\t Pred: a a man standing in the ocean holding a surfboard . <EOS>\n",
      "291.\n",
      "\t Ref: A man rides a skateboard with a sail(?) in the street.\n",
      "\t Pred: a a man rides a skateboard with a <UNK> <UNK> <UNK> <UNK> in the street . <EOS>\n",
      "292.\n",
      "\t Ref: A group of green apples in an orange bowl.\n",
      "\t Pred: a of green of green apples in an orange bowl . <EOS>\n",
      "293.\n",
      "\t Ref: A man standing in front of a bathroom mirror.\n",
      "\t Pred: a a man standing in front of a bathroom mirror . <EOS>\n",
      "294.\n",
      "\t Ref: The person is driving a motorcycle on the road.\n",
      "\t Pred: the the person is driving a motorcycle on the road . <EOS>\n",
      "295.\n",
      "\t Ref: A picture of a livestock with the american flag and blue and white ribbons hanging from the ceiling.\n",
      "\t Pred: a a picture of a <UNK> with a <UNK> flag and blue and a clock hanging in the ceiling . <EOS>\n",
      "296.\n",
      "\t Ref: a kitchen with a tea pot on a stove.\n",
      "\t Pred: a a kitchen with a <UNK> pot on a stove . <EOS>\n",
      "297.\n",
      "\t Ref: A banana split with a fruit topping and whip cream.\n",
      "\t Pred: a a banana <UNK> with a fruit <UNK> and <UNK> plastic . <EOS>\n",
      "298.\n",
      "\t Ref: A stuffed toy bunny lurking inside a microwave oven.\n",
      "\t Pred: a large stuffed toy <UNK> <UNK> inside a kitchen oven . <EOS>\n",
      "299.\n",
      "\t Ref: A woman in her underwear riding on top of a paddle boat.\n",
      "\t Pred: a a woman in her <UNK> riding on top of a <UNK> truck . <EOS>\n",
      "300.\n",
      "\t Ref: A man riding a skateboard on a wooden ramp.\n",
      "\t Pred: a a man riding a skateboard on a wooden skateboard . <EOS>\n",
      "301.\n",
      "\t Ref: A book shelf filled with lots of books.\n",
      "\t Pred: a a book shelf filled with lots of books . <EOS>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302.\n",
      "\t Ref: A small boat is moored at the dock with rope.\n",
      "\t Pred: the the small boat is <UNK> at the sandy with <UNK> . <EOS>\n",
      "303.\n",
      "\t Ref: A sharply dressed young boy standing next to a sticker wall.\n",
      "\t Pred: a <UNK> <UNK> dressed young boy standing next to a <UNK> wall . <EOS>\n",
      "304.\n",
      "\t Ref: A fork full of food including carrots and tomato is being held up to the camera.\n",
      "\t Pred: a a container full of food including rice and scissors is being looks up to the ground . <EOS>\n",
      "305.\n",
      "\t Ref: A large Chinese lantern display restricted by barriers.\n",
      "\t Pred: a large large <UNK> <UNK> display <UNK> by <UNK> . <EOS>\n",
      "306.\n",
      "\t Ref: The man holding a backpack is next to a man wearing a business suit.\n",
      "\t Pred: a the man holding a backpack is next to a man pair a business suit . <EOS>\n",
      "307.\n",
      "\t Ref: A dog sitting with his leash tied to a fire hydrant.\n",
      "\t Pred: a a dog sitting with his tie tied to a fire hydrant . <EOS>\n",
      "308.\n",
      "\t Ref: A look at a bunch of bananas that have been frozen.\n",
      "\t Pred: a <UNK> look at a bunch of bananas are have been <UNK> . <EOS>\n",
      "309.\n",
      "\t Ref: Photos of large dog and wooden chair and different reactions.\n",
      "\t Pred: two photos of large dog and wooden chair and different <UNK> . <EOS>\n",
      "310.\n",
      "\t Ref: A messy and unmade bed and a red chair.\n",
      "\t Pred: a a messy and <UNK> bed and a red chair . <EOS>\n",
      "311.\n",
      "\t Ref: Two boats with a dog between them on an island.\n",
      "\t Pred: a large sandy with a dog between them on an doughnut . <EOS>\n",
      "312.\n",
      "\t Ref: A laptop computer is sitting on a large wooden desk.\n",
      "\t Pred: a a laptop computer is sitting on a large wooden desk . <EOS>\n",
      "313.\n",
      "\t Ref: A teddy bear in pink sitting next to an old dusty machine.\n",
      "\t Pred: a a teddy bear in coffee sitting next to an old <UNK> machine . <EOS>\n",
      "314.\n",
      "\t Ref: A red and white fire hydrant between two red barriers.\n",
      "\t Pred: a a red and white fire hydrant between two red <UNK> . <EOS>\n",
      "315.\n",
      "\t Ref: Three people on skis standing in the snow.\n",
      "\t Pred: the three people on skis standing in the snow . <EOS>\n",
      "316.\n",
      "\t Ref: Four surfers walking out into the water at dusk.\n",
      "\t Pred: the few friends coming out into the water at <UNK> . <EOS>\n",
      "317.\n",
      "\t Ref: Two people sitting on a dock eating sandwiches.\n",
      "\t Pred: a two people sitting on a sofa holding drinks . <EOS>\n",
      "318.\n",
      "\t Ref: A man rared back at a baseball with his bat as another man holds his glove.\n",
      "\t Pred: a a man <UNK> back at a game with his bat as another man holds his glove . <EOS>\n",
      "319.\n",
      "\t Ref: four people around a table with various plates of food.\n",
      "\t Pred: two four people around a table with various plates of food . <EOS>\n",
      "320.\n",
      "\t Ref: A dessert with cake and apples is on a plate with a fork.\n",
      "\t Pred: a a chocolate with cake is apples on <UNK> a plate with a fork . <EOS>\n",
      "321.\n",
      "\t Ref: A person standing in a grassy area next to a river holding a frisbee.\n",
      "\t Pred: a a person standing in a living area next to a river holding a soccer . <EOS>\n",
      "322.\n",
      "\t Ref: Three zebras trying to graze but not much is green.\n",
      "\t Pred: the three six trying to get <UNK> sun <UNK> is green . <EOS>\n",
      "323.\n",
      "\t Ref: A homemade wreath with stuffed bears and a bird.\n",
      "\t Pred: a <UNK> <UNK> <UNK> with stuffed bears and a bird . <EOS>\n",
      "324.\n",
      "\t Ref: The batter gets ready to swing in a school yard baseball game.\n",
      "\t Pred: the young batter gets ready to swing at a crowded pool baseball game . <EOS>\n",
      "325.\n",
      "\t Ref: A very nice sandwich next to some glasses of wine.\n",
      "\t Pred: a very very nice sandwich next to some glasses of wine . <EOS>\n",
      "326.\n",
      "\t Ref: A white bus driving past a hillside covered with trees.\n",
      "\t Pred: a white a bus driving past a blanket covered with trees . <EOS>\n",
      "327.\n",
      "\t Ref: A big guy holding a remote next to a smiling woman.\n",
      "\t Pred: a a big guy holding a device next to a smiling smiling . <EOS>\n",
      "328.\n",
      "\t Ref: Man in a red shirt and blue jeans skateboarding.\n",
      "\t Pred: a man in a red shirt and blue <UNK> landing . <EOS>\n",
      "329.\n",
      "\t Ref: a number of horses standing near one another.\n",
      "\t Pred: a of number of horses standing near one another . <EOS>\n",
      "330.\n",
      "\t Ref: A small herd of buffalo resting on the ither side of the stream.\n",
      "\t Pred: a in small statue of <UNK> resting on the <UNK> side of the <UNK> . <EOS>\n",
      "331.\n",
      "\t Ref: The man is walking on a very narrow street.\n",
      "\t Pred: the the man is walking on a very narrow street . <EOS>\n",
      "332.\n",
      "\t Ref: a public transit bus on a city stree.\n",
      "\t Pred: a a public passenger bus on a city <UNK> . <EOS>\n",
      "333.\n",
      "\t Ref: A red truck collection crops on a lush farm field.\n",
      "\t Pred: a red red truck <UNK> <UNK> on a lush field field . <EOS>\n",
      "334.\n",
      "\t Ref: A full dressed marine is looking at his cell phone.\n",
      "\t Pred: a full full dressed <UNK> is looking at his cell phone . <EOS>\n",
      "335.\n",
      "\t Ref: A black brown cat with large whiskers looking at the camera.\n",
      "\t Pred: a black brown brown cat with large <UNK> looking at the camera . <EOS>\n",
      "336.\n",
      "\t Ref: A big sign that says \"Restaurant Bar Jackpots.\".\n",
      "\t Pred: a a big that that says into lit bar <UNK> <UNK> `` . <EOS>\n",
      "337.\n",
      "\t Ref: A traffic light hanging on a street pole.\n",
      "\t Pred: a a traffic light hanging on a street pole . <EOS>\n",
      "338.\n",
      "\t Ref: Several people are sitting around a table having a business meeting.\n",
      "\t Pred: the several people are sitting around a table having a business <UNK> . <EOS>\n",
      "339.\n",
      "\t Ref: a man in his bathroom taking a picture of himself.\n",
      "\t Pred: a in man in his bathroom taking a picture of himself . <EOS>\n",
      "340.\n",
      "\t Ref: An elephant walking around outside in a park.\n",
      "\t Pred: a an elephant walking around outside in a park . <EOS>\n",
      "341.\n",
      "\t Ref: A clean kitchen with all the necessary appliances.\n",
      "\t Pred: the a clean kitchen with all the <UNK> appliances . <EOS>\n",
      "342.\n",
      "\t Ref: A train with train cars and some wires above it.\n",
      "\t Pred: a a train with train plants and some <UNK> above it . <EOS>\n",
      "343.\n",
      "\t Ref: two green vases next to each other.\n",
      "\t Pred: a green green vases next to each other . <EOS>\n",
      "344.\n",
      "\t Ref: A group of people are standing in the snow on skis.\n",
      "\t Pred: the of group of people are standing in the snow on skis . <EOS>\n",
      "345.\n",
      "\t Ref: An older man has a woman standing next to him.\n",
      "\t Pred: a an older man has a woman standing next to him . <EOS>\n",
      "346.\n",
      "\t Ref: a white bathroom with a black counter a mirror and a sink.\n",
      "\t Pred: a white a refrigerator with a <UNK> counter a refrigerator and a sink . <EOS>\n",
      "347.\n",
      "\t Ref: Cute little kid smiling while holding a cell phone.\n",
      "\t Pred: a cute little kid smiling while holding a cell phone . <EOS>\n",
      "348.\n",
      "\t Ref: A bear made out of gummy bears sitting on a counter.\n",
      "\t Pred: a <UNK> bear made out of <UNK> bears sitting on a counter . <EOS>\n",
      "349.\n",
      "\t Ref: A man and woman play an interactive video game.\n",
      "\t Pred: a a man and woman play an <UNK> video game . <EOS>\n",
      "350.\n",
      "\t Ref: A tennis player is shown wiping the sweat and engaging in action.\n",
      "\t Pred: a a tennis player is shown <UNK> the <UNK> and <UNK> in action . <EOS>\n",
      "351.\n",
      "\t Ref: A man getting ready to serve in tennis.\n",
      "\t Pred: a man man getting ready to serve in tennis . <EOS>\n",
      "352.\n",
      "\t Ref: Elephants washing themselves and relaxing at a river.\n",
      "\t Pred: two horses <UNK> <UNK> and <UNK> at a river . <EOS>\n",
      "353.\n",
      "\t Ref: Four zebras are grazing on a grassy green field.\n",
      "\t Pred: the four grazing are grazing on a green grassy field . <EOS>\n",
      "354.\n",
      "\t Ref: A man hitting a tennis ball with his racket.\n",
      "\t Pred: a man a hitting a tennis ball with his racket . <EOS>\n",
      "355.\n",
      "\t Ref: A person roasting a hot dog by campfire.\n",
      "\t Pred: a a person <UNK> a hot dog by <UNK> . <EOS>\n",
      "356.\n",
      "\t Ref: The plastic shower curtain is closed next to the toilet.\n",
      "\t Pred: the the plastic cream sink is mounted next to the airplane . <EOS>\n",
      "357.\n",
      "\t Ref: Two white q-tips with cream on the tip.\n",
      "\t Pred: a two white <UNK> with cream on the <UNK> . <EOS>\n",
      "358.\n",
      "\t Ref: A drawing of a man riding a wave on a surfboard.\n",
      "\t Pred: a a picture of a man riding a wave on a surfboard . <EOS>\n",
      "359.\n",
      "\t Ref: Zipper drawn on a banana peel with black marker.\n",
      "\t Pred: a <UNK> drawn on a banana <UNK> with black <UNK> . <EOS>\n",
      "360.\n",
      "\t Ref: Living room area of home with couches and television.\n",
      "\t Pred: a living room area of home with tv and television . <EOS>\n",
      "361.\n",
      "\t Ref: A dog sits between a person's legs on the floor of the passenger side of a vehicle.\n",
      "\t Pred: a green dog sits underneath a pair of poles on the back of the back of of a neck . <EOS>\n",
      "362.\n",
      "\t Ref: Two large ships are docked, while several people look at them.\n",
      "\t Pred: the two large <UNK> are docked , while several people look at them . <EOS>\n",
      "363.\n",
      "\t Ref: A tennis game with the player looking up .\n",
      "\t Pred: a a tennis game with the player looking up . <EOS>\n",
      "364.\n",
      "\t Ref: The surfer is riding a wave in the ocean.\n",
      "\t Pred: the the surfer is riding a wave in the ocean . <EOS>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365.\n",
      "\t Ref: A person jumping in the air, catching a Frisbee and another person chasing him.\n",
      "\t Pred: a person person jumping in the air , catching a catching and another man <UNK> him . <EOS>\n",
      "366.\n",
      "\t Ref: A kitchen filled with black counter tops and a black stove top oven.\n",
      "\t Pred: a small kitchen filled with black hair <UNK> and a large stove top oven . <EOS>\n",
      "367.\n",
      "\t Ref: Cup of mixed vegetables with a spoon sitting in the middle.\n",
      "\t Pred: a cup of a vegetables with a spoon sitting in the middle . <EOS>\n",
      "368.\n",
      "\t Ref: Two dogs sitting in the backseat of a car.\n",
      "\t Pred: two people dogs sitting in the <UNK> of a car . <EOS>\n",
      "369.\n",
      "\t Ref: Two giraffes and a zebra standing outside during the day.\n",
      "\t Pred: the two pots and a pen standing outside during the day . <EOS>\n",
      "370.\n",
      "\t Ref: A person in a van with a canoe strapped to the roof stopped in the middle of the street next to a motorcyclist with a helmet on a motorcycle.\n",
      "\t Pred: a a picture in a seat with a <UNK> <UNK> it to be it the the of of a <UNK> a <UNK> a <UNK> <UNK> on on on a motorcycle . <EOS>\n",
      "371.\n",
      "\t Ref: A person in a red snowsuit riding on skis on a slope.\n",
      "\t Pred: a a person in a red <UNK> riding on skis on a slope . <EOS>\n",
      "372.\n",
      "\t Ref: a living room with a couch a table and a panting.\n",
      "\t Pred: a a living room with a couch a table and a <UNK> . <EOS>\n",
      "373.\n",
      "\t Ref: A person is playing a Wii golf game in a living room.\n",
      "\t Pred: a the person is playing a video a game in a living room . <EOS>\n",
      "374.\n",
      "\t Ref: A hand holds an iphone playing a video of 2 men.\n",
      "\t Pred: a a hand holds his <UNK> room a video of <UNK> men . <EOS>\n",
      "375.\n",
      "\t Ref: Horses grazing in a field near a barn and house.\n",
      "\t Pred: two grazing grazing in a field near a <UNK> and house . <EOS>\n",
      "376.\n",
      "\t Ref: A bunch of yellow bananas sitting on top of a counter.\n",
      "\t Pred: a a bunch of yellow bananas sitting on top of a counter . <EOS>\n",
      "377.\n",
      "\t Ref: there are many statues of zebras all around the field.\n",
      "\t Pred: the there are many <UNK> of plants all around the field . <EOS>\n",
      "378.\n",
      "\t Ref: A red motorcycle parked in front of a car on a street.\n",
      "\t Pred: a red red motorcycle parked in front of a car on a street . <EOS>\n",
      "379.\n",
      "\t Ref: There is a control room with several boards and screens.\n",
      "\t Pred: the there is a living room with several shelves and <UNK> . <EOS>\n",
      "380.\n",
      "\t Ref: a table that has a muffin and some drink on it.\n",
      "\t Pred: a a table that has a <UNK> and some drink on it . <EOS>\n",
      "381.\n",
      "\t Ref: a dog tucked under a blanket in bed with feet hanging out.\n",
      "\t Pred: a a dog with under a sofa in bed with mouth lying it . <EOS>\n",
      "382.\n",
      "\t Ref: A large brown pug down reaching up on a table.\n",
      "\t Pred: a large large brown <UNK> down seen up on a table . <EOS>\n",
      "383.\n",
      "\t Ref: Two elephants roaming on a field during the day.\n",
      "\t Pred: two people grazing <UNK> on a field during the day . <EOS>\n",
      "384.\n",
      "\t Ref: A picture of some flowers by a window.\n",
      "\t Pred: a a picture of some flowers by a window . <EOS>\n",
      "385.\n",
      "\t Ref: Graffiti is sprayed over the door of a red train.\n",
      "\t Pred: the pot is <UNK> over the door of a red hair . <EOS>\n",
      "386.\n",
      "\t Ref: a drawn picture of a horse with wings.\n",
      "\t Pred: a a drawn picture of a horse with <UNK> . <EOS>\n",
      "387.\n",
      "\t Ref: A barren bathroom with bucket, toilet and white walls.\n",
      "\t Pred: a <UNK> of sofa with <UNK> , cabinets and white walls . <EOS>\n",
      "388.\n",
      "\t Ref: A man riding a dirt bike through a desert field.\n",
      "\t Pred: a a man riding a bike bike through a rock field . <EOS>\n",
      "389.\n",
      "\t Ref: Several people stand on a narrow, long pier on the water.\n",
      "\t Pred: a several people stand on a narrow , dark pier on the ground . <EOS>\n",
      "390.\n",
      "\t Ref: A large black bear walks through the green terrain.\n",
      "\t Pred: a large large black bear grazing through the green <UNK> . <EOS>\n",
      "391.\n",
      "\t Ref: Several shots of a man in various positions with a tennis racquet.\n",
      "\t Pred: a bottle <UNK> of a man in various <UNK> with a tennis racquet . <EOS>\n",
      "392.\n",
      "\t Ref: 2 smiling men ring a gong in unison.\n",
      "\t Pred: a <UNK> smiling men <UNK> a <UNK> in <UNK> . <EOS>\n",
      "393.\n",
      "\t Ref: The bare tree is in front of a large brick building.\n",
      "\t Pred: a the <UNK> tree is in front of a large brick building . <EOS>\n",
      "394.\n",
      "\t Ref: Buses are driving down a street in front of a building.\n",
      "\t Pred: several driving are driving down a street in front of a building . <EOS>\n",
      "395.\n",
      "\t Ref: Room with many hanging clothes, a bed and dresser.\n",
      "\t Pred: a room with many items clothes , a bed and <UNK> . <EOS>\n",
      "396.\n",
      "\t Ref: Several giraffes gather at an elevated platform to take food from zoo visitors.\n",
      "\t Pred: two four friends <UNK> at a <UNK> seat to take from they off <UNK> . <EOS>\n",
      "397.\n",
      "\t Ref: Rider on horseback maneuvering in open field area.\n",
      "\t Pred: a skateboarder on <UNK> <UNK> in open field field . <EOS>\n",
      "398.\n",
      "\t Ref: A snowboarder does a flip after jumping off a hill.\n",
      "\t Pred: a a skateboarder does a <UNK> after jumping off a hill . <EOS>\n",
      "399.\n",
      "\t Ref: The microwave is sitting on the kitchen counter.\n",
      "\t Pred: the the microwave is sitting on the kitchen counter . <EOS>\n",
      "400.\n",
      "\t Ref: An old tower has a clock built into it.\n",
      "\t Pred: a old old tower has a clock <UNK> into it . <EOS>\n",
      "401.\n",
      "\t Ref: A dog laying on top of a bed in front of a red book.\n",
      "\t Pred: a green dog laying on top of a top of front of a red book . <EOS>\n",
      "402.\n",
      "\t Ref: The train has stopped on the railroad tracks at the train station.\n",
      "\t Pred: the the intersection is stopped on the cage post at the train station . <EOS>\n",
      "403.\n",
      "\t Ref: Street graffiti drawn on a parking meter on a bright day.\n",
      "\t Pred: a street traffic slope on a parking passenger on a bright day . <EOS>\n",
      "404.\n",
      "\t Ref: A woman standing next to a horse outside.\n",
      "\t Pred: a a woman standing next to a horse outside . <EOS>\n",
      "405.\n",
      "\t Ref: A large cargo van parked in front of a smart car.\n",
      "\t Pred: a a large <UNK> plane parked in front of a <UNK> car . <EOS>\n",
      "406.\n",
      "\t Ref: Some brown and white giraffes standing on grass.\n",
      "\t Pred: a brown brown and white bears standing on grass . <EOS>\n",
      "407.\n",
      "\t Ref: The mobile phone has a trinket attached to it by a cord.\n",
      "\t Pred: the the <UNK> phone has a <UNK> attached to it by a <UNK> . <EOS>\n",
      "408.\n",
      "\t Ref: A snowboarder is a doing a trick in the air.\n",
      "\t Pred: a a rice is a doing a trick in the air . <EOS>\n",
      "409.\n",
      "\t Ref: A paraglider who has just landed in the ocean.\n",
      "\t Pred: a <UNK> <UNK> who has just <UNK> in the ocean . <EOS>\n",
      "410.\n",
      "\t Ref: Black crow sitting on a black fence near a field.\n",
      "\t Pred: a black <UNK> sitting on a black blanket near a field . <EOS>\n",
      "411.\n",
      "\t Ref: a mirror is on a pole by a light.\n",
      "\t Pred: a the mirror is on a pole by a light . <EOS>\n",
      "412.\n",
      "\t Ref: Three sheep are standing on a rock of a hill.\n",
      "\t Pred: the three sheep are standing on a rock of a hill . <EOS>\n",
      "413.\n",
      "\t Ref: A kid with a baseball bat on a field.\n",
      "\t Pred: a a kid with a baseball bat on a field . <EOS>\n",
      "414.\n",
      "\t Ref: Surfer on a surf board in the ocean.\n",
      "\t Pred: a surfer on a surf board in the ocean . <EOS>\n",
      "415.\n",
      "\t Ref: Blue tram in a city with people boarding.\n",
      "\t Pred: a blue <UNK> in a city with people boarding . <EOS>\n",
      "416.\n",
      "\t Ref: a black passenger train going down the track.\n",
      "\t Pred: a large red passenger train going down the track . <EOS>\n",
      "417.\n",
      "\t Ref: A dog and a couple sitting on a wood bench.\n",
      "\t Pred: a a dog and a couple sitting on a wooden bench . <EOS>\n",
      "418.\n",
      "\t Ref: A young person sitting on a bench across the street from a big building.\n",
      "\t Pred: a of a boy sitting on a bench across the back from a big building . <EOS>\n",
      "419.\n",
      "\t Ref: Cow going against traffic on a very crowded street.\n",
      "\t Pred: a cow going several traffic on a very crowded street . <EOS>\n",
      "420.\n",
      "\t Ref: Men are sitting at a table with laptops.\n",
      "\t Pred: two men are sitting at a table with laptops . <EOS>\n",
      "421.\n",
      "\t Ref: A couple of kids laying on top of a bed.\n",
      "\t Pred: a a couple of kids laying on top of a bed . <EOS>\n",
      "422.\n",
      "\t Ref: A single giraffe standing in a grass field.\n",
      "\t Pred: a a single giraffe standing in a grass field . <EOS>\n",
      "423.\n",
      "\t Ref: A cat lying on a park bench,wedged between the arm of the bench and a person.\n",
      "\t Pred: a white cat lying on a wooden floor and <UNK> out the edge of a <UNK> with a person . <EOS>\n",
      "424.\n",
      "\t Ref: Several boats docked at a small boat dock.\n",
      "\t Pred: a yellow boats boats at a small beach sandy . <EOS>\n",
      "425.\n",
      "\t Ref: A group of men playing a game with remote controllers.\n",
      "\t Pred: a a group of men playing a game with remote controllers . <EOS>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426.\n",
      "\t Ref: A team  ends up in a pile on the field.\n",
      "\t Pred: a a skateboard <UNK> up in a pile on the field . <EOS>\n",
      "427.\n",
      "\t Ref: This is an interesting patterned clock on the side of a building.\n",
      "\t Pred: the this is an <UNK> <UNK> clock on the side of a building . <EOS>\n",
      "428.\n",
      "\t Ref: A big commercial plane flying in the sky over a wire.\n",
      "\t Pred: a large big plane plane flying in the sky over a wire . <EOS>\n",
      "429.\n",
      "\t Ref: Three rectangular bowls with food; Big bowl has nine meat and sesame seed patties with brown sauce, next to it, a bowl of shredded cabbage and carrots with yogurt dollop atop, and behind that is a bowl of cut broccoli and tomatoes with seasoning.\n",
      "\t Pred: a three <UNK> bowls with <UNK> with three orange <UNK> <UNK> bread , <UNK> <UNK> of <UNK> <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> with <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> with and on it . <EOS>\n",
      "430.\n",
      "\t Ref: A black bird standing on ground next to a bench.\n",
      "\t Pred: a black black bird standing on ground next to a bench . <EOS>\n",
      "431.\n",
      "\t Ref: Two people wearing blind folds drinking and tasting wine.\n",
      "\t Pred: the two people wearing <UNK> <UNK> drinking and <UNK> wine . <EOS>\n",
      "432.\n",
      "\t Ref: People sitting on small boats with oars, in water.\n",
      "\t Pred: two people sitting on small boats with <UNK> , and water . <EOS>\n",
      "433.\n",
      "\t Ref: a table with bowls of different food on top.\n",
      "\t Pred: a a table with bowls of different food on top . <EOS>\n",
      "434.\n",
      "\t Ref: A group of people are standing outside near a school bus.\n",
      "\t Pred: a of group of people are standing outside near a school bus . <EOS>\n",
      "435.\n",
      "\t Ref: A narrow foreign street has lots of overhead signs.\n",
      "\t Pred: the a narrow <UNK> street has lots of lights signs . <EOS>\n",
      "436.\n",
      "\t Ref: A bus making a right turn at an intersection.\n",
      "\t Pred: a a bus making a metal turn at an intersection . <EOS>\n",
      "437.\n",
      "\t Ref: A biplane leaves a smoke trail while doing a trick.\n",
      "\t Pred: a <UNK> <UNK> painting a tub poles while doing a trick . <EOS>\n",
      "438.\n",
      "\t Ref: A wooden bench is sitting in front of a red brick wall with two holes in it.\n",
      "\t Pred: a a wooden container is sits in front of a wooden brick wall , <UNK> <UNK> on it . <EOS>\n",
      "439.\n",
      "\t Ref: A person laying on a pillow with a remote in their hand.\n",
      "\t Pred: a a person laying on a pillow with a sofa in their hand . <EOS>\n",
      "440.\n",
      "\t Ref: Two children smiling and eating small personal pizzas.\n",
      "\t Pred: the two children smiling and eating small <UNK> breakfast . <EOS>\n",
      "441.\n",
      "\t Ref: two plates of food on two plates on a table.\n",
      "\t Pred: two two plates of food on two plates on a table . <EOS>\n",
      "442.\n",
      "\t Ref: A donut is on the table on a white saucer.\n",
      "\t Pred: the a donut is on the table on a white <UNK> . <EOS>\n",
      "443.\n",
      "\t Ref: An outdoor cage with tall, thin colorful birds.\n",
      "\t Pred: a an outdoor rock with tall , <UNK> colorful birds . <EOS>\n",
      "444.\n",
      "\t Ref: On a beach, a man is paying out the lines of his stunt kite.\n",
      "\t Pred: people on a beach , a man is <UNK> out the <UNK> of <UNK> his kite . <EOS>\n",
      "445.\n",
      "\t Ref: A statue of men riding horses next to a green hillside.\n",
      "\t Pred: a a pair of men are tied next to a green hillside . <EOS>\n",
      "446.\n",
      "\t Ref: A woman near two sitting men is taking a picture of a bowl of food on the table.\n",
      "\t Pred: a in woman with two and glasses is taking a picture of a <UNK> of food on the table . <EOS>\n",
      "447.\n",
      "\t Ref: A snowboarder flying up in the air with the sun behind him.\n",
      "\t Pred: a a doughnut flying up in the air with the sun behind him . <EOS>\n",
      "448.\n",
      "\t Ref: A man standing behind and closely to a woman he is talking to.\n",
      "\t Pred: a a man standing behind and <UNK> to a <UNK> she is talking down . <EOS>\n",
      "449.\n",
      "\t Ref: A black and white photograph is posted to a wall.\n",
      "\t Pred: a large black and white photograph and <UNK> to a wall . <EOS>\n",
      "450.\n",
      "\t Ref: A woman and a child are snow skiing.\n",
      "\t Pred: a a woman and a child are <UNK> skis . <EOS>\n",
      "451.\n",
      "\t Ref: a black orange and white cat and some bricks.\n",
      "\t Pred: a black black orange and white cat and some <UNK> . <EOS>\n",
      "452.\n",
      "\t Ref: A red stop sign sitting on top of a green planter.\n",
      "\t Pred: a red red pole sign sitting on top of a green <UNK> . <EOS>\n",
      "453.\n",
      "\t Ref: A bunch of bananas hanging above somewhere on a ceiling.\n",
      "\t Pred: a a bunch of bananas hanging above <UNK> on a ceiling . <EOS>\n",
      "454.\n",
      "\t Ref: A man stands with a flag-decked statue depicting a child with piles of luggage.\n",
      "\t Pred: a a man stands with a <UNK> statue <UNK> a child with <UNK> of luggage . <EOS>\n",
      "455.\n",
      "\t Ref: A burger and a salad are being displayed on a plate.\n",
      "\t Pred: a a <UNK> and a salad are being displayed on a plate . <EOS>\n",
      "456.\n",
      "\t Ref: A woman sitting with a little girl holding a doll.\n",
      "\t Pred: a a woman sitting with a little girl holding a <UNK> . <EOS>\n",
      "457.\n",
      "\t Ref: A man sits in a chair with a hand on a dog.\n",
      "\t Pred: a a man sits in a chair with a hand on a dog . <EOS>\n",
      "458.\n",
      "\t Ref: A bear standing on top of a large rock.\n",
      "\t Pred: a of bear standing on top of a large rock . <EOS>\n",
      "459.\n",
      "\t Ref: A black and white cat sitting on a windowsill.\n",
      "\t Pred: a a black and white cat sitting on a <UNK> . <EOS>\n",
      "460.\n",
      "\t Ref: A couple of pieces of pizza on plates.\n",
      "\t Pred: a a couple of pieces of pizza on plates . <EOS>\n",
      "461.\n",
      "\t Ref: A parking meter sitting next to a small covered sign.\n",
      "\t Pred: a person parking construction sitting next to a one covered stands . <EOS>\n",
      "462.\n",
      "\t Ref: A large truck is in the snow next to a Clark truck.\n",
      "\t Pred: a large large house is in the snow next to a <UNK> truck . <EOS>\n",
      "463.\n",
      "\t Ref: A wooden table topped with a pastry and a cup of coffee.\n",
      "\t Pred: a a wooden table topped with a pastry and a cup of coffee . <EOS>\n",
      "464.\n",
      "\t Ref: a small opened refrigerator on the ground.\n",
      "\t Pred: a in small cabinet refrigerator on the ground . <EOS>\n",
      "465.\n",
      "\t Ref: A silver luggage suitcase sitting in a room.\n",
      "\t Pred: a large silver luggage cabinets sitting in a room . <EOS>\n",
      "466.\n",
      "\t Ref: A woman with glasses eating a hot dog.\n",
      "\t Pred: a a woman with glasses eating a hot dog . <EOS>\n",
      "467.\n",
      "\t Ref: Three men stand atop elephants in the water.\n",
      "\t Pred: two three men stand atop motorcycle in the water . <EOS>\n",
      "468.\n",
      "\t Ref: A large sandwich cut in half on top of checkered paper.\n",
      "\t Pred: a large large sandwich cut in half on top of <UNK> paper . <EOS>\n",
      "469.\n",
      "\t Ref: A man standing in a park holding onto a camera.\n",
      "\t Pred: a a man standing in a park holding onto a camera . <EOS>\n",
      "470.\n",
      "\t Ref: A sheepdog prepares to guide a sheep into a corral.\n",
      "\t Pred: a <UNK> <UNK> prepares to <UNK> a sheep taking a <UNK> . <EOS>\n",
      "471.\n",
      "\t Ref: A brown and black dog laying on a bed with grey sheets.\n",
      "\t Pred: a a brown and black dog laying on a bed with tan <UNK> . <EOS>\n",
      "472.\n",
      "\t Ref: a zebra a giraffe and some birds by some water.\n",
      "\t Pred: a a grazing a giraffe and some hole by some water . <EOS>\n",
      "473.\n",
      "\t Ref: A man playing tennis is swinging his racket.\n",
      "\t Pred: a a man playing tennis is swinging his racket . <EOS>\n",
      "474.\n",
      "\t Ref: A gray tiered building features hundreds of windows and a clock high up near the top.\n",
      "\t Pred: a red dark <UNK> , narrow <UNK> from windows and a clock lit up on in it . <EOS>\n",
      "475.\n",
      "\t Ref: A large clock towers next to a forest filled with green trees.\n",
      "\t Pred: a large large clock <UNK> next to a town filled with green trees . <EOS>\n",
      "476.\n",
      "\t Ref: A red stop sign sitting on top of a wooden post.\n",
      "\t Pred: a red red pole sign sitting on top of a wooden post . <EOS>\n",
      "477.\n",
      "\t Ref: a blue plate filled with ravioli and a kids spoon.\n",
      "\t Pred: a a blue plate filled with <UNK> and a toy pasta . <EOS>\n",
      "478.\n",
      "\t Ref: Two zebras graze in some sparse ground in the sun.\n",
      "\t Pred: two people grazing grazing in some <UNK> ground in the sun . <EOS>\n",
      "479.\n",
      "\t Ref: a number of animals with a building in the background.\n",
      "\t Pred: a a number of animals with a building in the background . <EOS>\n",
      "480.\n",
      "\t Ref: A dumpster sitting in front of a building covered in graffiti.\n",
      "\t Pred: <UNK> a <UNK> sitting in front of a building covered in graffiti . <EOS>\n",
      "481.\n",
      "\t Ref: A small pizza with an assortment of toppings.\n",
      "\t Pred: a a small pizza with an assortment of toppings . <EOS>\n",
      "482.\n",
      "\t Ref: A woman plugs one ear in order to hear her cell phone.\n",
      "\t Pred: a a woman <UNK> to bow <UNK> <UNK> to <UNK> her cell phone . <EOS>\n",
      "483.\n",
      "\t Ref: A group of people standing on a beach flying a red kite.\n",
      "\t Pred: a of group of people standing on a park flying a yellow hit . <EOS>\n",
      "484.\n",
      "\t Ref: A young woman carries a Frisbee through a field.\n",
      "\t Pred: a young young woman <UNK> a kite through a field . <EOS>\n",
      "485.\n",
      "\t Ref: A man flying through the air holding a yellow frisbee.\n",
      "\t Pred: a a man flying through the air holding a yellow surfer . <EOS>\n",
      "486.\n",
      "\t Ref: Two cats getting into a sink in a bathroom.\n",
      "\t Pred: a two cats getting into a sink in a bathroom . <EOS>\n",
      "487.\n",
      "\t Ref: two zebras are standing neck to neck.\n",
      "\t Pred: the two bears are standing grazing to neck . <EOS>\n",
      "488.\n",
      "\t Ref: A little boy chewing on a tooth brush that is still in the wrapper.\n",
      "\t Pred: a a little boy <UNK> on a <UNK> brush that is displayed in the <UNK> . <EOS>\n",
      "489.\n",
      "\t Ref: Group of people eating from bowls of food on wooden table.\n",
      "\t Pred: a group of people eating from bowls of food on wooden table . <EOS>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490.\n",
      "\t Ref: A man and a boy playing with baseballs and baseball gloves.\n",
      "\t Pred: a a man and a boy playing with <UNK> and baseball <UNK> . <EOS>\n",
      "491.\n",
      "\t Ref: A young child standing near a train at a stop.\n",
      "\t Pred: a a young child standing near a train at a pole . <EOS>\n",
      "492.\n",
      "\t Ref: A black cat lying on his back on a bed.\n",
      "\t Pred: a large black cat lying on his back on a bed . <EOS>\n",
      "493.\n",
      "\t Ref: Two jet liners flying near the ocean under a blue sky.\n",
      "\t Pred: a red kite <UNK> flying near the ocean under a blue sky . <EOS>\n",
      "494.\n",
      "\t Ref: A group of very pretty yellow flowers in a glass vase.\n",
      "\t Pred: a a picture of very pretty yellow flowers in a glass vase . <EOS>\n",
      "495.\n",
      "\t Ref: A woman in a graduation gown holding an umbrella.\n",
      "\t Pred: a a woman in a <UNK> <UNK> holding an umbrella . <EOS>\n",
      "496.\n",
      "\t Ref: An orange street sign beside a snowy road announces a detour.\n",
      "\t Pred: a an orange orange sign along a palm road <UNK> a <UNK> . <EOS>\n",
      "497.\n",
      "\t Ref: A shelf filled with flowers and cards and gifts.\n",
      "\t Pred: a a shelf filled with flowers and <UNK> and <UNK> . <EOS>\n",
      "498.\n",
      "\t Ref: A city street is crowded with people and no cars.\n",
      "\t Pred: a a city street is crowded with people and no cars . <EOS>\n",
      "499.\n",
      "\t Ref: A black and white photo of a garden near a brick wall.\n",
      "\t Pred: a black black and white photo of a garden near a brick building . <EOS>\n",
      "500.\n",
      "\t Ref: A group of people including military personnel play soccer together.\n",
      "\t Pred: a a group of people including flat <UNK> their soccer together . <EOS>\n",
      "Average bleu score: 0.42623571630391743\n"
     ]
    }
   ],
   "source": [
    "# Perform inference for all validation sequences and report the average BLEU score\n",
    "# Your code goes here\n",
    "\n",
    "total_bleu = 0\n",
    "for val_sentence_index, sentence in enumerate(val_sentences):\n",
    "    pred_sentence = seq2seq_inference(sentence, encoder, decoder)\n",
    "    bleu = compute_bleu(sentence, pred_sentence) # reference, prediction\n",
    "    print('{}.'.format(val_sentence_index + 1))\n",
    "    print('\\t Ref: {}'.format(sentence))\n",
    "    print('\\t Pred: {}'.format(pred_sentence))\n",
    "    total_bleu += bleu\n",
    "\n",
    "print('Average bleu score: {}'.format(total_bleu / (val_sentence_index + 1)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Encoding as Generic Feature Representation\n",
    "\n",
    "We now use the final hidden state of our encoder, to identify the nearest neighbor amongst the training sentences for each sentence in our validation data.\n",
    "\n",
    "It would be effective to first define a method that would generate all of the hidden states and store these hidden states **on the CPU**, and then loop over the generated hidden states to identify/output the nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (30) : unknown error at d:\\pytorch\\pytorch\\torch\\lib\\thc\\generic/THCTensorCopy.c:20",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-c3af210cb067>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mtrain_hidden_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_sentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msentence_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_sentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mhidden_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_encoder_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# This is a numpy array of shape (300,)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mtrain_hidden_repr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msentence_index\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden_repr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msentence_index\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-78-c3af210cb067>\u001b[0m in \u001b[0;36mfinal_encoder_hidden\u001b[1;34m(sentence, encoder, embeddings)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Convert everything pytorch Variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0minput_sentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_hot_sentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0minput_sentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_sentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# Encoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\variable.py\u001b[0m in \u001b[0;36mcuda\u001b[1;34m(self, device, async)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masync\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 298\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mCudaTransfer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masync\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\_functions\\tensor.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(ctx, i, device, async)\u001b[0m\n\u001b[0;32m    199\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masync\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0masync\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masync\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0masync\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[1;34m(self, device, async)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masync\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cuda runtime error (30) : unknown error at d:\\pytorch\\pytorch\\torch\\lib\\thc\\generic/THCTensorCopy.c:20"
     ]
    }
   ],
   "source": [
    "def final_encoder_hidden(sentence, encoder, embeddings=one_hot_embeddings):\n",
    "    # Your code goes here\n",
    "    # Assume sentence is not already in one-hot\n",
    "    numberized = preprocess_numberize(sentence)\n",
    "    one_hot_sentence = embeddings[numberized]\n",
    "    sentence_length = one_hot_sentence.shape[0]\n",
    "    \n",
    "    # Convert everything pytorch Variable\n",
    "    input_sentence = torch.from_numpy(one_hot_sentence)\n",
    "    input_sentence = Variable(input_sentence).double().cuda()\n",
    "    \n",
    "    # Encoder\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    encoder_hidden = (encoder_hidden, encoder_hidden)\n",
    "    \n",
    "    for index_word in np.arange(sentence_length-1, 0, -1): # Skipping SOS, otherwise needs to be -1\n",
    "        encoder_input = input_sentence[index_word]\n",
    "        encoder_input = encoder_input.view(1, 1, vocabularySize)\n",
    "        encoder_hidden = encoder(encoder_input, encoder_hidden) # Gets hidden for next input\n",
    "        \n",
    "    # hidden is (h_n, c_n), we only need h_n\n",
    "    return encoder_hidden[0].squeeze().data.cpu().numpy()\n",
    "    \n",
    "    \n",
    "\n",
    "# Now run all training data and validation data to store hidden states\n",
    "start = time.time()\n",
    "train_hidden_repr = np.zeros(shape=(len(train_sentences), 300))\n",
    "for sentence_index, sentence in enumerate(train_sentences):\n",
    "    hidden_repr = final_encoder_hidden(sentence, encoder) # This is a numpy array of shape (300,)\n",
    "    train_hidden_repr[sentence_index] = hidden_repr\n",
    "    if sentence_index % 10000 == 0:\n",
    "        print('%s (%d %d%%)' % (timeSince(start, s_index / n_iters),\n",
    "                                     s_index, s_index / n_iters * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now get nearest neighbors and print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Effectiveness of word2vec\n",
    "\n",
    "We now repeat everything done above using word2vec embeddings in place of one-hot embeddings. This will require re-running steps 1-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
