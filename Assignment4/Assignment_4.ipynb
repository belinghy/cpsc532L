{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belin\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from gensim.models import Word2Vec\n",
    "from IPython import display\n",
    "from nltk import word_tokenize\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models, transforms\n",
    "\n",
    "import json\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition\n",
    "\n",
    "For this assignment, you will reuse the dataset you downloaded in assignment 2. This dataset contains a very large set of images, approximately 80K training images and 100 validation images, with multiple tags for each image. However that data *lacks captions* for the images, which is **vital** for this assignment. To obtain the captions for this assignment, download a few data files as shown below and add them to your `data/annotations` folder from assignment 2.\n",
    "\n",
    "`wget https://s3-us-west-2.amazonaws.com/cpsc532l-data/a4_data.zip`\n",
    "\n",
    "Following the data downloading and unzipping, the code below loads in the data into memory accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "( 0 , 0 ,.,.) = \n",
       "  0.0039  0.0078  0.0039  ...   0.0471  0.0471  0.0314\n",
       "  0.0039  0.0039  0.0039  ...   0.0353  0.0353  0.0392\n",
       "  0.0039  0.0039  0.0039  ...   0.0392  0.0392  0.0510\n",
       "           ...             ⋱             ...          \n",
       "  0.7137  0.7294  0.7137  ...   0.1686  0.1843  0.1686\n",
       "  0.7059  0.6902  0.6863  ...   0.1765  0.1804  0.2039\n",
       "  0.6784  0.6667  0.6706  ...   0.1922  0.2157  0.2275\n",
       "\n",
       "( 0 , 1 ,.,.) = \n",
       "  0.1490  0.1490  0.1412  ...   0.0039  0.0039  0.0039\n",
       "  0.1451  0.1412  0.1373  ...   0.0039  0.0039  0.0039\n",
       "  0.1412  0.1373  0.1373  ...   0.0039  0.0039  0.0039\n",
       "           ...             ⋱             ...          \n",
       "  0.4392  0.4667  0.4549  ...   0.2588  0.2745  0.2863\n",
       "  0.4353  0.4235  0.4196  ...   0.2745  0.2980  0.3137\n",
       "  0.4118  0.4000  0.4000  ...   0.3020  0.3176  0.3020\n",
       "\n",
       "( 0 , 2 ,.,.) = \n",
       "  0.5294  0.5294  0.5294  ...   0.1451  0.1412  0.1333\n",
       "  0.5255  0.5333  0.5373  ...   0.1725  0.1451  0.1412\n",
       "  0.5373  0.5490  0.5451  ...   0.2314  0.1843  0.1608\n",
       "           ...             ⋱             ...          \n",
       "  0.0118  0.0078  0.0078  ...   0.5216  0.5294  0.5137\n",
       "  0.0078  0.0078  0.0118  ...   0.5098  0.5216  0.5216\n",
       "  0.0078  0.0118  0.0039  ...   0.5294  0.5255  0.4784\n",
       "[torch.cuda.FloatTensor of size 1x3x224x224 (GPU 0)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a global transformer to appropriately scale images and subsequently convert them to a Tensor.\n",
    "img_size = 224\n",
    "loader = transforms.Compose([\n",
    "  transforms.Resize(img_size),\n",
    "  transforms.CenterCrop(img_size),\n",
    "  transforms.ToTensor(),\n",
    "]) \n",
    "def load_image(filename, volatile=False):\n",
    "    \"\"\"\n",
    "    Simple function to load and preprocess the image.\n",
    "\n",
    "    1. Open the image.\n",
    "    2. Scale/crop it and convert it to a float tensor.\n",
    "    3. Convert it to a variable (all inputs to PyTorch models must be variables).\n",
    "    4. Add another dimension to the start of the Tensor (b/c VGG expects a batch).\n",
    "    5. Move the variable onto the GPU.\n",
    "    \"\"\"\n",
    "    image = Image.open(filename).convert('RGB')\n",
    "    image_tensor = loader(image).float()\n",
    "    image_var = Variable(image_tensor, volatile=volatile).unsqueeze(0)\n",
    "    return image_var.cuda()\n",
    "\n",
    "load_image('data/train2014/COCO_train2014_000000000009.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load annotations file for the training images.\n",
    "mscoco_train = json.load(open('data/annotations/train_captions.json'))\n",
    "train_ids = [entry['id'] for entry in mscoco_train['images']]\n",
    "train_id_to_file = {entry['id']: 'data/train2014/' + entry['file_name'] for entry in mscoco_train['images']}\n",
    "\n",
    "# Extract out the captions for the training images\n",
    "train_id_set = set(train_ids)\n",
    "train_id_to_captions = defaultdict(list)\n",
    "for entry in mscoco_train['annotations']:\n",
    "    if entry['image_id'] in train_id_set:\n",
    "        train_id_to_captions[entry['image_id']].append(entry['caption'])\n",
    "\n",
    "# Load annotations file for the validation images.\n",
    "mscoco_val = json.load(open('data/annotations/val_captions.json'))\n",
    "val_ids = [entry['id'] for entry in mscoco_val['images']]\n",
    "val_id_to_file = {entry['id']: 'data/val2014/' + entry['file_name'] for entry in mscoco_val['images']}\n",
    "\n",
    "# Extract out the captions for the validation images\n",
    "val_id_set = set(val_ids)\n",
    "val_id_to_captions = defaultdict(list)\n",
    "for entry in mscoco_val['annotations']:\n",
    "    if entry['image_id'] in val_id_set:\n",
    "        val_id_to_captions[entry['image_id']].append(entry['caption'])\n",
    "\n",
    "# Load annotations file for the testing images\n",
    "mscoco_test = json.load(open('data/annotations/test_captions.json'))\n",
    "test_ids = [entry['id'] for entry in mscoco_test['images']]\n",
    "test_id_to_file = {entry['id']: 'data/val2014/' + entry['file_name'] for entry in mscoco_test['images']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "We do the same preprocessing done in assignment 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = [sentence for caption_set in train_id_to_captions.values() for sentence in caption_set]\n",
    "\n",
    "# Lower-case the sentence, tokenize them and add <SOS> and <EOS> tokens\n",
    "sentences = [[\"<SOS>\"] + word_tokenize(sentence.lower()) + [\"<EOS>\"] for sentence in sentences]\n",
    "\n",
    "# Create the vocabulary. Note that we add an <UNK> token to represent words not in our vocabulary.\n",
    "vocabularySize = 1000\n",
    "word_counts = Counter([word for sentence in sentences for word in sentence])\n",
    "vocabulary = [\"<UNK>\"] + [e[0] for e in word_counts.most_common(vocabularySize-1)]\n",
    "word2index = {word:index for index,word in enumerate(vocabulary)}\n",
    "one_hot_embeddings = np.eye(vocabularySize)\n",
    "\n",
    "# Build the word2vec embeddings\n",
    "wordEncodingSize = 300\n",
    "filtered_sentences = [[word for word in sentence if word in word2index] for sentence in sentences]\n",
    "w2v = Word2Vec(filtered_sentences, min_count=0, size=wordEncodingSize)\n",
    "w2v_embeddings = np.concatenate((np.zeros((1, wordEncodingSize)), w2v.wv.syn0))\n",
    "\n",
    "# Define the max sequence length to be the longest sentence in the training data. \n",
    "maxSequenceLength = max([len(sentence) for sentence in sentences])\n",
    "\n",
    "def preprocess_numberize(sentence):\n",
    "    \"\"\"\n",
    "    Given a sentence, in the form of a string, this function will preprocess it\n",
    "    into list of numbers (denoting the index into the vocabulary).\n",
    "    \"\"\"\n",
    "    tokenized = word_tokenize(sentence.lower())\n",
    "        \n",
    "    # Add the <SOS>/<EOS> tokens and numberize (all unknown words are represented as <UNK>).\n",
    "    tokenized = [\"<SOS>\"] + tokenized + [\"<EOS>\"]\n",
    "    numberized = [word2index.get(word, 0) for word in tokenized]\n",
    "    \n",
    "    return numberized\n",
    "\n",
    "def preprocess_one_hot(sentence):\n",
    "    \"\"\"\n",
    "    Given a sentence, in the form of a string, this function will preprocess it\n",
    "    into a numpy array of one-hot vectors.\n",
    "    \"\"\"\n",
    "    numberized = preprocess_numberize(sentence)\n",
    "    \n",
    "    # Represent each word as it's one-hot embedding\n",
    "    one_hot_embedded = one_hot_embeddings[numberized]\n",
    "    \n",
    "    return one_hot_embedded\n",
    "\n",
    "def preprocess_word2vec(sentence):\n",
    "    \"\"\"\n",
    "    Given a sentence, in the form of a string, this function will preprocess it\n",
    "    into a numpy array of word2vec embeddings.\n",
    "    \"\"\"\n",
    "    numberized = preprocess_numberize(sentence)\n",
    "    \n",
    "    # Represent each word as it's one-hot embedding\n",
    "    w2v_embedded = w2v_embeddings[numberized]\n",
    "    \n",
    "    return w2v_embedded\n",
    "\n",
    "def compute_bleu(reference_sentences, predicted_sentence):\n",
    "    \"\"\"\n",
    "    Given a list of reference sentences, and a predicted sentence, compute the BLEU similary between them.\n",
    "    \"\"\"\n",
    "    reference_tokenized = [word_tokenize(ref_sent.lower()) for ref_sent in reference_sentences]\n",
    "    predicted_tokenized = word_tokenize(predicted_sentence.lower())\n",
    "    return sentence_bleu(reference_tokenized, predicted_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup Image Encoder\n",
    "\n",
    "We load in the pre-trained VGG-16 model, and remove the final layer, as done in assignment 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "vgg_model = models.vgg16(pretrained=True).cuda()\n",
    "\n",
    "class VggMinusOneModel(torch.nn.Module):\n",
    "    def __init__(self, vgg_model):\n",
    "        \"\"\"\n",
    "        When constructing the model, we initialize two linear modules and assign them\n",
    "        as class fields. We also, as done earlier, remove the final layer of the vgg model.\n",
    "        \"\"\"\n",
    "        super(VggMinusOneModel, self).__init__()\n",
    "        self.features = vgg_model.features\n",
    "        self.classifier = nn.Sequential(*list(vgg_model.classifier.children())[:-1])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Pass the input through the network, applying the sigmoid activation function after each layer.\n",
    "        \"\"\"\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Setup a Language Decoder\n",
    "\n",
    "We're going to reuse our decoder from Assignment 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "use_cuda = True\n",
    "class DecoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.project = nn.Linear(4096, self.hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = F.relu(input)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output = self.out(output)\n",
    "        # Dont need this here since it's already in loss function\n",
    "        # Topk still works because max before softmax is also max after softmax\n",
    "        # output = F.log_softmax(output.squeeze())\n",
    "        output = output.squeeze()\n",
    "        return output.unsqueeze(0), hidden\n",
    "\n",
    "    def initHidden(self, init_size, image_features):\n",
    "        result = self.project(image_features)\n",
    "        result = F.relu(result)\n",
    "        # result = Variable(result)\n",
    "        # result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train encoder-decoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "\n",
    "# The next two functions are part of some other deep learning frameworks, but PyTorch\n",
    "# has not yet implemented them. We can find some commonly-used open source worked arounds\n",
    "# after searching around a bit: https://gist.github.com/jihunchoi/f1434a77df9db1bb337417854b398df1.\n",
    "def _sequence_mask(sequence_length, max_len=None):\n",
    "    if max_len is None:\n",
    "        max_len = sequence_length.data.max()\n",
    "    batch_size = sequence_length.size(0)\n",
    "    seq_range = torch.arange(0, max_len).long()\n",
    "    seq_range_expand = seq_range.unsqueeze(0).expand(batch_size, max_len)\n",
    "    seq_range_expand = Variable(seq_range_expand)\n",
    "    if sequence_length.is_cuda:\n",
    "        seq_range_expand = seq_range_expand.cuda()\n",
    "    seq_length_expand = (sequence_length.unsqueeze(1)\n",
    "                         .expand_as(seq_range_expand))\n",
    "    return seq_range_expand < seq_length_expand\n",
    "\n",
    "\n",
    "def compute_loss(logits, target, length):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        logits: A Variable containing a FloatTensor of size\n",
    "            (batch, max_len, num_classes) which contains the\n",
    "            unnormalized probability for each class.\n",
    "        target: A Variable containing a LongTensor of size\n",
    "            (batch, max_len) which contains the index of the true\n",
    "            class for each corresponding step.\n",
    "        length: A Variable containing a LongTensor of size (batch,)\n",
    "            which contains the length of each data in a batch.\n",
    "\n",
    "    Returns:\n",
    "        loss: An average loss value masked by the length.\n",
    "    \"\"\"\n",
    "    # logits_flat: (batch * max_len, num_classes)\n",
    "    logits_flat = logits.view(-1, logits.size(-1))\n",
    "    # log_probs_flat: (batch * max_len, num_classes)\n",
    "    log_probs_flat = F.log_softmax(logits_flat)\n",
    "    # target_flat: (batch * max_len, 1)\n",
    "    target_flat = target.view(-1, 1)\n",
    "    # losses_flat: (batch * max_len, 1)\n",
    "    losses_flat = -torch.gather(log_probs_flat, dim=1, index=target_flat)\n",
    "    # losses: (batch, max_len)\n",
    "    losses = losses_flat.view(*target.size())\n",
    "    # mask: (batch, max_len)\n",
    "    mask = _sequence_mask(sequence_length=length, max_len=target.size(1))\n",
    "    losses = losses * mask.float()\n",
    "    loss = losses.sum() / length.float().sum()\n",
    "    return loss\n",
    "\n",
    "def train(input_image,\n",
    "          input_variables, \n",
    "          target_variables, \n",
    "          input_lens,\n",
    "          encoder, \n",
    "          decoder, \n",
    "          encoder_optimizer, \n",
    "          decoder_optimizer, \n",
    "          criterion, \n",
    "          embeddings=one_hot_embeddings, \n",
    "          teacher_force=True,\n",
    "          train_encoder=False):\n",
    "    if train_encoder:\n",
    "        encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_variables.size()[0]\n",
    "    target_length = target_variables.size()[0]\n",
    "\n",
    "    # Pass through the encoder\n",
    "    image_features = encoder(input_image)\n",
    "    \n",
    "    \n",
    "    # Construct the decoder input (initially <SOS> for every batch)\n",
    "    decoder_input = Variable(torch.FloatTensor([[embeddings[word2index[\"<SOS>\"]]\n",
    "                                                for i in range(input_variables.size(1))]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    # Set the initial hidden state of the decoder to be the last hidden state of the encoder\n",
    "    last_hidden = torch.stack([decoder.initHidden(image_features.size(1), image_features).squeeze() \n",
    "                               for i,length in enumerate(input_lens)]).unsqueeze(0)\n",
    "    decoder_hidden = (last_hidden, last_hidden)\n",
    "\n",
    "    # Prepare the results tensor\n",
    "    all_decoder_outputs = Variable(torch.zeros(*input_variables.size()))\n",
    "    if use_cuda:\n",
    "        all_decoder_outputs = all_decoder_outputs.cuda()\n",
    "        \n",
    "    all_decoder_outputs[0] = decoder_input\n",
    "        \n",
    "    # Iterate over the indices after the first.\n",
    "    for t in range(1,target_length):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "    \n",
    "        if random.random() <= 0.9:\n",
    "            decoder_input = input_variables[t].unsqueeze(0)\n",
    "        else:\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "                       \n",
    "            #Prepare the inputs\n",
    "            decoder_input = torch.stack([Variable(torch.FloatTensor(embeddings[ni])).cuda()\n",
    "                                         for ni in topi.squeeze()]).unsqueeze(0)\n",
    "        \n",
    "        # Save the decoder output\n",
    "        all_decoder_outputs[t] = decoder_output\n",
    "        \n",
    "    loss = compute_loss(all_decoder_outputs.transpose(0,1).contiguous(),\n",
    "                        target_variables.transpose(0,1).contiguous(), \n",
    "                        Variable(torch.LongTensor(input_lens)).cuda())\n",
    "\n",
    "    loss.backward()\n",
    "    \n",
    "    torch.nn.utils.clip_grad_norm(encoder.parameters(), 10.0)\n",
    "    torch.nn.utils.clip_grad_norm(decoder.parameters(), 10.0)\n",
    "\n",
    "    if train_encoder:\n",
    "        encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0]\n",
    "\n",
    "def pad_seq(arr, length, pad_token):\n",
    "    \"\"\"\n",
    "    Pad an array to a length with a token.\n",
    "    \"\"\"\n",
    "    if len(arr) == length:\n",
    "        return np.array(arr)\n",
    "    \n",
    "    return np.concatenate((arr, [pad_token]*(length - len(arr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = VggMinusOneModel(vgg_model)\n",
    "decoder = DecoderLSTM(input_size=len(vocabulary), hidden_size=300, output_size=len(vocabulary)).cuda()\n",
    "# Load model\n",
    "#decoder.load_state_dict(torch.load('./model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.824213981628418\n",
      "a a a a a blanket blanket blanket blanket blanket blanket blanket side side passing passing passing passing passing\n",
      "a a a a a close feet that that passing passing passing passing passing passing passing passing passing passing\n",
      "0 4.490217208862305\n",
      "a <UNK> <UNK> <UNK> <UNK> <UNK> a <UNK> <UNK> <EOS>\n",
      "a <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <EOS>\n",
      "0 4.352753162384033\n",
      "a <UNK> <UNK> <UNK> <UNK> <UNK> a a a a . <EOS>\n",
      "a <UNK> <UNK> <UNK> <UNK> <UNK> a a a a . <EOS>\n",
      "0 4.232475757598877\n",
      "a <UNK> <UNK> a a <UNK> a a a . <EOS>\n",
      "a <UNK> <UNK> a a <UNK> a a . <EOS>\n",
      "0 4.084676265716553\n",
      "a <UNK> <UNK> a <UNK> <UNK> a a . <EOS>\n",
      "a <UNK> <UNK> a <UNK> <UNK> a <UNK> . <EOS>\n",
      "0 4.110964775085449\n",
      "a <UNK> <UNK> with a <UNK> and a <UNK> . <EOS>\n",
      "a <UNK> <UNK> a <UNK> <UNK> a a . <EOS>\n",
      "0 3.8718371391296387\n",
      "a <UNK> is with a <UNK> and a <UNK> . <EOS>\n",
      "a <UNK> of a <UNK> of a <UNK> of a <UNK> . <EOS>\n",
      "0 3.6940701007843018\n",
      "a <UNK> with a <UNK> and a <UNK> . <EOS>\n",
      "a <UNK> of a <UNK> of a <UNK> of a <UNK> . <EOS>\n",
      "0 3.5201570987701416\n",
      "a <UNK> with a <UNK> and a <UNK> and . <EOS>\n",
      "a <UNK> of a <UNK> <UNK> a <UNK> . <EOS>\n",
      "0 3.2768187522888184\n",
      "a <UNK> with a <UNK> and <UNK> and <UNK> . <EOS>\n",
      "a <UNK> <UNK> <UNK> <UNK> in a <UNK> of a <UNK> . <EOS>\n",
      "0 3.37326717376709\n",
      "a <UNK> with a <UNK> and <UNK> and a <UNK> . <EOS>\n",
      "a <UNK> of a <UNK> in a <UNK> in a <UNK> . <EOS>\n",
      "0 2.9518442153930664\n",
      "a <UNK> with a <UNK> and <UNK> on the . <EOS>\n",
      "a <UNK> of a <UNK> of a <UNK> of a <UNK> . <EOS>\n",
      "0 2.8350770473480225\n",
      "a <UNK> with a wooden with <UNK> <UNK> . <EOS>\n",
      "a man <UNK> <UNK> a <UNK> at a <UNK> . <EOS>\n",
      "0 2.9163730144500732\n",
      "a <UNK> with a <UNK> with <UNK> <UNK> and a <UNK> . <EOS>\n",
      "a woman <UNK> <UNK> <UNK> <UNK> to a <UNK> . <EOS>\n",
      "0 2.7522172927856445\n",
      "a <UNK> <UNK> with a <UNK> and chairs with <UNK> . <EOS>\n",
      "a woman in a <UNK> of a <UNK> <UNK> . <EOS>\n",
      "0 2.6097776889801025\n",
      "a <UNK> with <UNK> <UNK> <UNK> on the wall . <EOS>\n",
      "a <UNK> <UNK> in a <UNK> <UNK> . <EOS>\n",
      "0 2.496058225631714\n",
      "a long with with a wooden chairs and a <UNK> . <EOS>\n",
      "a woman <UNK> <UNK> to a <UNK> of food . <EOS>\n",
      "0 2.3065314292907715\n",
      "a long table with a wooden chairs and chairs <EOS>\n",
      "a woman <UNK> a at a food . <EOS>\n",
      "0 2.3383588790893555\n",
      "a long table with a wooden chairs with a table . <EOS>\n",
      "a woman <UNK> a a <UNK> with food <EOS>\n",
      "0 2.2172224521636963\n",
      "a long table with a wooden chairs and a table . <EOS>\n",
      "a woman <UNK> a <UNK> at a table with a table <EOS>\n",
      "0 1.8785946369171143\n",
      "a long table with a wooden chairs with a <UNK> . <EOS>\n",
      "a <UNK> <UNK> <UNK> in a small kitchen . <EOS>\n",
      "0 1.9478211402893066\n",
      "a long table with a wooden <UNK> and chairs . <EOS>\n",
      "a woman <UNK> preparing food at a kitchen table . <EOS>\n",
      "0 1.7290658950805664\n",
      "a long table with a plant with chairs and <UNK> <UNK> . <EOS>\n",
      "a woman preparing a food at a table with food <EOS>\n",
      "0 1.6764922142028809\n",
      "a long table with a plant on the wall . <EOS>\n",
      "a people <UNK> a food a <UNK> of food . <EOS>\n",
      "0 1.6485588550567627\n",
      "a long table with a plant with chairs and chairs <EOS>\n",
      "a woman <UNK> at a counter of a <UNK> <EOS>\n",
      "0 1.506964921951294\n",
      "a long table with a plant with chairs with a wooden table . <EOS>\n",
      "a group of people are at a table with a <UNK> <EOS>\n",
      "0 1.4791576862335205\n",
      "a long table with a flower <UNK> and chairs . <EOS>\n",
      "a woman <UNK> at a table with food on the counter . <EOS>\n",
      "0 1.329355239868164\n",
      "a long table with a flower <UNK> and chairs <EOS>\n",
      "a woman <UNK> standing at a table with food <EOS>\n",
      "0 1.2826558351516724\n",
      "a long table with a plant <UNK> top of it surrounded with wooden chairs <EOS>\n",
      "a group of people standing at a table with food making pizzas . <EOS>\n",
      "0 1.271615743637085\n",
      "a long table with a plant on top of it surrounded with wooden chairs <EOS>\n",
      "a group of people are getting of food table of a table <EOS>\n",
      "0 1.2376326322555542\n",
      "a long restaurant has a plant <UNK> on the middle for <UNK> <EOS>\n",
      "a group of people standing at a table with wine making pizzas . <EOS>\n",
      "0 1.0334233045578003\n",
      "a long table with a plant <UNK> top of it surrounded with wooden chairs <EOS>\n",
      "a group of people are getting food off of the table <EOS>\n",
      "0 1.0574448108673096\n",
      "a long table with a plant <UNK> back of a middle for <UNK> <EOS>\n",
      "a group of people standing at a table preparing food together <EOS>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-f934c4f6007d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# Get the sentences in the batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_id_to_file\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_id_to_captions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-f2d09b044460>\u001b[0m in \u001b[0;36mload_image\u001b[1;34m(filename, volatile)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \"\"\"\n\u001b[0;32m     18\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RGB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mimage_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mimage_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvolatile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvolatile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimage_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \"\"\"\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "\"\"\"\n",
    "This section is for testing only.  Using the first 100 pictures in the training set,\n",
    "manually checking if the result is ok.\n",
    "\n",
    "Result looks good after a few epochs.\n",
    "\"\"\"\n",
    "encoder.train()\n",
    "encoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=0.001) \n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=0.001) \n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "\n",
    "num_epochs = 1000\n",
    "for _ in range(num_epochs):\n",
    "    for i, train_id in enumerate(train_ids[0:100]):\n",
    "        # Get the sentences in the batch\n",
    "        img = load_image(train_id_to_file[train_id])\n",
    "        sentences = train_id_to_captions[train_id]\n",
    "        \n",
    "        # Get the sentence lengths\n",
    "        sentence_lens = [len(preprocess_numberize(sentence)) for sentence in sentences]\n",
    "        \n",
    "        # Sort by the sentence lengths\n",
    "        sorted_indices = sorted(list(range(len(sentence_lens))), key=lambda i: sentence_lens[i], reverse=True)\n",
    "        sentences = [sentences[i] for i in sorted_indices if sentence_lens[i] > 0]\n",
    "        \n",
    "        # Filter out 0 sentence lengths\n",
    "        sentence_lens = [sentence_lens[i] for i in sorted_indices if sentence_lens[i] > 0]\n",
    "        \n",
    "        # Determine length to pad everything to\n",
    "        max_len = max(sentence_lens)\n",
    "        \n",
    "        # Preprocess all of the sentences in each batch\n",
    "        one_hot_embedded_list = [preprocess_one_hot(sentence) for sentence in sentences]\n",
    "        one_hot_embedded_list_padded = [pad_seq(embed, max_len, np.zeros(len(vocabulary))) \n",
    "                                        for embed in one_hot_embedded_list]\n",
    "                \n",
    "        numberized_list = [preprocess_numberize(sentence) for sentence in sentences]\n",
    "        numberized_list_padded = [pad_seq(numb, max_len, 0).astype(torch.LongTensor) for numb in numberized_list]\n",
    "                \n",
    "        # Convert to variables\n",
    "        input_variable = Variable(torch.FloatTensor(one_hot_embedded_list_padded)).cuda()\n",
    "        target_variable = Variable(torch.LongTensor(numberized_list_padded)).cuda()\n",
    "        \n",
    "        # Transpose from batch_size x max_seq_len x vocab_size to max_seq_len x batch_size x vocab_size\n",
    "        input_variable = input_variable.transpose(0, 1)\n",
    "        target_variable = target_variable.transpose(0, 1)\n",
    "\n",
    "        loss = train(img,\n",
    "                     input_variable,\n",
    "                     target_variable, \n",
    "                     sentence_lens,\n",
    "                     encoder,\n",
    "                     decoder, \n",
    "                     encoder_optimizer,\n",
    "                     decoder_optimizer, \n",
    "                     criterion,\n",
    "                     train_encoder=False)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(i,loss)\n",
    "            \n",
    "        if i % 1000 == 0:\n",
    "            print(seq2seq_inference(load_image(train_id_to_file[train_ids[0]])))\n",
    "            print(seq2seq_inference(load_image(train_id_to_file[train_ids[16]])))\n",
    "            torch.save(encoder.state_dict(), 'encoder_model')\n",
    "            torch.save(decoder.state_dict(), 'decoder_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.843596458435059\n",
      "a a a a a a a a a a a a with with with with with with with\n",
      "a a a a a a a a a with with with with with with with with with with\n",
      "1000 4.103964328765869\n",
      "a <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a <UNK> of scissors on a table with a <UNK> <UNK> . <EOS>\n",
      "2000 2.8461992740631104\n",
      "a <UNK> <UNK> with a clock on a table . <EOS>\n",
      "a man is standing in front of a <UNK> <UNK> . <EOS>\n",
      "3000 3.3704841136932373\n",
      "a man in a <UNK> <UNK> in a <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> <UNK> in a <UNK> . <EOS>\n",
      "4000 3.5742483139038086\n",
      "a <UNK> <UNK> <UNK> on a table with a <UNK> . <EOS>\n",
      "a man sitting on a table with a laptop . <EOS>\n",
      "5000 2.6229162216186523\n",
      "a table topped with lots of pizza on a plate . <EOS>\n",
      "a man and a woman in a living room with a <UNK> . <EOS>\n",
      "6000 3.3872735500335693\n",
      "a living room with a <UNK> and a <UNK> . <EOS>\n",
      "a man standing in front of a <UNK> <UNK> <UNK> . <EOS>\n",
      "7000 3.3154046535491943\n",
      "a <UNK> <UNK> <UNK> <UNK> <UNK> on a table <EOS>\n",
      "a man sitting on a couch playing a video game . <EOS>\n",
      "8000 2.672028064727783\n",
      "a pizza is on a table with a <UNK> <UNK> . <EOS>\n",
      "a man in a living room playing a video game . <EOS>\n",
      "9000 3.7439169883728027\n",
      "a man <UNK> a <UNK> <UNK> pizza . <EOS>\n",
      "a man <UNK> a <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "10000 2.6816530227661133\n",
      "a <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is <UNK> a pizza with a <UNK> . <EOS>\n",
      "11000 3.8195011615753174\n",
      "a <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a little boy with a <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "12000 3.1228461265563965\n",
      "a <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a person holding a <UNK> <UNK> <UNK> . <EOS>\n",
      "13000 2.7730021476745605\n",
      "a cat is sitting on a bed with a <UNK> . <EOS>\n",
      "a man is <UNK> a <UNK> in a <UNK> . <EOS>\n",
      "14000 2.9632716178894043\n",
      "a person riding skis down a snow covered slope . <EOS>\n",
      "a person in a <UNK> shirt holding a <UNK> <UNK> . <EOS>\n",
      "15000 2.9335391521453857\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> on a <UNK> . <EOS>\n",
      "a man is a <UNK> <UNK> a <UNK> . <EOS>\n",
      "16000 1.7913141250610352\n",
      "a man is <UNK> his skateboard on a rail . <EOS>\n",
      "a man is <UNK> a <UNK> on a table . <EOS>\n",
      "17000 3.4130048751831055\n",
      "a <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a suit and tie standing next to a window . <EOS>\n",
      "18000 3.30352783203125\n",
      "a <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "people in suits and ties are <UNK> <UNK> . <EOS>\n",
      "19000 3.355473518371582\n",
      "a <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man <UNK> a <UNK> in a <UNK> of a <UNK> . <EOS>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-df6289ca9243>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     54\u001b[0m                      \u001b[0mdecoder_optimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m                      \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m                      train_encoder=False)\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-60-68c147459e23>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(input_image, input_variables, target_variables, input_lens, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, embeddings, teacher_force, train_encoder)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtrain_encoder\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\utils\\clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm\u001b[1;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0mparam_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m             \u001b[0mtotal_norm\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mparam_norm\u001b[0m \u001b[1;33m**\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_norm\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "\"\"\"\n",
    "As described in the handout.  First part of training should not backprop\n",
    "through the encoder.  This part has train_encoder set to False\n",
    "\"\"\"\n",
    "encoder.eval()\n",
    "encoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=0.01) \n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=0.01) \n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "\n",
    "num_epochs = 2\n",
    "for _ in range(num_epochs):\n",
    "    for i, train_id in enumerate(train_ids):\n",
    "        # Get the sentences in the batch\n",
    "        img = load_image(train_id_to_file[train_id])\n",
    "        sentences = train_id_to_captions[train_id]\n",
    "        \n",
    "        # Get the sentence lengths\n",
    "        sentence_lens = [len(preprocess_numberize(sentence)) for sentence in sentences]\n",
    "        \n",
    "        # Sort by the sentence lengths\n",
    "        sorted_indices = sorted(list(range(len(sentence_lens))), key=lambda i: sentence_lens[i], reverse=True)\n",
    "        sentences = [sentences[i] for i in sorted_indices if sentence_lens[i] > 0]\n",
    "        \n",
    "        # Filter out 0 sentence lengths\n",
    "        sentence_lens = [sentence_lens[i] for i in sorted_indices if sentence_lens[i] > 0]\n",
    "        \n",
    "        # Determine length to pad everything to\n",
    "        max_len = max(sentence_lens)\n",
    "        \n",
    "        # Preprocess all of the sentences in each batch\n",
    "        one_hot_embedded_list = [preprocess_one_hot(sentence) for sentence in sentences]\n",
    "        one_hot_embedded_list_padded = [pad_seq(embed, max_len, np.zeros(len(vocabulary))) \n",
    "                                        for embed in one_hot_embedded_list]\n",
    "                \n",
    "        numberized_list = [preprocess_numberize(sentence) for sentence in sentences]\n",
    "        numberized_list_padded = [pad_seq(numb, max_len, 0).astype(torch.LongTensor) for numb in numberized_list]\n",
    "                \n",
    "        # Convert to variables\n",
    "        input_variable = Variable(torch.FloatTensor(one_hot_embedded_list_padded)).cuda()\n",
    "        target_variable = Variable(torch.LongTensor(numberized_list_padded)).cuda()\n",
    "        \n",
    "        # Transpose from batch_size x max_seq_len x vocab_size to max_seq_len x batch_size x vocab_size\n",
    "        input_variable = input_variable.transpose(0, 1)\n",
    "        target_variable = target_variable.transpose(0, 1)\n",
    "\n",
    "        loss = train(img,\n",
    "                     input_variable,\n",
    "                     target_variable, \n",
    "                     sentence_lens,\n",
    "                     encoder,\n",
    "                     decoder, \n",
    "                     encoder_optimizer,\n",
    "                     decoder_optimizer, \n",
    "                     criterion,\n",
    "                     train_encoder=False)\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print(i,loss)\n",
    "            \n",
    "        if i % 1000 == 0:\n",
    "            print(seq2seq_inference(load_image(train_id_to_file[train_ids[0]])))\n",
    "            print(seq2seq_inference(load_image(train_id_to_file[train_ids[16]])))\n",
    "            torch.save(encoder.state_dict(), 'encoder_model')\n",
    "            torch.save(decoder.state_dict(), 'decoder_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19001 3.0840699672698975\n",
      "a living <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "there is a man with a <UNK> <UNK> on her phone . <EOS>\n",
      "20001 2.921872615814209\n",
      "a <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "21001 2.5674633979797363\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> <UNK> a <UNK> . <EOS>\n",
      "22001 2.9738781452178955\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "23001 2.2764458656311035\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> <UNK> a <UNK> . <EOS>\n",
      "24001 3.4217801094055176\n",
      "a cat is sitting on a table with a <UNK> . <EOS>\n",
      "a man is holding a <UNK> <UNK> in a kitchen . <EOS>\n",
      "25001 2.2303073406219482\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "26001 2.7840054035186768\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "27001 2.644818067550659\n",
      "a cat sitting on a table with a <UNK> of <UNK> . <EOS>\n",
      "a man is a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "28001 3.129906177520752\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "29001 2.3953194618225098\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man <UNK> a <UNK> in front of a <UNK> . <EOS>\n",
      "30001 2.8970823287963867\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is a <UNK> <UNK> a <UNK> . <EOS>\n",
      "31001 2.7796592712402344\n",
      "a bathroom with a <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is sitting on a bench with a <UNK> . <EOS>\n",
      "32001 2.5069408416748047\n",
      "a bathroom with a <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is holding a <UNK> in his hand . <EOS>\n",
      "33001 2.6857144832611084\n",
      "a bathroom with a <UNK> <UNK> on the floor . <EOS>\n",
      "a man is a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "34001 3.450860023498535\n",
      "a bathroom with a <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is sitting on a bench with a <UNK> . <EOS>\n",
      "35001 3.856304883956909\n",
      "a bathroom with a <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is a <UNK> <UNK> a <UNK> . <EOS>\n",
      "36001 2.9344444274902344\n",
      "a bathroom with a toilet and a sink . <EOS>\n",
      "a man in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "37001 3.2405593395233154\n",
      "a bathroom with a <UNK> and a <UNK> <UNK> . <EOS>\n",
      "a man in a suit and tie standing in a kitchen . <EOS>\n",
      "38001 3.543152332305908\n",
      "a bathroom with a <UNK> and a <UNK> <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "39001 2.914525032043457\n",
      "a bathroom with a <UNK> and a <UNK> <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "40001 3.483422040939331\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "41001 2.6776649951934814\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "42001 2.9498178958892822\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "43001 2.9555788040161133\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a <UNK> shirt and a <UNK> <UNK> . <EOS>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-c1a6e9159b3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m19001\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# Get the sentences in the batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_id_to_file\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_id_to_captions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-f2d09b044460>\u001b[0m in \u001b[0;36mload_image\u001b[1;34m(filename, volatile)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;36m5.\u001b[0m \u001b[0mMove\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvariable\u001b[0m \u001b[0monto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mGPU\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \"\"\"\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RGB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mimage_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mimage_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvolatile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvolatile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2476\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2477\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2478\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "\"\"\"\n",
    "Continue previous with lowered LR\n",
    "\"\"\"\n",
    "encoder.eval()\n",
    "encoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=0.001) \n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=0.001) \n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "\n",
    "num_epochs = 2\n",
    "for _ in range(num_epochs):\n",
    "    for i, train_id in enumerate(train_ids[19001:]):\n",
    "        # Get the sentences in the batch\n",
    "        img = load_image(train_id_to_file[train_id])\n",
    "        sentences = train_id_to_captions[train_id]\n",
    "        \n",
    "        # Get the sentence lengths\n",
    "        sentence_lens = [len(preprocess_numberize(sentence)) for sentence in sentences]\n",
    "        \n",
    "        # Sort by the sentence lengths\n",
    "        sorted_indices = sorted(list(range(len(sentence_lens))), key=lambda i: sentence_lens[i], reverse=True)\n",
    "        sentences = [sentences[i] for i in sorted_indices if sentence_lens[i] > 0]\n",
    "        \n",
    "        # Filter out 0 sentence lengths\n",
    "        sentence_lens = [sentence_lens[i] for i in sorted_indices if sentence_lens[i] > 0]\n",
    "        \n",
    "        # Determine length to pad everything to\n",
    "        max_len = max(sentence_lens)\n",
    "        \n",
    "        # Preprocess all of the sentences in each batch\n",
    "        one_hot_embedded_list = [preprocess_one_hot(sentence) for sentence in sentences]\n",
    "        one_hot_embedded_list_padded = [pad_seq(embed, max_len, np.zeros(len(vocabulary))) \n",
    "                                        for embed in one_hot_embedded_list]\n",
    "                \n",
    "        numberized_list = [preprocess_numberize(sentence) for sentence in sentences]\n",
    "        numberized_list_padded = [pad_seq(numb, max_len, 0).astype(torch.LongTensor) for numb in numberized_list]\n",
    "                \n",
    "        # Convert to variables\n",
    "        input_variable = Variable(torch.FloatTensor(one_hot_embedded_list_padded)).cuda()\n",
    "        target_variable = Variable(torch.LongTensor(numberized_list_padded)).cuda()\n",
    "        \n",
    "        # Transpose from batch_size x max_seq_len x vocab_size to max_seq_len x batch_size x vocab_size\n",
    "        input_variable = input_variable.transpose(0, 1)\n",
    "        target_variable = target_variable.transpose(0, 1)\n",
    "\n",
    "        loss = train(img,\n",
    "                     input_variable,\n",
    "                     target_variable, \n",
    "                     sentence_lens,\n",
    "                     encoder,\n",
    "                     decoder, \n",
    "                     encoder_optimizer,\n",
    "                     decoder_optimizer, \n",
    "                     criterion,\n",
    "                     train_encoder=False)\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print(i+19001,loss)\n",
    "            \n",
    "        if i % 1000 == 0:\n",
    "            print(seq2seq_inference(load_image(train_id_to_file[train_ids[0]])))\n",
    "            print(seq2seq_inference(load_image(train_id_to_file[train_ids[16]])))\n",
    "            torch.save(encoder.state_dict(), 'encoder_model')\n",
    "            torch.save(decoder.state_dict(), 'decoder_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43000 2.941473960876465\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "44000 2.502918243408203\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man holding a <UNK> phone while standing next to a <UNK> . <EOS>\n",
      "45000 2.8168702125549316\n",
      "a <UNK> of a <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "46000 3.3024306297302246\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "47000 2.469322681427002\n",
      "a <UNK> of a <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "48000 3.287797689437866\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "49000 2.8343281745910645\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "50000 2.6264383792877197\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "51000 2.8816537857055664\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "52000 2.906334161758423\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "53000 2.57908034324646\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is holding a <UNK> in his hand . <EOS>\n",
      "54000 2.2046353816986084\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "55000 2.9381463527679443\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "56000 2.466142416000366\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "57000 2.725680112838745\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a suit and tie holding a <UNK> . <EOS>\n",
      "58000 4.267619609832764\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "59000 2.3539106845855713\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is a <UNK> <UNK> a <UNK> of <UNK> . <EOS>\n",
      "60000 2.7012693881988525\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "61000 3.841657876968384\n",
      "a <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "62000 2.5324337482452393\n",
      "a <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a woman is a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "63000 2.7788374423980713\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "64000 2.6241302490234375\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "65000 3.518291473388672\n",
      "a train <UNK> <UNK> a <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "66000 2.6726415157318115\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "67000 2.373030662536621\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "68000 2.6423227787017822\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "69000 3.1767029762268066\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is holding a <UNK> <UNK> in a <UNK> . <EOS>\n",
      "70000 3.703159809112549\n",
      "a train is <UNK> on the tracks in a <UNK> . <EOS>\n",
      "a man is a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "71000 2.141496181488037\n",
      "a bathroom with a <UNK> and a <UNK> <UNK> . <EOS>\n",
      "a man is a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "72000 3.1595633029937744\n",
      "a group of people sitting at a table with a cake . <EOS>\n",
      "a man is <UNK> a <UNK> of a <UNK> . <EOS>\n",
      "73000 2.432941436767578\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is sitting at a table with a <UNK> of food . <EOS>\n",
      "74000 3.4704878330230713\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "75000 3.0329079627990723\n",
      "a bathroom with a <UNK> and a <UNK> <UNK> . <EOS>\n",
      "a man is a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "76000 2.0916965007781982\n",
      "a group of people sitting at a table with food and drinks . <EOS>\n",
      "a man is a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "77000 2.4467384815216064\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is sitting in a <UNK> with a <UNK> . <EOS>\n",
      "78000 2.8909194469451904\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is holding a <UNK> of <UNK> . <EOS>\n",
      "79000 2.385214328765869\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is holding a <UNK> <UNK> in a kitchen . <EOS>\n",
      "80000 2.415024995803833\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is holding a <UNK> of <UNK> . <EOS>\n",
      "81000 2.929643154144287\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a woman in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "82000 2.6885933876037598\n",
      "a <UNK> of a <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a woman sitting at a table with a <UNK> of food . <EOS>\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "\"\"\"\n",
    "Continue from last stopped\n",
    "\"\"\"\n",
    "encoder.eval()\n",
    "encoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=0.001) \n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=0.001) \n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "\n",
    "num_epochs = 1\n",
    "for _ in range(num_epochs):\n",
    "    for i, train_id in enumerate(train_ids[43000:]):\n",
    "        # Get the sentences in the batch\n",
    "        img = load_image(train_id_to_file[train_id])\n",
    "        sentences = train_id_to_captions[train_id]\n",
    "        \n",
    "        # Get the sentence lengths\n",
    "        sentence_lens = [len(preprocess_numberize(sentence)) for sentence in sentences]\n",
    "        \n",
    "        # Sort by the sentence lengths\n",
    "        sorted_indices = sorted(list(range(len(sentence_lens))), key=lambda i: sentence_lens[i], reverse=True)\n",
    "        sentences = [sentences[i] for i in sorted_indices if sentence_lens[i] > 0]\n",
    "        \n",
    "        # Filter out 0 sentence lengths\n",
    "        sentence_lens = [sentence_lens[i] for i in sorted_indices if sentence_lens[i] > 0]\n",
    "        \n",
    "        # Determine length to pad everything to\n",
    "        max_len = max(sentence_lens)\n",
    "        \n",
    "        # Preprocess all of the sentences in each batch\n",
    "        one_hot_embedded_list = [preprocess_one_hot(sentence) for sentence in sentences]\n",
    "        one_hot_embedded_list_padded = [pad_seq(embed, max_len, np.zeros(len(vocabulary))) \n",
    "                                        for embed in one_hot_embedded_list]\n",
    "                \n",
    "        numberized_list = [preprocess_numberize(sentence) for sentence in sentences]\n",
    "        numberized_list_padded = [pad_seq(numb, max_len, 0).astype(torch.LongTensor) for numb in numberized_list]\n",
    "                \n",
    "        # Convert to variables\n",
    "        input_variable = Variable(torch.FloatTensor(one_hot_embedded_list_padded)).cuda()\n",
    "        target_variable = Variable(torch.LongTensor(numberized_list_padded)).cuda()\n",
    "        \n",
    "        # Transpose from batch_size x max_seq_len x vocab_size to max_seq_len x batch_size x vocab_size\n",
    "        input_variable = input_variable.transpose(0, 1)\n",
    "        target_variable = target_variable.transpose(0, 1)\n",
    "\n",
    "        loss = train(img,\n",
    "                     input_variable,\n",
    "                     target_variable, \n",
    "                     sentence_lens,\n",
    "                     encoder,\n",
    "                     decoder, \n",
    "                     encoder_optimizer,\n",
    "                     decoder_optimizer, \n",
    "                     criterion,\n",
    "                     train_encoder=False)\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print(i+43000,loss)\n",
    "            \n",
    "        if i % 1000 == 0:\n",
    "            print(seq2seq_inference(load_image(train_id_to_file[train_ids[0]])))\n",
    "            print(seq2seq_inference(load_image(train_id_to_file[train_ids[16]])))\n",
    "            torch.save(encoder.state_dict(), 'encoder_model')\n",
    "            torch.save(decoder.state_dict(), 'decoder_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.0907952785491943\n",
      "a group of people standing around a <UNK> <UNK> . <EOS>\n",
      "a man and a woman are sitting at a table . <EOS>\n",
      "1000 3.3327207565307617\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man standing in front of a table with a plate of food . <EOS>\n",
      "2000 2.6742820739746094\n",
      "a room with a <UNK> and a <UNK> . <EOS>\n",
      "a man is sitting at a table with a plate of food . <EOS>\n",
      "3000 2.7755188941955566\n",
      "a man sitting on a couch with a laptop computer . <EOS>\n",
      "a man and a woman sitting at a table with a plate of food . <EOS>\n",
      "4000 2.64864444732666\n",
      "a living room with a couch , coffee table and a television . <EOS>\n",
      "a man sitting at a table with a <UNK> of pizza . <EOS>\n",
      "5000 2.0205068588256836\n",
      "a living room with a couch and a table <EOS>\n",
      "a man sitting at a table with a laptop . <EOS>\n",
      "6000 2.7240707874298096\n",
      "a living room with a couch , coffee table , and a television . <EOS>\n",
      "a woman in a <UNK> <UNK> <UNK> a <UNK> . <EOS>\n",
      "7000 2.3396198749542236\n",
      "a living room with a <UNK> and a <UNK> <EOS>\n",
      "a man in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "8000 2.651663303375244\n",
      "a living room with a couch , a couch , and a television . <EOS>\n",
      "a man holding a nintendo wii game controller . <EOS>\n",
      "9000 2.7041358947753906\n",
      "a living room with a couch , chair and a table . <EOS>\n",
      "a man <UNK> a <UNK> of pizza on a table . <EOS>\n",
      "10000 2.413695812225342\n",
      "a living room with a couch , chair and a table . <EOS>\n",
      "a man in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "11000 2.657479763031006\n",
      "a <UNK> <UNK> <UNK> a <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man <UNK> a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "12000 2.402169704437256\n",
      "a <UNK> <UNK> <UNK> a <UNK> <UNK> <UNK> . <EOS>\n",
      "a man and a woman are sitting on a table . <EOS>\n",
      "13000 2.089303970336914\n",
      "a <UNK> <UNK> <UNK> a <UNK> <UNK> <UNK> . <EOS>\n",
      "a <UNK> <UNK> with a <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "14000 2.848573923110962\n",
      "a <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man and woman are eating pizza at a table . <EOS>\n",
      "15000 2.144780397415161\n",
      "a <UNK> of broccoli and <UNK> on a <UNK> . <EOS>\n",
      "a man and a woman are sitting at a table eating pizza . <EOS>\n",
      "16000 1.4636902809143066\n",
      "a <UNK> of a <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is <UNK> a <UNK> <UNK> <UNK> . <EOS>\n",
      "17000 3.479947566986084\n",
      "a <UNK> of a <UNK> <UNK> with a <UNK> <UNK> . <EOS>\n",
      "a man and woman are sitting at a table eating a meal . <EOS>\n",
      "18000 2.869131326675415\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man and woman are sitting in a room . <EOS>\n",
      "19000 2.7042036056518555\n",
      "a <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is <UNK> a <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "20000 2.707585334777832\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is sitting in a chair with a <UNK> of bananas . <EOS>\n",
      "21000 2.6603031158447266\n",
      "a <UNK> of a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "a man is holding a <UNK> of bananas . <EOS>\n",
      "22000 2.2491488456726074\n",
      "a <UNK> of <UNK> <UNK> on a <UNK> . <EOS>\n",
      "a man in a suit and tie standing in front of a <UNK> . <EOS>\n",
      "23000 2.5311012268066406\n",
      "a <UNK> of a <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man and woman sitting at a table with a cake . <EOS>\n",
      "24000 1.815927267074585\n",
      "a cat is sitting on a chair in a room . <EOS>\n",
      "a group of people sitting around a table with a cake . <EOS>\n",
      "25000 2.459275007247925\n",
      "a cat is sitting on a <UNK> in a room . <EOS>\n",
      "a man sitting in a chair with a <UNK> . <EOS>\n",
      "26000 2.671840190887451\n",
      "a <UNK> of a <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is <UNK> a <UNK> of <UNK> <UNK> . <EOS>\n",
      "27000 2.38053035736084\n",
      "a <UNK> of a <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is sitting in a chair with a laptop . <EOS>\n",
      "28000 2.5395169258117676\n",
      "a giraffe standing in a <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is sitting at a table with a cake . <EOS>\n",
      "29000 3.064465045928955\n",
      "a <UNK> <UNK> <UNK> a <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is sitting on a table with a laptop . <EOS>\n",
      "30000 3.3231256008148193\n",
      "a living room with a couch , chair , and a television . <EOS>\n",
      "a man is sitting on a table with a laptop . <EOS>\n",
      "31000 1.8722831010818481\n",
      "a <UNK> <UNK> <UNK> a <UNK> <UNK> <UNK> . <EOS>\n",
      "a woman sitting at a table with a plate of food . <EOS>\n",
      "32000 3.5029377937316895\n",
      "a living room with a <UNK> and a <UNK> <EOS>\n",
      "a man and a woman are sitting at a table . <EOS>\n",
      "33000 2.8638293743133545\n",
      "a <UNK> of a <UNK> <UNK> <UNK> on a <UNK> . <EOS>\n",
      "a man is sitting on a bench with a <UNK> <UNK> . <EOS>\n",
      "34000 2.8398773670196533\n",
      "a living room with a <UNK> and a <UNK> . <EOS>\n",
      "a man sitting at a table with a <UNK> of food . <EOS>\n",
      "35000 2.295468330383301\n",
      "a <UNK> of <UNK> <UNK> <UNK> in a <UNK> . <EOS>\n",
      "a man is sitting at a table with a <UNK> of food . <EOS>\n",
      "36000 2.3524465560913086\n",
      "a living room with a couch and a table <EOS>\n",
      "a man sitting at a table with a <UNK> of food . <EOS>\n",
      "37000 2.935208559036255\n",
      "a living room with a couch and a table <EOS>\n",
      "a man and woman sitting on a couch with a dog . <EOS>\n",
      "38000 2.28676700592041\n",
      "a <UNK> of a <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man sitting at a table with a <UNK> of food . <EOS>\n",
      "39000 2.113351583480835\n",
      "a bathroom with a sink and a mirror <EOS>\n",
      "a man sitting at a table with a <UNK> of food . <EOS>\n",
      "40000 3.2481861114501953\n",
      "a vase filled with flowers and a <UNK> of flowers . <EOS>\n",
      "a woman sitting at a table with a <UNK> of food . <EOS>\n",
      "41000 3.7785439491271973\n",
      "a kitchen with a <UNK> and a <UNK> . <EOS>\n",
      "a man sitting at a table with a plate of food . <EOS>\n",
      "42000 2.3822553157806396\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> <UNK> a <UNK> . <EOS>\n",
      "43000 2.638293504714966\n",
      "a living room with a couch and a table <EOS>\n",
      "a man sitting at a table with a plate of food . <EOS>\n",
      "44000 3.3590776920318604\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is holding a cell phone in his hand . <EOS>\n",
      "45000 2.3931448459625244\n",
      "a living room with a couch and a table <EOS>\n",
      "a man is holding a <UNK> phone while standing in a room . <EOS>\n",
      "46000 3.021110773086548\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a woman in a kitchen preparing food . <EOS>\n",
      "47000 2.2883365154266357\n",
      "a living room with a couch , chairs , and a television . <EOS>\n",
      "a man in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "48000 2.9517018795013428\n",
      "a living room with a couch , chair , and a television . <EOS>\n",
      "a man <UNK> a pizza with a <UNK> <UNK> . <EOS>\n",
      "49000 2.9867684841156006\n",
      "a living room with a couch and a table <EOS>\n",
      "a man is a <UNK> <UNK> <UNK> a <UNK> . <EOS>\n",
      "50000 2.4994349479675293\n",
      "there is a <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "two men are <UNK> a cake with a <UNK> . <EOS>\n",
      "51000 2.638967514038086\n",
      "a living room with a couch and a table <EOS>\n",
      "a man in a <UNK> <UNK> a pizza . <EOS>\n",
      "52000 2.4991776943206787\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "53000 2.5120484828948975\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is a <UNK> <UNK> a pizza . <EOS>\n",
      "54000 2.286595106124878\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man and a woman sitting at a table with a <UNK> of food . <EOS>\n",
      "55000 2.7911980152130127\n",
      "a <UNK> of a <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is holding a <UNK> of <UNK> . <EOS>\n",
      "56000 1.9853273630142212\n",
      "a person is holding a <UNK> <UNK> pizza . <EOS>\n",
      "a man is holding a hot dog in a <UNK> . <EOS>\n",
      "57000 2.3681328296661377\n",
      "a <UNK> of a <UNK> <UNK> with a <UNK> <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "58000 3.2155590057373047\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man and a woman sitting at a table with a plate of food . <EOS>\n",
      "59000 2.11069655418396\n",
      "a dog is sitting in a chair with a <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "60000 2.534364700317383\n",
      "a man sitting at a table with a plate of food . <EOS>\n",
      "a man in a <UNK> shirt and a <UNK> <UNK> <EOS>\n",
      "61000 3.386898994445801\n",
      "a cat is sitting on a table with a <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "62000 2.4934909343719482\n",
      "a group of people sitting around a table with a cake . <EOS>\n",
      "a man and a woman are sitting at a table . <EOS>\n",
      "63000 2.698470115661621\n",
      "a kitchen with a stove and a sink <EOS>\n",
      "a man sitting at a table with a plate of food . <EOS>\n",
      "64000 2.578700065612793\n",
      "a <UNK> of a <UNK> <UNK> with a <UNK> <UNK> . <EOS>\n",
      "a man and a woman are sitting at a table with a <UNK> of food . <EOS>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65000 2.948715925216675\n",
      "a cat is sitting on a chair in a room . <EOS>\n",
      "a man and woman sitting at a table with a cake . <EOS>\n",
      "66000 2.6634511947631836\n",
      "a <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man sitting at a table with a plate of food . <EOS>\n",
      "67000 2.455280065536499\n",
      "a cat sitting on a chair in a room . <EOS>\n",
      "a man sitting at a table with a plate of food . <EOS>\n",
      "68000 2.4511003494262695\n",
      "a cat sitting on top of a table next to a <UNK> . <EOS>\n",
      "a man in a suit and tie standing next to a woman . <EOS>\n",
      "69000 2.608196973800659\n",
      "a <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a suit and tie standing next to a table . <EOS>\n",
      "70000 2.87721848487854\n",
      "a cat sitting on top of a wooden chair . <EOS>\n",
      "a man sitting at a table with a plate of food . <EOS>\n",
      "71000 2.7080514430999756\n",
      "a cat is sitting on a bench in a <UNK> . <EOS>\n",
      "a man sitting at a table with a plate of food . <EOS>\n",
      "72000 2.7895944118499756\n",
      "a <UNK> <UNK> <UNK> a <UNK> in a <UNK> . <EOS>\n",
      "a man is <UNK> a <UNK> <UNK> <UNK> . <EOS>\n",
      "73000 2.1726672649383545\n",
      "a <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man sitting at a table with a plate of food . <EOS>\n",
      "74000 3.387246608734131\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is sitting at a table with a plate of food . <EOS>\n",
      "75000 2.953015089035034\n",
      "a kitchen with a stove and a <UNK> <UNK> . <EOS>\n",
      "a man sitting in a chair with a <UNK> in his hand . <EOS>\n",
      "76000 2.379685640335083\n",
      "a bathroom with a toilet and a sink . <EOS>\n",
      "a man is a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "77000 2.457493305206299\n",
      "a <UNK> <UNK> <UNK> in a <UNK> <UNK> . <EOS>\n",
      "a man sitting at a table with a <UNK> of food . <EOS>\n",
      "78000 2.7928476333618164\n",
      "a table with a <UNK> and a <UNK> <UNK> . <EOS>\n",
      "a man sitting at a table with a laptop . <EOS>\n",
      "79000 2.2865612506866455\n",
      "a vase of flowers sitting on a table . <EOS>\n",
      "a man sitting at a table with a <UNK> of food . <EOS>\n",
      "80000 2.1929118633270264\n",
      "a <UNK> of <UNK> <UNK> <UNK> on a <UNK> . <EOS>\n",
      "a man sitting at a table with a <UNK> of <UNK> . <EOS>\n",
      "81000 2.7479746341705322\n",
      "a <UNK> <UNK> <UNK> a <UNK> in a <UNK> . <EOS>\n",
      "a woman sitting at a table with a plate of food . <EOS>\n",
      "82000 2.468714475631714\n",
      "a table with a <UNK> and a <UNK> on it . <EOS>\n",
      "a woman sitting at a table with a plate of food . <EOS>\n",
      "0 3.4220497608184814\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man sitting at a table with a plate of food . <EOS>\n",
      "1000 3.135125160217285\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is sitting at a table with a plate of food . <EOS>\n",
      "2000 2.1628315448760986\n",
      "a kitchen with a stove , sink , and refrigerator . <EOS>\n",
      "a man is sitting at a table with a laptop . <EOS>\n",
      "3000 2.838003158569336\n",
      "a <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man sitting at a table with a plate of food . <EOS>\n",
      "4000 2.791999578475952\n",
      "a <UNK> <UNK> <UNK> a <UNK> <UNK> <UNK> . <EOS>\n",
      "a woman sitting at a table with a laptop . <EOS>\n",
      "5000 1.95703125\n",
      "a living room with a couch and a table <EOS>\n",
      "a man sitting at a table with a pizza . <EOS>\n",
      "6000 2.679109573364258\n",
      "a <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "7000 2.3687634468078613\n",
      "a living room with a couch , coffee table , and a table . <EOS>\n",
      "a man sitting at a table with a pizza . <EOS>\n",
      "8000 2.2066898345947266\n",
      "a <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man sitting on a couch with a laptop . <EOS>\n",
      "9000 2.734297513961792\n",
      "a toilet with a <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man holding a nintendo wii game controller . <EOS>\n",
      "10000 2.4615418910980225\n",
      "a <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "11000 2.500162363052368\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man sitting at a table with a plate of food . <EOS>\n",
      "12000 2.4140849113464355\n",
      "a <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is eating a hot dog in a <UNK> . <EOS>\n",
      "13000 2.2383766174316406\n",
      "a man is standing in front of a table with a cake . <EOS>\n",
      "a man is eating a sandwich in a restaurant . <EOS>\n",
      "14000 2.5640335083007812\n",
      "a <UNK> of <UNK> <UNK> <UNK> on a table . <EOS>\n",
      "a man and a woman are eating a meal . <EOS>\n",
      "15000 2.087165594100952\n",
      "a living room with a couch , chair and a table . <EOS>\n",
      "a man is <UNK> a <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "16000 1.546007513999939\n",
      "a living room with a couch and a table <EOS>\n",
      "a man is <UNK> a <UNK> <UNK> on a <UNK> . <EOS>\n",
      "17000 3.623927593231201\n",
      "this is a <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man and a woman are sitting at a table eating pizza . <EOS>\n",
      "18000 3.049023389816284\n",
      "a <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a suit and tie standing in front of a mirror . <EOS>\n",
      "19000 2.557041883468628\n",
      "this <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man <UNK> a <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "20000 3.0402817726135254\n",
      "a <UNK> of a <UNK> <UNK> with a <UNK> of <UNK> . <EOS>\n",
      "a man in a suit and tie standing in front of a mirror . <EOS>\n",
      "21000 2.8652281761169434\n",
      "this is a picture of a <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a suit and tie standing next to a woman . <EOS>\n",
      "22000 2.1823291778564453\n",
      "this is a picture of a <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a suit and tie is standing in a <UNK> . <EOS>\n",
      "23000 2.806239128112793\n",
      "this is a <UNK> of a <UNK> <UNK> . <EOS>\n",
      "a man sitting at a table with a <UNK> of food . <EOS>\n",
      "24000 1.844648838043213\n",
      "this is a cat sitting on a chair <EOS>\n",
      "a group of people sitting around a table with a cake . <EOS>\n",
      "25000 2.4435338973999023\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man sitting at a table with a <UNK> of <UNK> . <EOS>\n",
      "26000 2.490823268890381\n",
      "this is a picture of a <UNK> <UNK> . <EOS>\n",
      "a man sitting at a table with a <UNK> of <UNK> . <EOS>\n",
      "27000 2.3939402103424072\n",
      "this is a <UNK> <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "a man sitting at a table with a <UNK> of food . <EOS>\n",
      "28000 2.4133543968200684\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is sitting at a table with a cake . <EOS>\n",
      "29000 3.1965441703796387\n",
      "a living room with a couch and a table <EOS>\n",
      "a man is sitting on a table with a <UNK> of <UNK> . <EOS>\n",
      "30000 3.095255136489868\n",
      "a <UNK> <UNK> <UNK> a <UNK> <UNK> <UNK> . <EOS>\n",
      "a man sitting at a table with a plate of food . <EOS>\n",
      "31000 1.954760193824768\n",
      "this is a picture of a <UNK> <UNK> . <EOS>\n",
      "a man sitting at a table with a pizza . <EOS>\n",
      "32000 3.279092311859131\n",
      "this is a picture of a giraffe in the <UNK> . <EOS>\n",
      "a man is sitting at a table with a <UNK> . <EOS>\n",
      "33000 2.744535207748413\n",
      "this is a picture of a fire hydrant on the sidewalk . <EOS>\n",
      "a man sitting on a bench with a laptop on his lap . <EOS>\n",
      "34000 2.850214958190918\n",
      "this is a picture of a <UNK> <UNK> . <EOS>\n",
      "a man is sitting at a table with a laptop . <EOS>\n",
      "35000 2.1255786418914795\n",
      "this is a picture of a <UNK> <UNK> . <EOS>\n",
      "a man is sitting at a table with a <UNK> of food . <EOS>\n",
      "36000 2.5692739486694336\n",
      "this is a picture of a <UNK> <UNK> . <EOS>\n",
      "a man sitting at a table with a plate of food . <EOS>\n",
      "37000 2.7922191619873047\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man sitting at a table with a plate of food . <EOS>\n",
      "38000 2.8382437229156494\n",
      "this is a <UNK> <UNK> with a <UNK> <UNK> . <EOS>\n",
      "a man sitting at a table with a <UNK> . <EOS>\n",
      "39000 2.10349702835083\n",
      "this is a picture of a <UNK> <UNK> . <EOS>\n",
      "a man sitting at a table with a plate of food . <EOS>\n",
      "40000 3.2330806255340576\n",
      "this is a picture of a living room with a <UNK> <EOS>\n",
      "a man sitting at a table with a plate of food . <EOS>\n",
      "41000 3.973085880279541\n",
      "this is a <UNK> of <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man sitting at a table with a plate of food . <EOS>\n",
      "42000 2.5672786235809326\n",
      "this living room with a <UNK> and a <UNK> . <EOS>\n",
      "a woman sitting at a table with a plate of food . <EOS>\n",
      "43000 2.5981392860412598\n",
      "this is a <UNK> of <UNK> <UNK> <UNK> . <EOS>\n",
      "a man sitting at a table with a plate of food . <EOS>\n",
      "44000 2.777508497238159\n",
      "this is a picture of a <UNK> <UNK> . <EOS>\n",
      "a man is holding a cell phone while sitting at a table . <EOS>\n",
      "45000 2.4444825649261475\n",
      "this is a <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is sitting at a table with a pizza . <EOS>\n",
      "46000 3.4641599655151367\n",
      "this is a picture of a <UNK> <UNK> <UNK> . <EOS>\n",
      "a woman is sitting at a table with a plate of food . <EOS>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47000 2.283838987350464\n",
      "this is a <UNK> <UNK> <UNK> in a <UNK> . <EOS>\n",
      "a group of people sitting around a table with a pizza . <EOS>\n",
      "48000 2.9064786434173584\n",
      "this is a picture of a living room with a couch and a <UNK> . <EOS>\n",
      "a man sitting at a table with a pizza . <EOS>\n",
      "49000 2.5519447326660156\n",
      "this living room with a <UNK> and a <UNK> . <EOS>\n",
      "a man is holding a <UNK> <UNK> <UNK> . <EOS>\n",
      "50000 2.6211280822753906\n",
      "this is a <UNK> of a <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> <UNK> a <UNK> . <EOS>\n",
      "51000 2.785151243209839\n",
      "this is a <UNK> of <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man and a woman are sitting at a table . <EOS>\n",
      "52000 2.475053071975708\n",
      "this is a <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man sitting at a table with a plate of food . <EOS>\n",
      "53000 2.416255235671997\n",
      "a living room with a <UNK> and a <UNK> . <EOS>\n",
      "a man and woman sitting at a table with plates of food . <EOS>\n",
      "54000 2.1566050052642822\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man sitting at a table with a plate of food . <EOS>\n",
      "55000 2.6428890228271484\n",
      "this is a <UNK> of <UNK> <UNK> <UNK> . <EOS>\n",
      "a man sitting at a table with a plate of food . <EOS>\n",
      "56000 2.0586442947387695\n",
      "this is a <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is <UNK> a <UNK> <UNK> <UNK> . <EOS>\n",
      "57000 2.8527843952178955\n",
      "this is a <UNK> of a <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "58000 3.051194429397583\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man sitting at a table with a plate of food . <EOS>\n",
      "59000 2.204674005508423\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is <UNK> a <UNK> <UNK> on a table . <EOS>\n",
      "60000 2.526660442352295\n",
      "a living room with a couch , chair , and a fireplace . <EOS>\n",
      "a man sitting at a table with a plate of food . <EOS>\n",
      "61000 3.609637498855591\n",
      "a bathroom with a sink and a toilet <EOS>\n",
      "a man sitting at a table with a plate of food . <EOS>\n",
      "62000 2.1507883071899414\n",
      "a <UNK> of a <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man sitting at a table with a <UNK> of cake . <EOS>\n",
      "63000 2.7171263694763184\n",
      "a <UNK> of <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man sitting at a table with a plate of food . <EOS>\n",
      "64000 2.665694236755371\n",
      "a <UNK> <UNK> <UNK> a <UNK> <UNK> <UNK> . <EOS>\n",
      "a man sitting at a table with a plate of food . <EOS>\n",
      "65000 2.8645639419555664\n",
      "a <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man in a suit and tie standing next to a woman . <EOS>\n",
      "66000 2.7546238899230957\n",
      "a <UNK> <UNK> <UNK> a <UNK> <UNK> <UNK> . <EOS>\n",
      "a man is standing in front of a <UNK> . <EOS>\n",
      "67000 2.4298059940338135\n",
      "a <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man sitting at a table with a <UNK> of food . <EOS>\n",
      "68000 2.387586832046509\n",
      "a cat sitting on a table next to a <UNK> . <EOS>\n",
      "a man in a suit and tie standing next to a woman . <EOS>\n",
      "69000 2.6487817764282227\n",
      "a cat sitting on top of a wooden chair . <EOS>\n",
      "a man sitting at a table with a plate of food . <EOS>\n",
      "70000 3.292771100997925\n",
      "a <UNK> <UNK> <UNK> a <UNK> <UNK> <UNK> . <EOS>\n",
      "a group of people sitting around a table with a cake . <EOS>\n",
      "71000 1.9760390520095825\n",
      "a <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a group of people sitting around a table with a cake . <EOS>\n",
      "72000 2.783710241317749\n",
      "this is a picture of a cat sitting on a bench . <EOS>\n",
      "a <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "73000 2.236499786376953\n",
      "this is a <UNK> <UNK> <UNK> in this kitchen <EOS>\n",
      "a group of people sitting around a table with a cake . <EOS>\n",
      "74000 3.0712244510650635\n",
      "this is a picture of a <UNK> <UNK> <UNK> . <EOS>\n",
      "a group of people sitting at a table with a cake . <EOS>\n",
      "75000 2.9487364292144775\n",
      "this is a picture of a <UNK> <UNK> <UNK> . <EOS>\n",
      "a woman sitting at a table with a plate of food . <EOS>\n",
      "76000 2.180041551589966\n",
      "this is a picture of a giraffe in the <UNK> . <EOS>\n",
      "a group of people sitting at a table with a cake . <EOS>\n",
      "77000 2.3992347717285156\n",
      "this is a picture of a cat that is sitting on a bench . <EOS>\n",
      "a man sitting at a table with a plate of food . <EOS>\n",
      "78000 2.90334415435791\n",
      "this is a picture of a <UNK> <UNK> . <EOS>\n",
      "a man sitting at a table with a plate of food . <EOS>\n",
      "79000 2.505044460296631\n",
      "this is a <UNK> of <UNK> <UNK> <UNK> <UNK> . <EOS>\n",
      "a man sitting at a table with a <UNK> of food . <EOS>\n",
      "80000 2.5129005908966064\n",
      "a <UNK> of a <UNK> <UNK> on a table . <EOS>\n",
      "a man sitting at a table with a plate of food . <EOS>\n",
      "81000 3.203336000442505\n",
      "this is a picture of a <UNK> <UNK> . <EOS>\n",
      "a woman sitting at a table with a plate of food . <EOS>\n",
      "82000 2.5050785541534424\n",
      "a man is a <UNK> <UNK> a <UNK> <UNK> . <EOS>\n",
      "a woman sitting at a table with a plate of food . <EOS>\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "\"\"\"\n",
    "Continue from last stopped\n",
    "\"\"\"\n",
    "encoder.train()\n",
    "encoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=0.001) \n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=0.001) \n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "\n",
    "num_epochs = 2\n",
    "for _ in range(num_epochs):\n",
    "    for i, train_id in enumerate(train_ids):\n",
    "        # Get the sentences in the batch\n",
    "        img = load_image(train_id_to_file[train_id])\n",
    "        sentences = train_id_to_captions[train_id]\n",
    "        \n",
    "        # Get the sentence lengths\n",
    "        sentence_lens = [len(preprocess_numberize(sentence)) for sentence in sentences]\n",
    "        \n",
    "        # Sort by the sentence lengths\n",
    "        sorted_indices = sorted(list(range(len(sentence_lens))), key=lambda i: sentence_lens[i], reverse=True)\n",
    "        sentences = [sentences[i] for i in sorted_indices if sentence_lens[i] > 0]\n",
    "        \n",
    "        # Filter out 0 sentence lengths\n",
    "        sentence_lens = [sentence_lens[i] for i in sorted_indices if sentence_lens[i] > 0]\n",
    "        \n",
    "        # Determine length to pad everything to\n",
    "        max_len = max(sentence_lens)\n",
    "        \n",
    "        # Preprocess all of the sentences in each batch\n",
    "        one_hot_embedded_list = [preprocess_one_hot(sentence) for sentence in sentences]\n",
    "        one_hot_embedded_list_padded = [pad_seq(embed, max_len, np.zeros(len(vocabulary))) \n",
    "                                        for embed in one_hot_embedded_list]\n",
    "                \n",
    "        numberized_list = [preprocess_numberize(sentence) for sentence in sentences]\n",
    "        numberized_list_padded = [pad_seq(numb, max_len, 0).astype(torch.LongTensor) for numb in numberized_list]\n",
    "                \n",
    "        # Convert to variables\n",
    "        input_variable = Variable(torch.FloatTensor(one_hot_embedded_list_padded)).cuda()\n",
    "        target_variable = Variable(torch.LongTensor(numberized_list_padded)).cuda()\n",
    "        \n",
    "        # Transpose from batch_size x max_seq_len x vocab_size to max_seq_len x batch_size x vocab_size\n",
    "        input_variable = input_variable.transpose(0, 1)\n",
    "        target_variable = target_variable.transpose(0, 1)\n",
    "\n",
    "        loss = train(img,\n",
    "                     input_variable,\n",
    "                     target_variable, \n",
    "                     sentence_lens,\n",
    "                     encoder,\n",
    "                     decoder, \n",
    "                     encoder_optimizer,\n",
    "                     decoder_optimizer, \n",
    "                     criterion,\n",
    "                     train_encoder=True)\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print(i,loss)\n",
    "            \n",
    "        if i % 1000 == 0:\n",
    "            print(seq2seq_inference(load_image(train_id_to_file[train_ids[0]])))\n",
    "            print(seq2seq_inference(load_image(train_id_to_file[train_ids[16]])))\n",
    "            torch.save(encoder.state_dict(), 'encoder_model')\n",
    "            torch.save(decoder.state_dict(), 'decoder_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. MAP and Sampling Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 57870 A restaurant has modern wooden tables and chairs.\n",
      "0 57870 A long restaurant table with rattan rounded back chairs.\n",
      "0 57870 a long table with a plant on top of it surrounded with wooden chairs \n",
      "0 57870 A long table with a flower arrangement in the middle for meetings\n",
      "0 57870 A table is adorned with wooden chairs with blue accents.\n",
      "1 384029 A man preparing desserts in a kitchen covered in frosting.\n",
      "1 384029 A chef is preparing and decorating many small pastries.\n",
      "1 384029 A baker prepares various types of baked goods.\n",
      "1 384029 a close up of a person grabbing a pastry in a container\n",
      "1 384029 Close up of a hand touching various pastries.\n",
      "2 222016 a big red telephone booth that a man is standing in\n",
      "2 222016 a person standing inside of a phone booth \n",
      "2 222016 this is an image of a man in a phone booth.\n",
      "2 222016 A man is standing in a red phone booth.\n",
      "2 222016 A man using a phone in a phone booth.\n",
      "3 520950 the kitchen is full of spices on the rack\n",
      "3 520950 A kitchen with counter, oven and other accessories.\n",
      "3 520950 A small kitchen that utilizes all of its space. \n",
      "3 520950 This small kitchen has pots, pans and spices on display\n",
      "3 520950 A VERY SMALL KITCHEN WITH A STOVE AND A SHELF OF POTS \n",
      "4 69675 A child and woman are cooking in the kitchen.\n",
      "4 69675 A woman glances at a young girl's cooking on the stovetop\n",
      "4 69675 A young girl and a woman preparing food in a kitchen.\n",
      "4 69675 a young person and an older person in a kitchen\n",
      "4 69675 Two women cooking on stove in a kitchen together.\n",
      "5 547471 A black and white image of a man in a suit wearing glasses walking through a door.\n",
      "5 547471 A nicely dressed man in a door way.\n",
      "5 547471 A man in glasses walks through an open door. \n",
      "5 547471  A man smiling and walking through a doorway.\n",
      "5 547471 A black and white photo of a man in suit and tie.\n",
      "6 122688 The huge clock on the wall is near a wooden table.\n",
      "6 122688 The clock has a large face with numbers.\n",
      "6 122688 a clock with big numbers at the end of a table\n",
      "6 122688 A table and chairs with a large clock on the wall.\n",
      "6 122688 a large clock on the wall above a radiator \n",
      "7 392136 A large bus and some people on the street.\n",
      "7 392136 Several people are standing on the sidewalk as a bus goes by.\n",
      "7 392136 Bus rushing by a group of people walking in a city.\n",
      "7 392136 A double-decker bus moving down the street as people stand waiting.\n",
      "7 392136 A group of people standing next to a yellow and blue double decker bus.\n",
      "8 398494 A bicycle parked in a kitchen with a stove and cabinets.\n",
      "8 398494 A black bicycle leaning against the kitchen cabinets.\n",
      "8 398494 small white kitchen with a bike and backpack parked in it\n",
      "8 398494 A bicycle leaning on the stove and cabinets located inside the kitchen.\n",
      "8 398494 A bicycle parked in a kitchen by the stove.\n",
      "9 90570 Two people in a food truck, one looking at an order.\n",
      "9 90570 A man in a beanie and glasses leans over a counter.\n",
      "9 90570 A man in a food cart looking down at a piece of paper.\n",
      "9 90570 a man with a beard and a blue shirt is making some food\n",
      "9 90570 A person working behind the counter of a food truck.\n",
      "10 504616 a person in white is standing in a kitchen\n",
      "10 504616 A chef slides a pizza into a brick oven.\n",
      "10 504616 a man wearing an apron and standing next to an oven\n",
      "10 504616 A man with a ball cap and an apron using a brick oven. \n",
      "10 504616 The baker is getting ready for his bread to be ready.\n",
      "11 161919 A person is cutting a roast with a fork and knife.\n",
      "11 161919 There is a man cutting meat on a cutting board\n",
      "11 161919 A man is slicing meat with a knife. \n",
      "11 161919 Man cutting a hot piece of meat on a cutting board. \n",
      "11 161919 A man cutting meat on a small cutting board.\n",
      "12 457732 a kitchen with a table and some chairs \n",
      "12 457732 A dark kitchen with several tables and chairs.\n",
      "12 457732 The room has table, chairs, counters and shelves.\n",
      "12 457732 a room filled with wooden table and chairs\n",
      "12 457732 a big kitchen filled with some tables and shelves \n",
      "13 44404 A kitchen has wood cabinets, a dishwasher, sink, and refrigerator. \n",
      "13 44404 The window above the kitchen sink is opened.\n",
      "13 44404 A kitchen with wood shelves and appliances. \n",
      "13 44404 a kitchen that has a stove and a icebox\n",
      "13 44404 A fridge, microwave and sink in the kitchen\n",
      "14 4428 A chef preparing food inside of a kitchen near  a window.\n",
      "14 4428 A cook is making food under a lamp.\n",
      "14 4428 A chief in a kitchen plating food out of a pan.\n",
      "14 4428 Sous chef adding sauce to a plate at the pass of a restaurant kitchen. \n",
      "14 4428 a person in a kitchen preparing food under a lamp\n",
      "15 170558 Adults using laptop computers while sitting at outdoor venue.\n",
      "15 170558 A row of men using laptops on side of a building.\n",
      "15 170558 A man is on his laptop while people looking on. \n",
      "15 170558 a number of people siting on a bench with a laptop\n",
      "15 170558 Young men sit next to each other working on laptops. \n",
      "16 405613 A group of men at a table preparing food together\n",
      "16 405613 some men standing around a counter while making a pizza \n",
      "16 405613 people preparing what they want to eat on a table\n",
      "16 405613 A group of people standing at a table with wine making pizzas. \n",
      "16 405613 THERE ARE PEOPLE THAT ARE GETTING FOOD OFF OF THE TABLE \n",
      "17 283524 a man cutting up vegetables on top of a food cart.\n",
      "17 283524 A man cutting up scallions at an outdoor table \n",
      "17 283524 A man chopping vegetables on a white board.\n",
      "17 283524 A man stands as he cuts up some vegetables.\n",
      "17 283524 A man stands with a knife and onions in front of a garage.\n",
      "18 37015 Chefs are preparing food at a restaurant as patrons exit.\n",
      "18 37015 A chef is cooking at the counter in front of a restaurant.\n",
      "18 37015 The view shows two young people and  a woman leaving an elaborate entry way that includes a curved wall and window, revealing chefs at work,\n",
      "18 37015 a restaurant that features a window to see the chefs cooking. \n",
      "18 37015 Several people walking outside of an Asian restaurant.\n",
      "19 71631 Dining room table set for a casual meal, with flowers.\n",
      "19 71631 A red table topped with four white place mats.\n",
      "19 71631 there is a dining room table with a red cloth and a vase with roses\n",
      "19 71631 a table with a red tablecloth and white placemats\n",
      "19 71631 A small dinning table with all red napkins and a red table cloth . \n",
      "20 491269 A very cluttered but very clean kept kitchen.\n",
      "20 491269 A small and cramped empty kitchen with overhead lighting \n",
      "20 491269 Looking into a small home kitchen with stove in a bar.\n",
      "20 491269 a small kitchen with two microwaves a fridge and stove\n",
      "20 491269 A full kitchen that is accented with the color red.\n",
      "21 365363 Two people flying a kite above pine trees.\n",
      "21 365363 A couple of people standing in a show covered field flying kites.\n",
      "21 365363 Two people flying a kite in a field with a forest in the background.\n",
      "21 365363 A man and a boy fly kites in the snow in front of pine trees.\n",
      "21 365363 a couple of people that have kites in the sky\n",
      "22 64460 A kitchen in a restaurant with food on the counter.\n",
      "22 64460 A restaurant kitchen with prepared food on the counter.\n",
      "22 64460 two people in a kitchen area preparing food\n",
      "22 64460 Two chefs preparing meals in the restaurant kitchen.\n",
      "22 64460 a kitchen with chefs and plated dishes of food.\n",
      "23 581674 Several kitchen workers making dishes in commercial kitchen.\n",
      "23 581674 A couple of men in a small kitchen.\n",
      "23 581674 a bunch of people cooking inside of a kitchen\n",
      "23 581674 The chefs are preparing for the upcoming dinner service.\n",
      "23 581674 A team of chefs working in a commercial kitchen.\n",
      "24 470072 a grill that has a bunch of burgers on it\n",
      "24 470072 Two men standing next to an oven with sandwiches\n",
      "24 470072 A restaurant's grill top is full of meats and sandwiches.\n",
      "24 470072 Food on a grill with people working \n",
      "24 470072 A view of a bunch of burgers being made on a grill.\n",
      "25 344806 A man laying on his stomach with a towel on his head.\n",
      "25 344806 someone that is laying face down on a bed\n",
      "25 344806 A man on his stomach in a white bed.\n",
      "25 344806 This is a photo of someones bare back.\n",
      "25 344806 A man is lying face down on the bed\n",
      "26 84427 A small cluttered kitchen with a window and sink.\n",
      "26 84427 A kitchen with a sink a dish rack on the wall and utensils hanging from a window. \n",
      "26 84427 A strange dark kitchen has an interesting curtain.\n",
      "26 84427 A crowded kitchen with dishes hanging from the walls\n",
      "26 84427 A kitchen with many utensils hanging from the window.\n",
      "27 317237 A small child eating noodles from a bowl in a kitchen \n",
      "27 317237 An Asian baby feeding himself noodles from a bowl.\n",
      "27 317237 a kid using a spoon eating from a plate\n",
      "27 317237 A little boy that has a spoon with food on it.\n",
      "27 317237 An asian child is eating noodles with a fork with help using his own hands in the kitchen.\n",
      "28 409382 People on a skateboard ramp with one doing a trick and one with skateboard on his head.\n",
      "28 409382 two boys sitting down one has his skate board on his head\n",
      "28 409382 A couple of young men sitting in a skate park.\n",
      "28 409382 Group of children entertaining. Selves in a skatepark\n",
      "28 409382 A man performs skateboard tricks while two onlookers watch, one with a skateboard on his head\n",
      "29 570608 a kitchen that has a microwave and some cabinets in it\n",
      "29 570608 a modern looking kitchen with steel countertops and utensils\n",
      "29 570608 The kitchen is full of stainless steel appliances.\n",
      "29 570608 a kitchen wit ha coffee make in the corner \n",
      "29 570608 A stainless steel kitchen countertop with appliances and utensils.\n",
      "30 469605 there is a man standing on a field talking on the phone\n",
      "30 469605 A man is standing in the grass talking on a phone.\n",
      "30 469605 The man talks on a cell phone far from three others sitting on a blanket.\n",
      "30 469605 A man in light colored clothing stands near white tents while people sit on grass on a blankent.\n",
      "30 469605 A man on a cellphone near a group of people on the lawn,\n",
      "31 356702 A couple of young men sitting in front of a child's laptop.\n",
      "31 356702 A pair of men looking at a tablet perched on a table.\n",
      "31 356702 Two men laugh as they look at a computer.\n",
      "31 356702 Two men are smiling looking at a laptop computer.\n",
      "31 356702 Two men happily working on a plastic computer\n",
      "32 405207 A large bottle of wine sitting on a kitchen counter.\n",
      "32 405207 A closeup of soup bowls, a bottle of wine and other food.\n",
      "32 405207 A wine bottle that is three fourths full is sitting on a table.\n",
      "32 405207 A corked bottle of wine near stacks of dishes and food.\n",
      "32 405207 a soup kitchen full of soup bowls and food \n",
      "33 472925 A stove top with pots and pans in a kitchen.\n",
      "33 472925 There is a pot and a skillet on the stove.\n",
      "33 472925 A stove that has several pots and pans on it.\n",
      "33 472925 Food cooking in a pot on the stove with dirty dishes on the counter. \n",
      "33 472925 A full view of a kitchen with pans and plates all over. \n",
      "34 214704 A young man that is sitting at a kitchen table is looking of to the side.\n",
      "34 214704 Bearded man in colorized image looks off to the side.\n",
      "34 214704 A man with a beard with his head turned sitting down.\n",
      "34 214704 A man at a table observing something away from him.\n",
      "34 214704 a person sitting down with a tv behind him\n",
      "35 279108 A woman feeding a man food from a spoon.\n",
      "35 279108 A woman offering a man a taste of something in front of other people.\n",
      "35 279108 A woman feeds a man a bite of food.\n",
      "35 279108 a woman is feeding something to a man\n",
      "35 279108 A woman spoon feeding an old man \n",
      "36 438422 A woman giving a taste test to a man. \n",
      "36 438422 A woman feeds a sample of her dish to a man in front of onlookers.\n",
      "36 438422 Man is fed a spoonful of food by a woman in front of other people. \n",
      "36 438422 Several people observing a woman feeding a man food inside a restaurant kitchen\n",
      "36 438422 A woman is giving a taste of her food to a man\n",
      "37 257350 a group of people riding bikes stopped in front of a building\n",
      "37 257350 A group of people on bicy les in front of a church.\n",
      "37 257350 Bike riders on the corner outside of a church.\n",
      "37 257350 Several children on bicycles outside a white church.\n",
      "37 257350 Several people on bikes in front of a building.\n",
      "38 393493 Little girl looking down at leaves with her bicycle with training wheels parked next to her.\n",
      "38 393493 A little girl in a red jumpsuit and sweater is near a red bike and red table.\n",
      "38 393493 A young child in a park next to a red bench and red bicycle that as training wheels.\n",
      "38 393493 A little girl standing next to a red bike near leaves.\n",
      "38 393493 Small child next to a picnic table and tricycle. \n",
      "39 62426 A sink and bath in a small room.\n",
      "39 62426 An ornate bathroom is adorned with yellow and multicolor tiles.\n",
      "39 62426 The bathroom is decorated in an elaborate style.\n",
      "39 62426 An old Mediterranean yellow mosaic tiled bathroom with ornate hanging light.\n",
      "39 62426 A bathroom decorated with a lot of fancy tile.\n",
      "40 19380 A bathroom with a yellow sink next to a white bath tub.\n",
      "40 19380 A bathroom with yellow walls and tile tub\n",
      "40 19380 A bathroom double vanity and tub with a chandelier above and intricate tile work.\n",
      "40 19380 A golden bath area with a chandelier and blue and white bathtub.\n",
      "40 19380 Double sink vanity next to a bathtub with a chandelier in the ceiling.\n",
      "41 485894 A bathroom with a white bath tub sitting in a corner of a green room.\n",
      "41 485894 A mint green bathroom with car pictures on the wall\n",
      "41 485894 a bathroom with mint green walls and pictures \n",
      "41 485894 Two pictures are hanging on the wall of the bathroom.\n",
      "41 485894 A bathroom has pictures hanging on the wall above the bathtub.\n",
      "42 446014 A girl washing her hands while looking into a mirror crying.\n",
      "42 446014 Black and white photograph of a child crying in mirror.\n",
      "42 446014 Little kid crying in the mirror while washing hands\n",
      "42 446014 A little child crying while standing at a bathroom sink.\n",
      "42 446014 A toddler cries while washing her hands in the bathroom\n",
      "43 530683 A woman in a dress riding a bicycle.\n",
      "43 530683 A woman in a black and white dress on a bicycle.\n",
      "43 530683 A woman stand near a group of people, and everyone is on bikes.\n",
      "43 530683 A woman in sunglasses is sitting on a bike with a dog.\n",
      "43 530683 A woman and a dog on a bike on the street.\n",
      "44 292835 A view of a very dirty bathroom that needs to be cleaned.\n",
      "44 292835 A bowl is on the floor in front of a broken toilet.\n",
      "44 292835 A white toilet in a bathroom under a window.\n",
      "44 292835 a bathroom that has a toilet and some nasty stuff all over\n",
      "44 292835 A bowl sitting in a bathroom across from a toilet.\n",
      "45 262845 A picture of a broken down bathroom with two sinks.\n",
      "45 262845 A dirty bathroom with two sinks and a curtain.\n",
      "45 262845 A dirty double sink bathroom with a curtain. \n",
      "45 262845 Two bathroom sinks are shown in a beat up bathroom.\n",
      "45 262845 Two sinks are shown in an abandoned place.\n",
      "46 299411 a bathroom that has a sink and a toilet in it\n",
      "46 299411 The bathroom has red carpet and yellowish appliances.\n",
      "46 299411 A bathroom sketch including a red carpet and pink towels and rug.\n",
      "46 299411 a painting or drawing of a bathroom with red flooring\n",
      "46 299411 An old bathroom with yellow colored toilet, sink and bath tub.\n",
      "47 42493 Two mountain bikers take a break on a path.\n",
      "47 42493 To young people on mountain bikes with trees behind them.\n",
      "47 42493 Two mountain bikers taking a break on a trail\n",
      "47 42493 Two young men on motorcross bikes stopped on a trail coming out of the woods.\n",
      "47 42493 two men standing on a rocky ground near a bush\n",
      "48 239811 A solid white bicycle is parked next to statues on a sidewalk.\n",
      "48 239811 A white bicycle leans against a post on the sidewalk.\n",
      "48 239811 A white bike parked next to a  couple of statues.\n",
      "48 239811 Bike monument in a city atmosphere with people walking and relaxing nearby.\n",
      "48 239811 A white bicycle anchored between the parking posts.\n",
      "49 2024 A bathroom looks new with nothing in it.\n",
      "49 2024 A mirror in the bathroom displays toilet paper and another mirror.\n",
      "49 2024 A bathroom sink beneath a very large mirror reflecting a roll of toilet paper.\n",
      "49 2024 This is a bathroom with a sink and a mirror.\n",
      "49 2024 A bathroom sink with a large mirror over it. \n",
      "50 95133 a bathroom scene with a wooden door and a sink in view\n",
      "50 95133 A bathroom featuring an antique style sink and tiled walls\n",
      "50 95133 A picture that is on the wall near a sink.\n",
      "50 95133 a sink a picture a mirror and white tiles\n",
      "50 95133 A white sink with brass fixtures in a small bathroom.\n",
      "51 287541 Two bathroom sinks mounted against a mirror, with soap in between the two sinks.\n",
      "51 287541 Two pedestal sinks at a mirror in a public restroom.\n",
      "51 287541 A close up view of a couple of sinks and soap bottle.\n",
      "51 287541 A couple of bottles of soap are sitting on sink\n",
      "51 287541 A bathroom that has two sinks in it.\n",
      "52 441488 MAN KNEELING BETWEEN TWO BICYCLES LOOKING AT HIS PHONE\n",
      "52 441488 A man squatting near two bikes and taking a picture of something. \n",
      "52 441488 Man taking picture while crouching on ground by two parked bicycles. \n",
      "52 441488 a man hunkered down between two bicycles \n",
      "52 441488 Man with bicycles squatting while taking a picture with a phone camera.\n",
      "53 179620 A toilet bowl with rolls of toilet paper stacked next to it\n",
      "\n",
      "53 179620 A bathroom toilet sitting next to a few roles of toilet paper.\n",
      "53 179620 There is a toilet with a picture above it, there are four rolls of tissue.\n",
      "53 179620 A bathroom with a toilet and white walls. \n",
      "53 179620 A white walled bathroom with six rolls of toilet paper next to a white toilet. \n",
      "54 70000 Bright loft space with large rustic dining table and bikes on the wall.\n",
      "54 70000 A room with windows, bikes, chairs, and a table. \n",
      "54 70000 A room with a table and chairs and bikes hanging up.\n",
      "54 70000 There is a long table in the middle of this room.\n",
      "54 70000 A dark room with a long wooden table and a bike hanging on the wall.\n",
      "55 536587 Adjustable magnifying mirror attached to a bathroom wall\n",
      "55 536587 A bathroom view of the vanity mirror and the close up mirror.\n",
      "55 536587 There are circular mirrors mounted to the tiled walls of the bathroom\n",
      "55 536587 A large mirror reflects a smaller bathroom mirror.\n",
      "55 536587 two mirrors that are attached to a wall\n",
      "56 543877 A bathroom features white, bowl sinks and a bathtub.\n",
      "56 543877 There are two sinks and a large tub in this bathroom.  \n",
      "56 543877 a modern looking white bathroom with 2 sinks, bathtub and shower\n",
      "56 543877 A bathroom with a large tub and his and her sinks.\n",
      "56 543877 This bathroom has a large jacuzzi tub and two sinks\n",
      "57 420721 A large furry cat pulling up the bathroom carpet\n",
      "57 420721 A playful cat pulls up the corner of a bathroom rug.\n",
      "57 420721 a bath room with a toilet and a cat on the rug\n",
      "57 420721 A cat laying next to a white toilet in a bathroom.\n",
      "57 420721 A cat playing with the rug around a toilet.\n",
      "58 540162 Toilet with upraised lid sitting next to bookshelves.\n",
      "58 540162 A shelf with books and toilet paper outside of a small bathroom.\n",
      "58 540162 A toilet and sink in a small bathroom.\n",
      "58 540162 A toilet with an adjacent bookshelf of books. \n",
      "58 540162 A bookshelf on the outside of a bathroom with a toilet.\n",
      "59 218956 A man standing in front of a white toilet in a restroom.\n",
      "59 218956 Guy in hoodie peeing in a bathroom toilet\n",
      "59 218956 A man is standing in front of a toilet.\n",
      "59 218956 A MAN PEEING IN THE TOILET WITH SOME NOTE WRITTEN IN FRONT OF HIM.\n",
      "59 218956 A man wearing a purple hoodie urinating in a dirty restroom. \n",
      "59 218956 A man is urinating in an unfinished restroom.\n",
      "60 318574 Bicycle wheels are lined up on bicycles in a row.  \n",
      "60 318574 A crosswalk photo focusing on the wheels of bikes\n",
      "60 318574 A group of bicyclists going together on the street. \n",
      "60 318574 People are riding bikes on a street. \n",
      "60 318574 some people riding some bikes down the road \n",
      "61 172899 A bathroom scene complete with a tab, sink and toilet.\n",
      "61 172899 A plain bathroom features a white toilet and sink and a beige bathtub.\n",
      "61 172899 A bathroom with both white and beige fixtures.  \n",
      "61 172899 Three piece bathroom with white sink and toilet and beige tub/shower.\n",
      "61 172899 A bathroom white sink, toilet and shower, looks clean.\n",
      "62 352884 Bathroom with destroyed walls, a sink and a mirrored cabinet. \n",
      "62 352884 A run down bathroom with paint peeling off the walls. \n",
      "62 352884 The bathroom is in need of remodeling and repair. \n",
      "62 352884 A crumbling bathroom has a sink and a medicine cabinet.\n",
      "62 352884 The paint of an abandoned bathroom peels off the walls.\n",
      "63 394326 A black and white photo of restroom toilet with a filthy floor.\n",
      "63 394326 Black and white photograph of bathroom toilet and sink.\n",
      "63 394326 A dirty looking bathroom with a sink and a toilet.\n",
      "63 394326 A black and white photo of a dirty bathroom with focus on the toilet.\n",
      "63 394326 A toilet and sink sit in a dark room.\n",
      "64 535786 A toilet with a bow on it inside a bathroom.\n",
      "64 535786 a bathroom scene with a white toilet covered with a red bow\n",
      "64 535786 There is a picture of a bathroom with a toliet wrapped in a red ribbon.\n",
      "64 535786 A white bathroom with a carefully gift-wrapped toilet bowl.\n",
      "64 535786 A brand new toilet with a bow across the seat.\n",
      "65 357684 Several groups of people are standing outside of a building.\n",
      "65 357684 A view of a clock tower with people around it.\n",
      "65 357684 A small clock tower in a town plaza.\n",
      "65 357684 there are many people that are gathered in this square\n",
      "65 357684 Many people are strolling through the open plaza. \n",
      "66 576757 An unfinished bathroom has a toilet and tools\n",
      "66 576757 A white toilet sitting in a demolished bathroom.\n",
      "66 576757 Construction tools sit in a bathroom that has has the walls and floor torn up.\n",
      "66 576757 A bathroom toilet in the middle of being remodeled.\n",
      "66 576757 A bathroom that's being remodeled and has a toilet.\n",
      "67 165499 A bathroom shower with glass doors and tile walls. \n",
      "67 165499 a bathroom with a white sink shower and toilet\n",
      "67 165499 Bathroom that has a toilet, shower, and sink.\n",
      "67 165499 A modern bathroom has a corner shower that's clear.\n",
      "67 165499 A bathroom with a see-through shower door. \n",
      "68 181104 A white bathtub sitting in a bathroom next to a sink.\n",
      "68 181104 The small bathroom has a grey and white motif.\n",
      "68 181104 A bathroom with a black door and a white tub\n",
      "68 181104 a bathroom has one black wall and a black floor\n",
      "68 181104 A tiled bathroom with mirrors in the bathtub\n",
      "69 55627 A bathroom is freshly cleaned and ready for hotel patrons.\n",
      "69 55627 Closed toilet, sink, and mirror in a modern bathroom.\n",
      "69 55627 A bathroom with a mirror above the sink, a towel rack and toilet.\n",
      "69 55627 There is a sink and toilet in the bathroom.\n",
      "69 55627 Heated towel racks and a built in hairdryer in a hotel bathroom\n",
      "70 241364 A mirror that is sitting behind a sink.\n",
      "70 241364 A bathroom with a sink and a toilet in it.\n",
      "70 241364 A white bathroom with chrome fixtures and blue tile.\n",
      "70 241364 A hotel bathroom with a large sink sticking out of the counter.\n",
      "70 241364 A decently sized bathroom with a nice sink\n",
      "71 209967 A sink and vanity with overhead lights a decorative piece on the wall and a commode.\n",
      "71 209967 The light is on over the sink in the bathroom.\n",
      "71 209967 A marble tiled counter in a small bathroom\n",
      "71 209967 A bathroom with a Monogrammed symbol above a toilet.\n",
      "71 209967 this bathroom has a sculpture hanging on the wall\n",
      "72 153674 A bathroom sink with the faucet on the side\n",
      "72 153674 A small porcelain sink is reflected in a bathroom mirror.\n",
      "72 153674 A small rectangular sink with a single chrome faucet.\n",
      "72 153674 Two sinks that are set right next to each other.\n",
      "72 153674 a small sink with a small bottle of soap \n",
      "73 354444 a lady sitting in a van with several seagulls landing on the top\n",
      "73 354444 A woman in a truck watching the birds sit on her open door and the top of the truck. \n",
      "73 354444 Birds are sitting on an automobile where a woman is sitting.\n",
      "73 354444 A group of seagull attacking the roof of some peoples truck.\n",
      "73 354444 A group of birds on a truck with a person inside.\n",
      "74 98760 A dog sticks its out out the window of a car. \n",
      "74 98760 a brown dog puts his head out of the window of a moving car\n",
      "74 98760 A small brown dog sticking it's head out of a car window.\n",
      "74 98760 A fluffy dog sticking his head out the window of a moving car. \n",
      "74 98760 This is a cute dog sticking his head out of the window of a red car.\n",
      "75 311914 A school bus parked with it's stop sign closed.\n",
      "75 311914 A stop sign is on the side of a school bus. \n",
      "75 311914 a bus sits stopped with a sign on the side of it \n",
      "75 311914 Side of a school bus showing a stop sign.\n",
      "75 311914 A view of a stop sign, on the side of a bus.\n",
      "76 467311 A bus and a few other vehicles that appear to be traveling down the road.\n",
      "76 467311 A yellow automobile behind a bus in a city. \n",
      "76 467311 The yellow truck is riding behind the grey city bus. \n",
      "76 467311 A bus with an advertisement and a yellow hummer behind it\n",
      "76 467311 A truck that is sitting behind a bus.\n",
      "77 236772 In the bathroom a toilet is full of ice cubes.\n",
      "77 236772 The toilet in the bathroom is filled with a bunch of ice.\n",
      "77 236772 Ice cubes in the bottom of a toilet bowl.\n",
      "77 236772 a big toilet that has some ice in it\n",
      "77 236772 A view of a bunch of ice sitting in a toilet.\n",
      "78 49183 A white toilet commode sits on a tile floor.\n",
      "78 49183 A toilet bowl with a bucket and trash can by it.\n",
      "78 49183 A dirty toilet in a dirty bathroom with laminate flooring. \n",
      "78 49183 a toilet sits on a tiled floor next to a trash can \n",
      "78 49183 The toilet and surrounding area is extremely dirty. \n",
      "79 426038 A boat with lots of seats and large windows.\n",
      "79 426038 View of the Golden Gate Bridge from a restaurant. \n",
      "79 426038 Inside view of tables next to the windows in the boat\n",
      "79 426038 The eating car of the train has empty booths.\n",
      "79 426038 A view looking outside a train window by a table with a flower vase.\n",
      "80 309322 The Phillips 66 clocks is in front of some posters.\n",
      "80 309322 Vintage photos of a car and motorcycle are displayed with a gas station clock.\n",
      "80 309322 Phillips 66 logo with photo of old car and motorcycle behind.\n",
      "80 309322 A clock hangs on the wall underneath some pictures\n",
      "80 309322 A clock resembling an old gas station sign.\n",
      "81 318189 An old red and yellow car with a yellow surfboard on top.\n",
      "81 318189 an older car on a street with a surf board\n",
      "81 318189 A classic woody station wagon with a yellow surfboard strapped on top.\n",
      "81 318189 a colorful station wagon sitting on the side of the road with a surfboard on top \n",
      "81 318189 A bright station wagon with a surfboard on the roof\n",
      "82 343322 Blue and white antique car at intersection of city roadway.\n",
      "82 343322 A blue vintage car is driving down the street.\n",
      "82 343322 The antique cars are traveling down main street.\n",
      "82 343322 A car driving down a street next to a tall building.\n",
      "82 343322 A blue classic Chevy Nomad driving down a busy city street.\n",
      "83 36633 A toilet with a trash can and a roll of toilet paper on top \n",
      "83 36633 A toilet sits in a simple yet messy bathroom.\n",
      "83 36633 A toilet in a small bathroom with garbage on the ground.\n",
      "83 36633 A bathroom stall with pantyhose on the floor. \n",
      "83 36633 A toilet that is next to a trashcan and some toilet paper.\n",
      "84 213546 A mirrored bathroom features duel, white porcelain sinks and silver faucets. \n",
      "84 213546 A white bathroom sink surrounded by mirrors and lights.\n",
      "84 213546 A gray bathroom is lit up to show to sinks.\n",
      "84 213546 A bathroom with a sink, mirror and garbage can. \n",
      "84 213546 The reflection of the bathroom sink in a mirror\n",
      "85 378710 A wall with four mounted urinals on it.\n",
      "85 378710 A couple of strange shaped urinals on a wall.\n",
      "85 378710 Four white urinals are lined up along a wall.\n",
      "85 378710 Three tall urinals and one short one in a restroom. \n",
      "85 378710 there are four pee toilets on the wall in a bathroom\n",
      "86 189993 A black bear on display in a library.\n",
      "86 189993 A mounted bear in a display case in a library.\n",
      "86 189993 A taxidermy bear on display in a library.\n",
      "86 189993 A view of a fake bear in a glass box.\n",
      "86 189993 A stuffed bear is in a display case in a library. \n",
      "87 551125 A group of three urinals mounted to a wall.\n",
      "87 551125 Three urinals are attached to a bathroom wall.\n",
      "87 551125 Three waterless urinals are more disgusting than one.\n",
      "87 551125 Three urinals line a tiled wall in a restroom.\n",
      "87 551125 Three modern looking urinals up against a wall.\n",
      "88 77806 Small dog in wire basket transported on motor scooter in city.\n",
      "88 77806 A dog is inside of a covered cage on back of a motorcycle.\n",
      "88 77806 a dog in a cage on a motocycle\n",
      "88 77806 A dog sits in a cage on the back of a motorcycle.\n",
      "88 77806 A dog is in a cage on the back of a motorcycle\n",
      "89 546451 A small restroom that is painted the color blue.\n",
      "89 546451 The toilet bowl is next to two rolls of toilet paper mounted on a wall.\n",
      "89 546451 A small bathroom is seen from above and at a slanted angle.\n",
      "89 546451 A toilet in a bathroom with its seat down.\n",
      "89 546451 A toilet area painted in a light green color.\n",
      "90 444546 a spoon and a fork that is on a table\n",
      "90 444546 The spoon and fork are on the napkin near a glass. \n",
      "90 444546 A napkin with a cup, spoon, and knife arranged on it.\n",
      "90 444546 a spoon and fork crossed over each other next to a clear glass \n",
      "90 444546 An empty table with a fork, spoon, and glass.\n",
      "91 147016 A toilet connected to a wire, next to a speaker.\n",
      "91 147016 A white toilet sitting in the corner of a room next to a black object.\n",
      "91 147016 A toilet with speaker wire running through it.\n",
      "91 147016 A toilet and a speaker sitting on the floor.\n",
      "91 147016 An toilet on a wooden floor next to a black speaker\n",
      "92 497616 A black and white photo of a cat sitting on a chair.\n",
      "92 497616 a black and white photo of a cat using an old photo camera \n",
      "92 497616 A cat comically taking an old fashioned picture of another cat.\n",
      "92 497616 A cat sitting in a chair near another cat that is holding on to something with his paw\n",
      "92 497616 a vintage photo of a cat taking a picture of another cat\n",
      "93 520208 a spoon sitting on some food in a bowl \n",
      "93 520208 A bowl of food and a spoon held up that has eaten food.\n",
      "93 520208 A white bowl filled with mixed vegetables and a spoon.\n",
      "93 520208 There is a spoons resting in a bowl of food.\n",
      "93 520208 a close up of a spoon in a bowl of food\n",
      "94 199628 A public restroom has two sinks shaped like fancy vases. \n",
      "94 199628 Two tall ceramic sinks in a men's restroom. \n",
      "94 199628 Two old fashion looking pots are standing in a bathroom. \n",
      "94 199628 Two sinks are shown that are blue and white floral.\n",
      "94 199628 Two sinks ,mirrors and urinals in a bathroom.\n",
      "95 280980 A man in a costume and wig is using a urinal.\n",
      "95 280980 a person in a bathroom with a toilet and frames on the wall\n",
      "95 280980 A man with a white wig and beard and a Christmas hat in a bathroom.\n",
      "95 280980 A person in a Santa hat holds a cup away from the sink in a bathroom.\n",
      "95 280980 A man dressed up like santa taking a leak.\n",
      "96 167613 A bathroom with a white toilet and sink and checkered tile.\n",
      "96 167613 A bathroom with a toilet and a sink.\n",
      "96 167613 A bathroom that is done in checkered walls and flooring.\n",
      "96 167613 Public restroom with black and white checker pattern walls.\n",
      "96 167613 A toilet and sink in a bathroom with checked walls.\n",
      "97 142088 Black motorcycle sitting underneath an overhang outdoors. \n",
      "97 142088 a motorcycle sitting under an awning next to a bunch of stuff \n",
      "97 142088 A bunch of stuff that is being stored in a small open building. \n",
      "97 142088 A motorcycle parked under a wooden structure with other items.\n",
      "97 142088 Motorcycle parked under covered area in fenced yard.\n",
      "98 301778 Dirty bathroom floor with a toilet and a toilet brush next to it.\n",
      "98 301778 A gas station toilet has not been cleaned in months\n",
      "98 301778 A white toilet with black water around it.\n",
      "98 301778 A toilet and a toilet cleaning brush on a dirty floor.\n",
      "98 301778 A toilet that is in a dirty bathroom.\n",
      "99 454325 A modern restroom is equipped with fashionable sinks and urinals surrounded by architectural subway tile.\n",
      "99 454325 a bathroom with urinals sinks and towel dispensers\n",
      "99 454325 Sinks and urinals with unconventional placement in a public restroom.\n",
      "99 454325 A couple of urinals mounted to a wall in a restroom.\n",
      "99 454325 A bathroom with two urinals directly below the sinks.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Testing only, please ignore for marking. \"\"\"\n",
    "for i in range(len(train_ids[0:100])):\n",
    "    for caption in train_id_to_captions[train_ids[i]]:\n",
    "        print(i, train_ids[i], caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82783\n",
      "57870 truck truck truck donuts antique antique antique antique antique antique antique antique antique antique antique antique antique antique antique\n",
      "429437 riding donuts net net net meal net vehicles antique antique antique antique antique antique antique antique antique antique antique\n",
      "239596 broccoli broccoli path path vehicles vehicles vehicles vehicles antique antique antique antique antique antique antique antique antique antique antique\n",
      "142420 fork fork blanket blanket vehicles vehicles vehicles vehicles antique antique antique antique antique antique antique antique antique antique antique\n",
      "344883 dark blanket blanket blanket blanket about hold hold hold hold hold meal vehicles vehicles vehicles antique antique antique antique\n",
      "114474 middle blanket blanket blanket blanket blanket professional vehicles vehicles vehicles antique antique antique antique antique antique antique antique antique\n",
      "395406 features features steam displayed under net vehicles antique antique antique antique antique antique antique antique antique antique antique antique\n",
      "454708 soccer soccer vehicles vehicles vehicles vehicles antique antique antique antique antique antique antique antique antique antique antique antique antique\n",
      "337902 track track hold hold hold hold hold hold hold meal vehicles vehicles vehicles antique antique antique antique antique antique\n",
      "307061 one driving under cart vehicles vehicles vehicles antique antique antique antique antique antique antique antique antique antique antique antique\n",
      "440813 rain skies hay hay hay hay hay hay hay gear vehicles vehicles antique antique antique antique antique antique antique\n",
      "526793 middle middle be be hold hold hold hold hold hold meal vehicles vehicles vehicles antique antique antique antique antique\n",
      "286284 wide middle hold hold meal hold hold meal vehicles vehicles vehicles antique antique antique antique antique antique antique antique\n",
      "95019 object controller controller in bananas hold hold controller antique antique antique antique antique antique antique antique antique antique antique\n",
      "404495 skis skis hill hold hold hold hold hold hold meal vehicles vehicles vehicles antique antique antique antique antique antique\n",
      "166477 riding chairs blanket blanket bananas vehicles antique antique antique antique antique antique antique antique antique antique antique antique antique\n",
      "57767 road takes in in net in bananas vehicles antique antique antique antique antique antique antique antique antique antique antique\n",
      "262603 towards towards wide net net meal net vehicles antique antique antique antique antique antique antique antique antique antique antique\n",
      "355438 trailer donuts hold hold hold meal vehicles vehicles vehicles antique antique antique antique antique antique antique antique antique antique\n",
      "498372 soccer soccer carrot vehicles vehicles vehicles vehicles vehicles antique antique antique antique antique antique antique antique antique antique antique\n",
      "316293 image in in bananas vehicles vehicles antique antique antique antique antique antique antique antique antique antique antique antique antique\n",
      "532612 eating eating different under net net vehicles antique antique antique antique antique antique antique antique antique antique antique antique\n",
      "291894 truck truck donuts donuts antique antique antique antique antique antique antique antique antique antique antique antique antique antique antique\n",
      "252627 wide wide lamp lamp hold hold controller hold hold hold hold hold meal vehicles vehicles vehicles antique antique antique\n",
      "358378 wide steam steam hold hold hold hold hold meal vehicles vehicles vehicles antique antique antique antique antique antique antique\n",
      "397462 flat large large large vehicles vehicles vehicles vehicles antique antique antique antique antique antique antique antique antique antique antique\n",
      "60319 dining hold hold hold hold hold hold hold hold meal vehicles vehicles vehicles antique antique antique antique antique antique\n",
      "279871 park park hold hold hold hold hold hold meal vehicles vehicles vehicles antique antique antique antique antique antique antique\n",
      "31865 older older bananas hold hold hold hold hold meal vehicles vehicles vehicles antique antique antique antique antique antique antique\n",
      "127042 arm arm arm donuts hold hold hold hold hold hold meal vehicles vehicles vehicles antique antique antique antique antique\n",
      "341245 chairs chairs chairs chairs controller controller antique antique antique antique antique antique antique antique antique antique antique antique antique\n",
      "151577 riding wide net net net in lamp vehicles vehicles antique antique antique antique antique antique antique antique antique antique\n",
      "123424 hay hay hay hay hay hay hay antique antique antique antique antique antique antique antique antique antique antique antique\n",
      "70485 look look look look vehicles vehicles antique antique antique antique antique antique antique antique antique antique antique antique antique\n",
      "40455 net net net net net vehicles antique antique antique antique antique antique antique antique antique antique antique antique antique\n",
      "140762 line line line net net about vehicles vehicles antique antique antique antique antique antique antique antique antique antique antique\n",
      "27879 object different rain hold hold hold hold hold hold meal vehicles vehicles vehicles antique antique antique antique antique antique\n",
      "379766 skis steam displayed displayed net net antique antique antique antique antique antique antique antique antique antique antique antique antique\n",
      "301381 dining chairs controller controller controller antique antique antique antique antique antique antique antique antique antique antique antique antique antique\n",
      "389577 van blanket blanket blanket lamp vehicles vehicles vehicles antique antique antique antique antique antique antique antique antique antique antique\n",
      "455342 truck truck wide hold hold hold hold hold meal vehicles vehicles vehicles antique antique antique antique antique antique antique\n",
      "407626 what what hold hold hold hold hold hold meal vehicles vehicles vehicles antique antique antique antique antique antique antique\n",
      "21285 skateboard net net net cream vehicles antique antique antique antique antique antique antique antique antique antique antique antique antique\n",
      "21097 walks walks walks walks meal under vehicles vehicles vehicles antique antique antique antique antique antique antique antique antique antique\n",
      "557695 rain net net net net net in vehicles vehicles antique antique antique antique antique antique antique antique antique antique\n",
      "391084 getting getting tracks hold hold hold hold hold meal vehicles vehicles vehicles antique antique antique antique antique antique antique\n",
      "134958 elephant hold hold hold hold hold hold meal vehicles vehicles vehicles antique antique antique antique antique antique antique antique\n",
      "580913 what hold hold hold hold hold hold meal vehicles vehicles vehicles antique antique antique antique antique antique antique antique\n",
      "396115 fenced large large look vehicles antique antique antique antique antique antique antique antique antique antique antique antique antique antique\n",
      "223928 concrete concrete empty net net net in vehicles antique antique antique antique antique antique antique antique antique antique antique\n",
      "67116 oven oven vehicles vehicles vehicles vehicles vehicles vehicles antique antique antique antique antique antique antique antique antique antique antique\n",
      "311941 making runway hold hold hold hold hold meal vehicles vehicles vehicles antique antique antique antique antique antique antique antique\n",
      "339059 donut hold hold hold hold hold hold meal vehicles vehicles vehicles antique antique antique antique antique antique antique antique\n",
      "329230 dining set under under under net under net vehicles antique antique antique antique antique antique antique antique antique antique\n",
      "521094 van van meal net meal vehicles vehicles vehicles vehicles antique antique antique antique antique antique antique antique antique antique\n",
      "342681 sit sit sit professional hold hold hold hold hold hold hold meal vehicles vehicles vehicles antique antique antique antique\n",
      "225054 truck in and wide hold hold hold meal vehicles vehicles vehicles antique antique antique antique antique antique antique antique\n",
      "132836 truck donuts hold hold hold hold hold hold hold hold meal vehicles vehicles vehicles antique antique antique antique antique\n",
      "198227 truck narrow narrow hold hold hold hold hold hold hold meal vehicles vehicles vehicles antique antique antique antique antique\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246990 truck truck asian asian asian vehicles vehicles antique antique antique antique antique antique antique antique antique antique antique antique\n",
      "403133 wide wide wide net net in about hold hold hold hold meal vehicles vehicles vehicles antique antique antique antique\n",
      "154107 truck hay hay hay hay hay hay hay hay hay hay gear vehicles vehicles antique antique antique antique antique\n",
      "517138 hay hay hay hay hay hay hay hay hay hay gear vehicles vehicles antique antique antique antique antique antique\n",
      "315268 chairs hold hold hold hold hold hold hold hold meal vehicles vehicles vehicles antique antique antique antique antique antique\n",
      "365008 arm broccoli broccoli net net net vehicles vehicles antique antique antique antique antique antique antique antique antique antique antique\n",
      "135338 kinds kinds steam hold hold antique antique antique antique antique antique antique antique antique antique antique antique antique antique\n",
      "66118 something something oven racing cart vehicles vehicles vehicles vehicles antique antique antique antique antique antique antique antique antique antique\n",
      "269051 wide wide professional professional net lamp hold hold hold hold hold hold meal vehicles vehicles vehicles antique antique antique\n",
      "41226 toddler net net net net net net vehicles antique antique antique antique antique antique antique antique antique antique antique\n",
      "465507 jump middle middle antique antique antique antique antique antique antique antique antique antique antique antique antique antique antique antique\n",
      "205851 dining chairs chairs net net about antique antique antique antique antique antique antique antique antique antique antique antique antique\n",
      "74997 jump driving driving hold hold hold hold hold hold meal vehicles vehicles vehicles antique antique antique antique antique antique\n",
      "554823 colored colored hold hold hold hold hold meal vehicles vehicles vehicles antique antique antique antique antique antique antique antique\n",
      "422305 van van skate antique antique antique antique antique antique antique antique antique antique antique antique antique antique antique antique\n",
      "195772 field and herd hold antique antique antique antique antique antique antique antique antique antique antique antique antique antique antique\n",
      "434813 group driving hold hold hold hold hold hold hold hold meal vehicles vehicles vehicles antique antique antique antique antique\n",
      "362067 truck truck donuts donuts donuts antique antique antique antique antique antique antique antique antique antique antique antique antique antique\n",
      "177628 object object chairs chairs hay hay hay antique antique antique antique antique antique antique antique antique antique antique antique\n",
      "261071 veggies gear wide red hold hold meal vehicles vehicles vehicles antique antique antique antique antique antique antique antique antique\n",
      "390539 containers containers under under net net vehicles antique antique antique antique antique antique antique antique antique antique antique antique\n",
      "423223 concrete track hold hold hold hold hold hold meal vehicles vehicles vehicles antique antique antique antique antique antique antique\n",
      "505633 dining chairs hold hold hold hold hold hold hold meal vehicles vehicles vehicles antique antique antique antique antique antique\n",
      "46365 in in in wild vehicles vehicles antique antique antique antique antique antique antique antique antique antique antique antique antique\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "def seq2seq_inference(input_image, embeddings=one_hot_embeddings, max_length=20):\n",
    "    image_features = encoder(input_image)\n",
    "\n",
    "    # Construct the decoder input (initially <SOS> for every batch)\n",
    "    decoder_input = Variable(torch.FloatTensor([[embeddings[word2index[\"<SOS>\"]]]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    # Set the initial hidden state of the decoder to be the last hidden state of the encoder\n",
    "    last_hidden = decoder.initHidden(image_features.size(1), image_features).unsqueeze(0)\n",
    "    decoder_hidden = (last_hidden, last_hidden)\n",
    "    \n",
    "    # Iterate over the indices after the first.\n",
    "    decoder_outputs = []\n",
    "    for t in range(1,max_length):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "    \n",
    "        # Get the top result\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        decoder_outputs.append(ni)\n",
    "\n",
    "        if vocabulary[ni] == \"<EOS>\":\n",
    "            break\n",
    "        \n",
    "        #Prepare the inputs\n",
    "        decoder_input = Variable(torch.FloatTensor([[embeddings[ni]]])).cuda()\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    return ' '.join(vocabulary[i] for i in decoder_outputs)\n",
    "\n",
    "print(len(train_ids))\n",
    "for i in range(len(train_ids)):\n",
    "    if i % 1000 == 0:\n",
    "        print(train_ids[i], seq2seq_inference(load_image(train_id_to_file[train_ids[i]])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluate performance\n",
    "\n",
    "For validation images compute the average BLEU score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
